{"StableSR_doc/README":{"slug":"StableSR_doc/README","filePath":"StableSR_doc/README.md","title":"README","links":[],"tags":[],"content":"StableSR_doc"},"StableSR_doc/ldm/models/diffusion/ddpm/DiffusionWrapper(pl.LightningModule)":{"slug":"StableSR_doc/ldm/models/diffusion/ddpm/DiffusionWrapper(pl.LightningModule)","filePath":"StableSR_doc/ldm/models/diffusion/ddpm/DiffusionWrapper(pl.LightningModule).md","title":"DiffusionWrapper(pl.LightningModule)","links":[],"tags":[],"content":"class DiffusionWrapper(pl.LightningModule):\n    def __init__(self, diff_model_config, conditioning_key):\n        super().__init__()\n        self.diffusion_model = instantiate_from_config(diff_model_config) # [[instantiate_from_config]]\n        self.conditioning_key = conditioning_key\n        assert self.conditioning_key in [None, &#039;concat&#039;, &#039;crossattn&#039;, &#039;hybrid&#039;, &#039;adm&#039;]\n \n    def forward(self, x, t, c_concat: list = None, c_crossattn: list = None, struct_cond=None, seg_cond=None):\n        if self.conditioning_key is None: # [[#none无条件扩散unconditional|None：无条件扩散（Unconditional）]]\n            out = self.diffusion_model(x, t)\n        elif self.conditioning_key == &#039;concat&#039;: # [[#concat通道拼接channel-concat|concat：通道拼接（Channel Concat）]]\n            xc = torch.cat([x] + c_concat, dim=1) \n            out = self.diffusion_model(xc, t)\n        elif self.conditioning_key == &#039;crossattn&#039;: # [[#crossattn交叉注意力cross-attention|crossattn：交叉注意力（Cross-Attention）]]\n            cc = torch.cat(c_crossattn, 1)\n            if seg_cond is None:\n                out = self.diffusion_model(x, t, context=cc, struct_cond=struct_cond)\n            else:\n                out = self.diffusion_model(x, t, context=cc, struct_cond=struct_cond, seg_cond=seg_cond)\n        elif self.conditioning_key == &#039;hybrid&#039;: # [[#hybrid通道拼接--交叉注意力concat--cross-attn|hybrid：通道拼接 + 交叉注意力（Concat + Cross-Attn）]]\n            xc = torch.cat([x] + c_concat, dim=1)\n            cc = torch.cat(c_crossattn, 1)\n            out = self.diffusion_model(xc, t, context=cc)\n        elif self.conditioning_key == &#039;adm&#039;: # [[#adm标签注入classifier-free-guidance|adm：标签注入（Classifier-free Guidance）]]\n            cc = c_crossattn[0]\n            out = self.diffusion_model(x, t, y=cc)\n        else:\n            raise NotImplementedError()\n \n        return out\n \nDiffusionWrapper.forward() 中 conditioning_key 的五种模式解析\n在 StableSR 或 Latent Diffusion 中，conditioning_key 决定了条件信息如何注入到扩散模型（通常是 UNet，如 UNetModelDualConv2d）中。该参数影响的是 DiffusionWrapper 在 forward 阶段如何组织输入，并通过哪些通路将条件信息传递到扩散网络。\n\nNone：无条件扩散（Unconditional）\nout = self.diffusion_model(x, t)\n\n不使用任何条件信息；\n输入仅为带噪图像 x 和时间步 t；\n通常用于纯图像建模、初期训练或 unconditional generation。\n\n\nconcat：通道拼接（Channel Concat）\nxc = torch.cat([x] + c_concat, dim=1)\nout = self.diffusion_model(xc, t)\n\n条件以图像形式提供（如低清图、边缘图、小波子带），直接拼接到 x 上；\n通道维度变为 C + C_cond；\n是 SR3 使用的典型条件注入方法；\n是传统sr3的方法,简单高效，但灵活性较差。\n\n\ncrossattn：交叉注意力（Cross-Attention）\ncc = torch.cat(c_crossattn, 1)\nout = self.diffusion_model(x, t, context=cc, struct_cond=..., seg_cond=...)\n\n条件信息（如结构图、小波图、文本）通过 cond_stage_model 编码为 latent 向量；\n这些 latent 向量作为 context，传入 UNet 内部的 CrossAttention 模块；\n可选地支持结构条件 struct_cond 和语义条件 seg_cond；\n是现代条件扩散（如 Stable Diffusion）最常用策略，灵活且表达力强。\n\n\nhybrid：通道拼接 + 交叉注意力（Concat + Cross-Attn）\nxc = torch.cat([x] + c_concat, dim=1)\ncc = torch.cat(c_crossattn, 1)\nout = self.diffusion_model(xc, t, context=cc)\n\n同时使用 concat 和 cross-attention 两种通路注入条件；\n通道拼接传递低级信息（细节、边缘）；\ncross-attn 传递高级语义（结构 latent、小波 latent）；\n在 StableSR 中，通常两路条件信息都来源于同一个结构图，只是经过不同路径处理；\n平衡引导性与灵活性，是推荐模式之一。\n\n\nadm：标签注入（Classifier-free Guidance）\ncc = c_crossattn[0]\nout = self.diffusion_model(x, t, y=cc)\n\n用于类别或 token 作为标签条件（如 ImageNet class label）；\ny=cc 表示将条件作为类标签注入；\n需要扩散模型支持 y 输入（如通过 ConditionalBatchNorm、embedding 等）；\n常见于 ADM/DDPMv2 等分类条件生成场景。\n\n\n总结\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nconditioning_key条件注入方式典型用途None无条件纯图像建模&#039;concat&#039;通道拼接SR3、结构图引导&#039;crossattn&#039;交叉注意力Stable Diffusion、结构/文本引导&#039;hybrid&#039;拼接 + 注意力StableSR、小波 + 结构联合引导&#039;adm&#039;标签输入分类条件生成（如 class-conditional DDPM）\n实际应用中，可根据条件类型和任务目标灵活选择或组合这些模式。"},"StableSR_doc/ldm/models/diffusion/ddpm/Module_info":{"slug":"StableSR_doc/ldm/models/diffusion/ddpm/Module_info","filePath":"StableSR_doc/ldm/models/diffusion/ddpm/Module_info.md","title":"Module_info","links":["StableSR_doc/ldm/models/diffusion/ddpm/torch2img","StableSR_doc/ldm/models/diffusion/ddpm/cal_pca_components","StableSR_doc/ldm/models/diffusion/ddpm/visualize_fea","StableSR_doc/ldm/models/diffusion/ddpm/calc_mean_std","StableSR_doc/ldm/models/diffusion/ddpm/adaptive_instance_normalization","StableSR_doc/ldm/models/diffusion/ddpm/space_timesteps","StableSR_doc/ldm/models/diffusion/ddpm/disabled_train","StableSR_doc/ldm/models/diffusion/ddpm/uniform_on_device","StableSR_doc/ldm/models/diffusion/ddpm/class-DDPM/DDPM(pl.LightningModule)","LatentDiffusion(DDPM)","LatentDiffusionSRTextWT(DDPM)","LatentDiffusionSRTextWTFFHQ(LatentDiffusionSRTextWT)","StableSR_doc/ldm/models/diffusion/ddpm/DiffusionWrapper(pl.LightningModule)","Layout2ImgDiffusion(LatentDiffusion)"],"tags":[],"content":"\n\n                  \n                  UML 图解：ddpm.py文件结构 \n                  \n                \n\n\n\n‘ldm.models.diffusion.ddpm’ 中各个类的关系。\n\n\n\nFunctions\ntorch2img\ncal_pca_components\nvisualize_fea\ncalc_mean_std\nadaptive_instance_normalization\nspace_timesteps\ndisabled_train\nuniform_on_device\nClasses\nDDPM(pl.LightningModule)\nLatentDiffusion(DDPM)\nLatentDiffusionSRTextWT(DDPM)\nLatentDiffusionSRTextWTFFHQ(LatentDiffusionSRTextWT)\nDiffusionWrapper(pl.LightningModule)\nLayout2ImgDiffusion(LatentDiffusion)"},"StableSR_doc/ldm/models/diffusion/ddpm/adaptive_instance_normalization":{"slug":"StableSR_doc/ldm/models/diffusion/ddpm/adaptive_instance_normalization","filePath":"StableSR_doc/ldm/models/diffusion/ddpm/adaptive_instance_normalization.md","title":"adaptive_instance_normalization","links":[],"tags":[],"content":""},"StableSR_doc/ldm/models/diffusion/ddpm/cal_pca_components":{"slug":"StableSR_doc/ldm/models/diffusion/ddpm/cal_pca_components","filePath":"StableSR_doc/ldm/models/diffusion/ddpm/cal_pca_components.md","title":"cal_pca_components","links":[],"tags":[],"content":""},"StableSR_doc/ldm/models/diffusion/ddpm/calc_mean_std":{"slug":"StableSR_doc/ldm/models/diffusion/ddpm/calc_mean_std","filePath":"StableSR_doc/ldm/models/diffusion/ddpm/calc_mean_std.md","title":"calc_mean_std","links":[],"tags":[],"content":""},"StableSR_doc/ldm/models/diffusion/ddpm/class-DDPM/DDPM(pl.LightningModule)":{"slug":"StableSR_doc/ldm/models/diffusion/ddpm/class-DDPM/DDPM(pl.LightningModule)","filePath":"StableSR_doc/ldm/models/diffusion/ddpm/class DDPM/DDPM(pl.LightningModule).md","title":"DDPM(pl.LightningModule)","links":["register_schedule","DDPM","_get_rows_from_list","configure_optimizers","forward","get_input","get_loss","get_v","StableSR_doc/ldm/models/diffusion/ddpm/class-DDPM/init_from_ckpt","on_train_batch_end","p_losses","p_mean_variance","predict_start_from_noise","predict_start_from_z_and_v","q_mean_variance","q_posterior","q_sample","q_sample_respace","shared_step","training_step"],"tags":[],"content":"Class: DDPM\nInheritance Tree (MRO):\n\nDDPM\nLightningModule\nABC\nDeviceDtypeModuleMixin\nHyperparametersMixin\nGradInformation\nModelIO\nModelHooks\nDataHooks\nCheckpointHooks\nModule\nobject\n\nInstance Attributes (from self.xxx assignments):\n\nparameterization (defined in: [[init]])\ncond_stage_model (defined in: [[init]])\nclip_denoised (defined in: [[init]])\nlog_every_t (defined in: [[init]])\nfirst_stage_key (defined in: [[init]])\nimage_size (defined in: [[init]])\nchannels (defined in: [[init]])\nuse_positional_encodings (defined in: [[init]])\nmodel (defined in: [[init]])\nuse_ema (defined in: [[init]])\nuse_scheduler (defined in: [[init]])\nv_posterior (defined in: [[init]])\noriginal_elbo_weight (defined in: [[init]])\nl_simple_weight (defined in: [[init]])\nloss_type (defined in: [[init]])\nlearn_logvar (defined in: [[init]])\nlogvar (defined in: [[init, init]])\nmodel_ema (defined in: [[init]])\nscheduler_config (defined in: [[init]])\nmonitor (defined in: [[init]])\nnum_timesteps (defined in: register_schedule)\nlinear_start (defined in: register_schedule)\nlinear_end (defined in: register_schedule)\n\nProject-defined Methods:\n\n[[init]]  ←  DDPM\n_get_rows_from_list  ←  DDPM\nconfigure_optimizers  ←  DDPM\nforward  ←  DDPM\nget_input  ←  DDPM\nget_loss  ←  DDPM\nget_v  ←  DDPM\ninit_from_ckpt  ←  DDPM\non_train_batch_end  ←  DDPM\np_losses  ←  DDPM\np_mean_variance  ←  DDPM\npredict_start_from_noise  ←  DDPM\npredict_start_from_z_and_v  ←  DDPM\nq_mean_variance  ←  DDPM\nq_posterior  ←  DDPM\nq_sample  ←  DDPM\nq_sample_respace  ←  DDPM\nregister_schedule  ←  DDPM\nshared_step  ←  DDPM\ntraining_step  ←  DDPM\n\nProject-defined Attributes:"},"StableSR_doc/ldm/models/diffusion/ddpm/class-DDPM/__init__":{"slug":"StableSR_doc/ldm/models/diffusion/ddpm/class-DDPM/__init__","filePath":"StableSR_doc/ldm/models/diffusion/ddpm/class DDPM/__init__.md","title":"__init__","links":["StableSR_doc/pytorch-lightning"],"tags":[],"content":"init 函数介绍\nclass DDPM(pl.LightningModule): # [[pytorch lightning#pllightningmoudule|pl.LightningMoudule]]\n    # classic DDPM with Gaussian diffusion, in image space\n    def __init__(self,\n                 unet_config,\n                 timesteps=1000,\n                 beta_schedule=&quot;linear&quot;,\n                 loss_type=&quot;l2&quot;,\n                 ckpt_path=None,\n                 ignore_keys=[],\n                 load_only_unet=False,\n                 monitor=&quot;val/loss&quot;,\n                 use_ema=True,\n                 first_stage_key=&quot;image&quot;,\n                 image_size=256,\n                 channels=3,\n                 log_every_t=100,\n                 clip_denoised=True,\n                 linear_start=1e-4,\n                 linear_end=2e-2,\n                 cosine_s=8e-3,\n                 given_betas=None,\n                 original_elbo_weight=0.,\n                 v_posterior=0.,  # weight for choosing posterior variance as sigma = (1-v) * beta_tilde + v * beta\n                 l_simple_weight=1.,\n                 conditioning_key=None,\n                 parameterization=&quot;eps&quot;,  # all assuming fixed variance schedules\n                 scheduler_config=None,\n                 use_positional_encodings=False,\n                 learn_logvar=False,\n                 logvar_init=0.,\n                 ):\n        super().__init__() \n        # [[#parameterization|parameterization]]\n        assert parameterization in [&quot;eps&quot;, &quot;x0&quot;, &quot;v&quot;], &#039;currently only supporting &quot;eps&quot; and &quot;x0&quot; and &quot;v&quot;&#039;\n        self.parameterization = parameterization\n        print(f&quot;{self.__class__.__name__}: Running in {self.parameterization}-prediction mode&quot;)\n        self.cond_stage_model = None\n        self.clip_denoised = clip_denoised\n        self.log_every_t = log_every_t\n        self.first_stage_key = first_stage_key\n        self.image_size = image_size  # try conv?\n        self.channels = channels\n        self.use_positional_encodings = use_positional_encodings\n        self.model = DiffusionWrapper(unet_config, conditioning_key) # [[DiffusionWrapper(pl.LightningModule)]]\n        count_params(self.model, verbose=True) # [[#line-45-to-57--ddpm__init__-中模型管理调度器与损失权重部分解析|line 45 to 57 🔧 `DDPM.__init__` 中模型管理、调度器与损失权重部分解析]]\n        self.use_ema = use_ema\n        if self.use_ema:\n            self.model_ema = LitEma(self.model)\n            print(f&quot;Keeping EMAs of {len(list(self.model_ema.buffers()))}.&quot;)\n \n        self.use_scheduler = scheduler_config is not None\n        if self.use_scheduler:\n            self.scheduler_config = scheduler_config\n \n        self.v_posterior = v_posterior\n        self.original_elbo_weight = original_elbo_weight\n        self.l_simple_weight = l_simple_weight\n \n        if monitor is not None: # [[#-pytorch-lightning-中的-monitor-参数简析|📈 PyTorch Lightning 中的 `monitor` 参数简析]]\n            self.monitor = monitor \n        if ckpt_path is not None: # 加载预训练模型\n            self.init_from_ckpt(ckpt_path, ignore_keys=ignore_keys, only_model=load_only_unet) # [[init_from_ckpt]]\n\t\t# [[#line-64-to-end|line 64 to end]]\n\t\t# [[#1-注册调度表beta-schedule|1. 注册调度表（beta schedule）]]\n        self.register_schedule(given_betas=given_betas, beta_schedule=beta_schedule, timesteps=timesteps,\n                               linear_start=linear_start, linear_end=linear_end, cosine_s=cosine_s)\n\t\t# [[#2-设置损失函数类型|2. 设置损失函数类型]]\n        self.loss_type = loss_type\n\t\t# [[#logvar-在-ddpm-扩散模型中的作用与实现|logvar 在 DDPM 扩散模型中的作用与实现]]\n        self.learn_logvar = learn_logvar\n        self.logvar = torch.full(fill_value=logvar_init, size=(self.num_timesteps,))\n        if self.learn_logvar:\n            self.logvar = nn.Parameter(self.logvar, requires_grad=True)\n \nparameterization\n\nparameterization: 扩散模型的预测目标，有三种：\n\n&quot;eps&quot;: 噪声预测（最常用）\n&quot;x0&quot;: 预测原始图像\n&quot;v&quot;: v-pred 方案，平衡两个极端\n\n\n断言限制只支持上述三种模式\n\nline 45 to 57 🔧 DDPM.__init__ 中模型管理、调度器与损失权重部分解析\n这部分代码负责扩散模型训练过程中的几个重要功能组件的配置，包括参数统计、EMA 平滑、调度器设置，以及损失项的加权策略。\n\n🔢 模型参数统计与打印\ncount_params(self.model, verbose=True)\n\n调用 count_params 打印模型参数数量；\nself.model 是之前创建的 DiffusionWrapper（包含 UNet 和条件控制）；\nverbose=True 表示输出详细层级参数统计，有助于模型调试与规模评估。\n\n\n🧮 EMA 模型配置（Exponential Moving Average）\nself.use_ema = use_ema\nif self.use_ema:\n    self.model_ema = LitEma(self.model)\n    print(f&quot;Keeping EMAs of {len(list(self.model_ema.buffers()))}.&quot;)\n\nuse_ema: 控制是否启用 EMA；\n如果启用，将创建 model_ema，用于在训练中对模型参数进行滑动平均；\nEMA 可在推理时提供更稳定的结果（尤其训练后期）；\nLitEma 是一个内部实现的 EMA 工具类（模仿 PyTorch EMA 实现）；\nbuffers() 提供了所有被 EMA 追踪的张量（通常是模型权重）。\n\nPS. EMA简介\n指数移动平均（Exponential Moving Average）也叫权重移动平均（Weighted Moving Average），是一种给予近期数据更高权重的平均方法。\n📈 训练调度器配置（如学习率调度）\nself.use_scheduler = scheduler_config is not None\nif self.use_scheduler:\n    self.scheduler_config = scheduler_config\n\n如果提供了 scheduler_config，则将其保存；\n后续在 configure_optimizers() 方法中会用到该配置；\n可用于定义如余弦退火（cosine annealing）、线性 warmup 等学习率调度策略。\n\n\n⚖️ 损失项权重设置\nself.v_posterior = v_posterior\nself.original_elbo_weight = original_elbo_weight\nself.l_simple_weight = l_simple_weight\n这三项参数控制扩散损失的组成：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n参数名含义v_posterior后验方差的加权控制项。用于设置预测方差的策略。具体计算形式为：σ² = (1 - v) * beta_tilde + v * beta，其中 v 就是这个参数。original_elbo_weight是否加入原始论文中的 ELBO loss 项（常为 0，代表不启用）l_simple_weightL2 或 L1 损失的主权重，用于稳定训练\n\n这部分最终将作用于 get_loss() 或 p_losses() 中的损失函数组合；\n对于不同任务（如图像重建 vs 生成），可以通过调整这些参数来平衡生成质量和保真度。\n\n\n✅ 小结\n这一部分为训练过程提供了必要的配置管理：\n\n模型参数统计有助于可视化规模；\nEMA 管理可提升训练稳定性；\n调度器设置为优化器行为提供了灵活性；\n损失项加权控制生成模型优化目标的侧重点。\n\n📈 PyTorch Lightning 中的 monitor 参数简析\nmonitor 是 PyTorch Lightning 中回调（Callback）机制的一部分，用于指定训练过程中要监控的指标名称，供如 ModelCheckpoint、EarlyStopping 等回调依据该指标执行相应逻辑（如保存模型、提前停止等）。\n详见pytorch_Lightning Callback 机制\n\n✅ 关键用途\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n组件用途ModelCheckpoint保存性能最好的模型EarlyStopping在验证指标停止提升时中止训练\n\n🧩 monitor 的工作流程\n\n\n模型内部记录指标：\nself.log(&quot;val/loss&quot;, val_loss, prog_bar=True)\n\n\n指定 monitor 的回调监听这个指标：\nModelCheckpoint(monitor=&quot;val/loss&quot;, mode=&quot;min&quot;)\n\n\nLightning 自动比较并触发保存 / 停止逻辑。\n\n\n\n⚙️ monitor 示例配置\nfrom pytorch_lightning.callbacks import ModelCheckpoint\n \ncheckpoint = ModelCheckpoint(\n    monitor=&quot;val/psnr&quot;,   # 监听 PSNR 指标\n    mode=&quot;max&quot;,           # 指标越大越好\n    save_top_k=1,\n    filename=&quot;best-psnr&quot;\n)\nfrom pytorch_lightning.callbacks import EarlyStopping\n \nearly_stop = EarlyStopping(\n    monitor=&quot;val/loss&quot;,\n    mode=&quot;min&quot;,\n    patience=5\n)\n\n🧠 说明\n\nmonitor 是一个字符串，必须和 .log(...) 中记录的名字一致；\n不会自动创建指标值，只是引用已有指标；\n和 mode 一起决定何时触发操作（min → 越小越好，max → 越大越好）；\n在模型类中可用 self.monitor 传递给 callback 实现动态配置。\n\n\n✅ 总结\n\nmonitor 是 回调系统监听的指标名称；\n配合 .log(...) 使用；\n决定是否保存模型 / 提前停止；\n本身不计算指标，仅作为引用字段使用。\n\nline 64 to end\n这一部分主要完成了噪声调度与损失配置,具体来说,\n本部分代码完成了扩散过程中的beta调度表构建(即噪声调度)、损失函数类型设定和对数方差的初始化，是 DDPM 建模核心参数的关键配置步骤。\n\n1. 注册调度表（beta schedule）\nself.register_schedule(\n    given_betas=given_betas,\n    beta_schedule=beta_schedule,\n    timesteps=timesteps,\n    linear_start=linear_start,\n    linear_end=linear_end,\n    cosine_s=cosine_s\n)\n\n该函数根据 beta_schedule 的类型（如 “linear” 或 “cosine”）构建扩散过程中的时间步噪声系数表；\n通常会生成如下参数：\n\nbetas：每一步的噪声幅度；\nalphas, alphas_cumprod, sqrt_alphas_cumprod, sqrt_one_minus_alphas_cumprod 等；\n\n\n这些系数会在后续 q_sample, q_posterior, predict_start_from_noise 等函数中使用；\n参数说明：\n\nlinear_start, linear_end: 用于线性 beta 调度起止值；\ncosine_s: 用于调整余弦调度的形状；\ngiven_betas: 若提供，优先使用用户自定义 beta 表。\n\n\n\n\n2. 设置损失函数类型\nself.loss_type = loss_type\n\n控制训练时使用哪种损失：\n\n&quot;l2&quot;（默认）：预测的噪声与真实噪声之间的均方误差；\n&quot;l1&quot;：预测残差的绝对值损失；\n也可能支持其他自定义损失类型，如 perceptual loss、hybrid loss 等；\n\n\n实际使用在 get_loss() 或 p_losses() 中处理。\n\n\n3. 初始化对数方差（log-variance）\nself.learn_logvar = learn_logvar\nself.logvar = torch.full(fill_value=logvar_init, size=(self.num_timesteps,))\nif self.learn_logvar:\n    self.logvar = nn.Parameter(self.logvar, requires_grad=True)\n\nlogvar 是一个长度为 num_timesteps 的张量，表示每一扩散时间步的对数方差；\n如果启用 learn_logvar=True，则将其设为可学习参数（nn.Parameter），允许模型自动优化每一时间步的不确定性；\n如果不启用，logvar 就是一个固定的常量值张量；\n在 get_loss() 中会参与 KL 项或 likelihood 的权重调整。\n\nlogvar 在 DDPM 扩散模型中的作用与实现\nlogvar（对数方差）是扩散模型（如 DDPM）中用于控制训练损失权重和不确定性建模的一个重要变量。在 StableSR 和 DDPM 实现中，它是 diffusion 模型的一部分，而非 encoder 或 decoder 的组成部分。\n\n1. 背景：为何需要 logvar\n扩散模型训练时通常以预测噪声为目标，基本损失形式为(以L2损失为例)：\nL_t = \\left\\| \\varepsilon_{\\text{pred}} - \\varepsilon_{\\text{true}} \\right\\|^2\n为了增强灵活性、稳定性或逼近对数似然，一些变体引入了对数方差 logvar，使得损失函数变为：\nL_t = \\frac{1}{2} \\cdot \\exp(-\\text{logvar}_t) \\cdot \\left\\| \\varepsilon_{\\text{pred}} - \\varepsilon_{\\text{true}} \\right\\|^2 + \\frac{1}{2} \\cdot \\text{logvar}_t\n这相当于使用一个可变的时间步权重项，用于：\n\n控制每一时间步损失的相对重要性；\n模拟高斯似然中的分布不确定性；\n使得模型对某些时间步预测更加稳健。\n\n\n2. 初始化方式\nlogvar 通常被初始化为常数张量：\nself.logvar = torch.full(fill_value=logvar_init, size=(self.num_timesteps,))\n\nlogvar_init: 对数方差的初始值（常为 0）；\nnum_timesteps: 扩散总步数（如 1000）；\n得到形状为 (T,) 的 logvar 张量，其中 T 是时间步数。\n\n若启用可学习方差：\nif self.learn_logvar:\n    self.logvar = nn.Parameter(self.logvar, requires_grad=True)\n则该张量在训练中会自动更新，每一时间步都有不同的可学习不确定性。\n\n3. 使用方式（训练时）\nlogvar 通常参与损失函数定义，在 get_loss() 或 p_losses() 中用作动态权重：\nloss = weighted_mse / torch.exp(self.logvar[t]) + self.logvar[t]\n或更复杂的：\nloss = loss_weight * loss_raw + offset * logvar[t]\n\n4. logvar总结\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n项目内容名称logvar（对数方差）类型Tensor / nn.Parameter维度(num_timesteps,)用途控制不同时间步的损失权重与不确定性建模初始化方法torch.full(size, fill_value)是否可训练由 learn_logvar 参数控制\nlogvar 是一个扩散过程中的权重调节器，尤其在加入 ELBO、VLB 等目标时尤为关键。\n\n总结\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n项目功能说明register_schedule()构造扩散过程中每一步的 beta 参数，用于控制加噪过程loss_type决定训练时的损失函数类型，如 L2 或 L1learn_logvar 和 logvar控制是否学习每个时间步的对数方差，以适配不同的不确定性建模策略\n这些设置构成了扩散模型训练阶段的核心数学基础。"},"StableSR_doc/ldm/models/diffusion/ddpm/class-DDPM/forward":{"slug":"StableSR_doc/ldm/models/diffusion/ddpm/class-DDPM/forward","filePath":"StableSR_doc/ldm/models/diffusion/ddpm/class DDPM/forward.md","title":"forward","links":[],"tags":[],"content":""},"StableSR_doc/ldm/models/diffusion/ddpm/class-DDPM/init_from_ckpt":{"slug":"StableSR_doc/ldm/models/diffusion/ddpm/class-DDPM/init_from_ckpt","filePath":"StableSR_doc/ldm/models/diffusion/ddpm/class DDPM/init_from_ckpt.md","title":"init_from_ckpt","links":[],"tags":[],"content":"    def init_from_ckpt(self, path, ignore_keys=list(), only_model=False):\n        sd = torch.load(path, map_location=&quot;cpu&quot;)\n        if &quot;state_dict&quot; in list(sd.keys()):\n            sd = sd[&quot;state_dict&quot;]\n        keys = list(sd.keys())\n        for k in keys:\n            for ik in ignore_keys:\n                if k.startswith(ik):\n                    print(&quot;Deleting key {} from state_dict.&quot;.format(k))\n                    del sd[k]\n        missing, unexpected = self.load_state_dict(sd, strict=False) if not only_model else self.model.load_state_dict(\n            sd, strict=False)\n        print(&#039;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&#039;)\n        print(f&quot;Restored from {path} with {len(missing)} missing and {len(unexpected)} unexpected keys&quot;)\n        if len(missing) &gt; 0:\n            print(f&quot;Missing Keys: {missing}&quot;)\n        if len(unexpected) &gt; 0:\n            print(f&quot;Unexpected Keys: {unexpected}&quot;)\ninit_from_ckpt(path, ignore_keys=list(), only_model=False) 函数解析\n该函数用于从 checkpoint 文件中加载模型参数，可选择只加载 UNet（self.model），或加载整个 DDPM 模型本身。支持忽略部分参数键名，适用于微调、迁移学习等场景。\n\n函数签名\ndef init_from_ckpt(self, path, ignore_keys=list(), only_model=False):\n\npath: checkpoint 文件路径（通常为 .ckpt 或 .pth）\nignore_keys: 字符串列表，指定哪些 key 应从 state_dict 中排除（常用于忽略不兼容的模块）\nonly_model: 若为 True，则只加载 self.model 的参数，不加载整个 DDPM 类结构（适用于仅更新 UNet 时）\n\n\n1. 加载 checkpoint 字典\nsd = torch.load(path, map_location=&quot;cpu&quot;)\nif &quot;state_dict&quot; in list(sd.keys()):\n    sd = sd[&quot;state_dict&quot;]\n\n使用 torch.load 加载权重；\n有些 checkpoint 是通过 PyTorch Lightning 保存的，外层是个字典，内部的模型权重位于 state_dict 键下；\n这一步兼容这两种结构。\n\n\n2. 根据 ignore_keys 删除不需要的参数\nkeys = list(sd.keys())\nfor k in keys:\n    for ik in ignore_keys:\n        if k.startswith(ik):\n            print(&quot;Deleting key {} from state_dict.&quot;.format(k))\n            del sd[k]\n\n遍历所有参数名（key），如果以 ik 中任一字符串开头，则删除该 key；\n典型用途：跳过 cond_stage_model, model_ema, scheduler 等与当前任务无关的部分。\n\n\n3. 加载权重到模型中\nmissing, unexpected = self.load_state_dict(sd, strict=False) if not only_model else self.model.load_state_dict(sd, strict=False)\n\nstrict=False：允许 checkpoint 和当前模型结构不完全一致（否则会报错）；\nmissing：当前模型中存在而 checkpoint 中没有的 key；\nunexpected：checkpoint 中存在但当前模型没有的 key；\n根据 only_model 决定加载整个 DDPM 模型或仅加载其 self.model（通常是 UNet）。\n\n\n4. 打印加载结果\nprint(&#039;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&#039;)\nprint(f&quot;Restored from {path} with {len(missing)} missing and {len(unexpected)} unexpected keys&quot;)\nif len(missing) &gt; 0:\n    print(f&quot;Missing Keys: {missing}&quot;)\nif len(unexpected) &gt; 0:\n    print(f&quot;Unexpected Keys: {unexpected}&quot;)\n\n清晰地汇报恢复情况；\n若 missing/unexpected 过多，可能说明模型结构不匹配，需要调整配置或 ignore_keys。\n\n\n总结表格\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n参数作用path指定加载的 checkpoint 文件路径ignore_keys忽略掉具有特定前缀的参数键（如 model_ema）only_model是否只加载 self.model（通常为 UNet）strict=False宽松加载，不要求结构完全一致missing / unexpected分别记录缺失和多余的参数 key 名\n此函数广泛用于 StableSR/LDMS/LatentDiffusion 的预训练模型加载与微调流程中，推荐配合 YAML 配置与 callback 一起使用。"},"StableSR_doc/ldm/models/diffusion/ddpm/disabled_train":{"slug":"StableSR_doc/ldm/models/diffusion/ddpm/disabled_train","filePath":"StableSR_doc/ldm/models/diffusion/ddpm/disabled_train.md","title":"disabled_train","links":[],"tags":[],"content":""},"StableSR_doc/ldm/models/diffusion/ddpm/space_timesteps":{"slug":"StableSR_doc/ldm/models/diffusion/ddpm/space_timesteps","filePath":"StableSR_doc/ldm/models/diffusion/ddpm/space_timesteps.md","title":"space_timesteps","links":[],"tags":[],"content":""},"StableSR_doc/ldm/models/diffusion/ddpm/torch2img":{"slug":"StableSR_doc/ldm/models/diffusion/ddpm/torch2img","filePath":"StableSR_doc/ldm/models/diffusion/ddpm/torch2img.md","title":"torch2img","links":[],"tags":[],"content":"def torch2img(input):\n    input_ = input[0]\n    input_ = input_.permute(1,2,0)\n    input_ = input_.data.cpu().numpy()\n    input_ = (input_ + 1.0) / 2\n    cv2.imwrite(&#039;./test.png&#039;, input_[:,:,::-1]*255.0)"},"StableSR_doc/ldm/models/diffusion/ddpm/uniform_on_device":{"slug":"StableSR_doc/ldm/models/diffusion/ddpm/uniform_on_device","filePath":"StableSR_doc/ldm/models/diffusion/ddpm/uniform_on_device.md","title":"uniform_on_device","links":[],"tags":[],"content":""},"StableSR_doc/ldm/models/diffusion/ddpm/visualize_fea":{"slug":"StableSR_doc/ldm/models/diffusion/ddpm/visualize_fea","filePath":"StableSR_doc/ldm/models/diffusion/ddpm/visualize_fea.md","title":"visualize_fea","links":[],"tags":[],"content":""},"StableSR_doc/ldm/modules/diffusionmodules/openaimodel/Module_info":{"slug":"StableSR_doc/ldm/modules/diffusionmodules/openaimodel/Module_info","filePath":"StableSR_doc/ldm/modules/diffusionmodules/openaimodel/Module_info.md","title":"Module_info","links":["convert_module_to_f16","convert_module_to_f32","exists","cal_fea_cossim","count_flops_attn","AttentionPool2d","TimestepBlock","TimestepBlockDual","TimestepBlock3cond","TimestepEmbedSequential","Upsample","TransposedUpsample","Downsample","ResBlock","ResBlockDual","AttentionBlock","QKVAttentionLegacy","QKVAttention","UNetModel","StableSR_doc/ldm/modules/diffusionmodules/openaimodel/class-UNetModelDualcondV2/UNetModelDualcondV2","EncoderUNetModelWT"],"tags":[],"content":"ldm/modules/diffusionmodules/openaimodel.py\n\n\n                  \n                  UML图解：openaimodels.py \n                  \n                \n\n\n\n\n\n\nFunctions\n\nconvert_module_to_f16\nconvert_module_to_f32\nexists\ncal_fea_cossim\ncount_flops_attn\n\nClasses\n\nAttentionPool2d\nTimestepBlock\nTimestepBlockDual\nTimestepBlock3cond\nTimestepEmbedSequential\nUpsample\nTransposedUpsample\nDownsample\nResBlock\nResBlockDual\nAttentionBlock\nQKVAttentionLegacy\nQKVAttention\nUNetModel\nUNetModelDualcondV2\nEncoderUNetModelWT\n"},"StableSR_doc/ldm/modules/diffusionmodules/openaimodel/class-UNetModelDualcondV2/UNetModelDualcondV2":{"slug":"StableSR_doc/ldm/modules/diffusionmodules/openaimodel/class-UNetModelDualcondV2/UNetModelDualcondV2","filePath":"StableSR_doc/ldm/modules/diffusionmodules/openaimodel/class UNetModelDualcondV2/UNetModelDualcondV2.md","title":"UNetModelDualcondV2","links":["StableSR_doc/ldm/modules/diffusionmodules/openaimodel/class-UNetModelDualcondV2/attribute","StableSR_doc/ldm/modules/diffusionmodules/openaimodel/class-UNetModelDualcondV2/UNetModelDualcondV2","StableSR_doc/ldm/modules/diffusionmodules/openaimodel/class-UNetModelDualcondV2/convert_to_fp16","StableSR_doc/ldm/modules/diffusionmodules/openaimodel/class-UNetModelDualcondV2/convert_to_fp32","forward"],"tags":[],"content":"Class: UNetModelDualcondV2\nInheritance Tree (MRO):\n\nUNetModelDualcondV2\nnn.Module\nobject\n\nInstance Attributes (from self.xxx assignments):\n\nimage_size (defined in: init)\nin_channels (defined in: init)\nmodel_channels (defined in: init)\nout_channels (defined in: init)\nattention_resolutions (defined in: init)\ndropout (defined in: init)\nchannel_mult (defined in: init)\nconv_resample (defined in: init)\nnum_classes (defined in: init)\nuse_checkpoint (defined in: init)\ndtype (defined in: init)\nnum_heads (defined in: init)\nnum_head_channels (defined in: init)\nnum_heads_upsample (defined in: init)\npredict_codebook_ids (defined in: init)\ntime_embed (defined in: init)\ninput_blocks (defined in: init)\n_feature_size (defined in: init)\nmiddle_block (defined in: init)\noutput_blocks (defined in: init)\nout (defined in: init)\nnum_res_blocks (defined in: init, init)\nid_predictor (defined in: init)\nlabel_emb (defined in: init, init)\nattribute\n\nProject-defined Methods:\n\n[[init]]  ←  UNetModelDualcondV2\nconvert_to_fp16  ←  UNetModelDualcondV2\nconvert_to_fp32  ←  UNetModelDualcondV2\nforward  ←  UNetModelDualcondV2\n\nProject-defined Class Attributes:"},"StableSR_doc/ldm/modules/diffusionmodules/openaimodel/class-UNetModelDualcondV2/__init__":{"slug":"StableSR_doc/ldm/modules/diffusionmodules/openaimodel/class-UNetModelDualcondV2/__init__","filePath":"StableSR_doc/ldm/modules/diffusionmodules/openaimodel/class UNetModelDualcondV2/__init__.md","title":"__init__","links":[],"tags":[],"content":"init\n    def __init__(\n        self,\n        image_size,\n        in_channels,\n        model_channels,\n        out_channels,\n        num_res_blocks,\n        attention_resolutions,\n        dropout=0,\n        channel_mult=(1, 2, 4, 8),\n        conv_resample=True,\n        dims=2,\n        num_classes=None,\n        use_checkpoint=False,\n        use_fp16=False,\n        num_heads=-1,\n        num_head_channels=-1,\n        num_heads_upsample=-1,\n        use_scale_shift_norm=False,\n        resblock_updown=False,\n        use_new_attention_order=False,\n        use_spatial_transformer=False,    # custom transformer support\n        transformer_depth=1,              # custom transformer support\n        context_dim=None,                 # custom transformer support\n        n_embed=None,                     # custom support for prediction of discrete ids into codebook of first stage vq model\n        legacy=True,\n        disable_self_attentions=None,\n        num_attention_blocks=None,\n        disable_middle_self_attn=False,\n        use_linear_in_transformer=False,\n        semb_channels=None\n    ):\n        super().__init__()\n        if use_spatial_transformer:\n            assert context_dim is not None, &#039;Fool!! You forgot to include the dimension of your cross-attention conditioning...&#039;\n \n        if context_dim is not None:\n            assert use_spatial_transformer, &#039;Fool!! You forgot to use the spatial transformer for your cross-attention conditioning...&#039;\n            from omegaconf.listconfig import ListConfig\n            if type(context_dim) == ListConfig:\n                context_dim = list(context_dim)\n \n        if num_heads_upsample == -1:\n            num_heads_upsample = num_heads\n \n        if num_heads == -1:\n            assert num_head_channels != -1, &#039;Either num_heads or num_head_channels has to be set&#039;\n \n        if num_head_channels == -1:\n            assert num_heads != -1, &#039;Either num_heads or num_head_channels has to be set&#039;\n \n        self.image_size = image_size\n        self.in_channels = in_channels\n        self.model_channels = model_channels\n        self.out_channels = out_channels\n        if isinstance(num_res_blocks, int): # [[#residual-block|residual block]]\n            self.num_res_blocks = len(channel_mult) * [num_res_blocks]\n        else:\n            if len(num_res_blocks) != len(channel_mult):\n                raise ValueError(&quot;provide num_res_blocks either as an int (globally constant) or &quot;\n                                 &quot;as a list/tuple (per-level) with the same length as channel_mult&quot;)\n            self.num_res_blocks = num_res_blocks\n        if disable_self_attentions is not None: # [[#attention-block|attention block]]\n            # should be a list of booleans, indicating whether to disable self-attention in TransformerBlocks or not\n            assert len(disable_self_attentions) == len(channel_mult)\n        if num_attention_blocks is not None:\n            assert len(num_attention_blocks) == len(self.num_res_blocks)\n            assert all(map(lambda i: self.num_res_blocks[i] &gt;= num_attention_blocks[i], range(len(num_attention_blocks))))\n            print(f&quot;Constructor of UNetModel received num_attention_blocks={num_attention_blocks}. &quot;\n                  f&quot;This option has LESS priority than attention_resolutions {attention_resolutions}, &quot;\n                  f&quot;i.e., in cases where num_attention_blocks[i] &gt; 0 but 2**i not in attention_resolutions, &quot;\n                  f&quot;attention will still not be set.&quot;)\n\t\t# [[#unet-关键参数配置|UNet 关键参数配置]] \n        self.attention_resolutions = attention_resolutions\n        self.dropout = dropout\n        self.channel_mult = channel_mult\n        self.conv_resample = conv_resample\n        self.num_classes = num_classes\n        self.use_checkpoint = use_checkpoint\n        self.dtype = th.float16 if use_fp16 else th.float32\n        self.num_heads = num_heads\n        self.num_head_channels = num_head_channels\n        self.num_heads_upsample = num_heads_upsample\n        self.predict_codebook_ids = n_embed is not None\n\t\t# [[#time_embed|time_embed]]\n        time_embed_dim = model_channels * 4\n        self.time_embed = nn.Sequential(\n            linear(model_channels, time_embed_dim),\n            nn.SiLU(),\n            linear(time_embed_dim, time_embed_dim),\n        )\n\t\t# [[#类别条件class-conditional机制在-unet-中的实现|类别条件（Class-Conditional）机制在 UNet 中的实现]]\n        if self.num_classes is not None:\n            if isinstance(self.num_classes, int):\n                self.label_emb = nn.Embedding(num_classes, time_embed_dim)\n            elif self.num_classes == &quot;continuous&quot;:\n                print(&quot;setting up linear c_adm embedding layer&quot;)\n                self.label_emb = nn.Linear(1, time_embed_dim)\n            else:\n                raise ValueError()\n \n        self.input_blocks = nn.ModuleList(\n            [\n                TimestepEmbedSequential(\n                    conv_nd(dims, in_channels, model_channels, 3, padding=1)\n                )\n            ]\n        )\n        self._feature_size = model_channels\n        input_block_chans = [model_channels]\n        ch = model_channels\n        ds = 1\n        for level, mult in enumerate(channel_mult):\n            for nr in range(self.num_res_blocks[level]):\n                layers = [\n                    ResBlockDual(\n                        ch,\n                        time_embed_dim,\n                        dropout,\n                        semb_channels=semb_channels,\n                        out_channels=mult * model_channels,\n                        dims=dims,\n                        use_checkpoint=use_checkpoint,\n                        use_scale_shift_norm=use_scale_shift_norm,\n                    )\n                ]\n                ch = mult * model_channels\n                if ds in attention_resolutions:\n                    if num_head_channels == -1:\n                        dim_head = ch // num_heads\n                    else:\n                        num_heads = ch // num_head_channels\n                        dim_head = num_head_channels\n                    if legacy:\n                        #num_heads = 1\n                        dim_head = ch // num_heads if use_spatial_transformer else num_head_channels\n                    if exists(disable_self_attentions):\n                        disabled_sa = disable_self_attentions[level]\n                    else:\n                        disabled_sa = False\n \n                    if not exists(num_attention_blocks) or nr &lt; num_attention_blocks[level]:\n                        layers.append(\n                            AttentionBlock(\n                                ch,\n                                use_checkpoint=use_checkpoint,\n                                num_heads=num_heads,\n                                num_head_channels=dim_head,\n                                use_new_attention_order=use_new_attention_order,\n                            ) if not use_spatial_transformer else SpatialTransformerV2(\n                                ch, num_heads, dim_head, depth=transformer_depth, context_dim=context_dim,\n                                disable_self_attn=disabled_sa, use_linear=use_linear_in_transformer,\n                                use_checkpoint=use_checkpoint\n                            )\n                        )\n                self.input_blocks.append(TimestepEmbedSequential(*layers))\n                self._feature_size += ch\n                input_block_chans.append(ch)\n            if level != len(channel_mult) - 1:\n                out_ch = ch\n                self.input_blocks.append(\n                    TimestepEmbedSequential(\n                        ResBlockDual(\n                            ch,\n                            time_embed_dim,\n                            dropout,\n                            semb_channels=semb_channels,\n                            out_channels=out_ch,\n                            dims=dims,\n                            use_checkpoint=use_checkpoint,\n                            use_scale_shift_norm=use_scale_shift_norm,\n                            down=True,\n                        )\n                        if resblock_updown\n                        else Downsample(\n                            ch, conv_resample, dims=dims, out_channels=out_ch\n                        )\n                    )\n                )\n                ch = out_ch\n                input_block_chans.append(ch)\n                ds *= 2\n                self._feature_size += ch\n\t\t# [[#attention_head|attention_head]] \n        if num_head_channels == -1:\n            dim_head = ch // num_heads\n        else:\n            num_heads = ch // num_head_channels\n            dim_head = num_head_channels\n        if legacy:\n            #num_heads = 1\n            dim_head = ch // num_heads if use_spatial_transformer else num_head_channels\n        self.middle_block = TimestepEmbedSequential(\n            ResBlockDual(\n                ch,\n                time_embed_dim,\n                dropout,\n                semb_channels=semb_channels,\n                dims=dims,\n                use_checkpoint=use_checkpoint,\n                use_scale_shift_norm=use_scale_shift_norm,\n            ),\n            AttentionBlock(\n                ch,\n                use_checkpoint=use_checkpoint,\n                num_heads=num_heads,\n                num_head_channels=dim_head,\n                use_new_attention_order=use_new_attention_order,\n            ) if not use_spatial_transformer else SpatialTransformerV2(  # always uses a self-attn\n                            ch, num_heads, dim_head, depth=transformer_depth, context_dim=context_dim,\n                            disable_self_attn=disable_middle_self_attn, use_linear=use_linear_in_transformer,\n                            use_checkpoint=use_checkpoint\n                        ),\n            ResBlockDual(\n                ch,\n                time_embed_dim,\n                dropout,\n                semb_channels=semb_channels,\n                dims=dims,\n                use_checkpoint=use_checkpoint,\n                use_scale_shift_norm=use_scale_shift_norm,\n            ),\n        )\n        self._feature_size += ch\n \n        self.output_blocks = nn.ModuleList([])\n        for level, mult in list(enumerate(channel_mult))[::-1]:\n            for i in range(self.num_res_blocks[level] + 1):\n                ich = input_block_chans.pop()\n                layers = [\n                    ResBlockDual(\n                        ch + ich,\n                        time_embed_dim,\n                        dropout,\n                        semb_channels=semb_channels,\n                        out_channels=model_channels * mult,\n                        dims=dims,\n                        use_checkpoint=use_checkpoint,\n                        use_scale_shift_norm=use_scale_shift_norm,\n                    )\n                ]\n                ch = model_channels * mult\n                if ds in attention_resolutions:\n                    if num_head_channels == -1:\n                        dim_head = ch // num_heads\n                    else:\n                        num_heads = ch // num_head_channels\n                        dim_head = num_head_channels\n                    if legacy:\n                        #num_heads = 1\n                        dim_head = ch // num_heads if use_spatial_transformer else num_head_channels\n                    if exists(disable_self_attentions):\n                        disabled_sa = disable_self_attentions[level]\n                    else:\n                        disabled_sa = False\n \n                    if not exists(num_attention_blocks) or i &lt; num_attention_blocks[level]:\n                        layers.append(\n                            AttentionBlock(\n                                ch,\n                                use_checkpoint=use_checkpoint,\n                                num_heads=num_heads_upsample,\n                                num_head_channels=dim_head,\n                                use_new_attention_order=use_new_attention_order,\n                            ) if not use_spatial_transformer else SpatialTransformerV2(\n                                ch, num_heads, dim_head, depth=transformer_depth, context_dim=context_dim,\n                                disable_self_attn=disabled_sa, use_linear=use_linear_in_transformer,\n                                use_checkpoint=use_checkpoint\n                            )\n                        )\n                if level and i == self.num_res_blocks[level]:\n                    out_ch = ch\n                    layers.append(\n                        ResBlockDual(\n                            ch,\n                            time_embed_dim,\n                            dropout,\n                            semb_channels=semb_channels,\n                            out_channels=out_ch,\n                            dims=dims,\n                            use_checkpoint=use_checkpoint,\n                            use_scale_shift_norm=use_scale_shift_norm,\n                            up=True,\n                        )\n                        if resblock_updown\n                        else Upsample(ch, conv_resample, dims=dims, out_channels=out_ch)\n                    )\n                    ds //= 2\n                self.output_blocks.append(TimestepEmbedSequential(*layers))\n                self._feature_size += ch\n \n        self.out = nn.Sequential(\n            normalization(ch),\n            nn.SiLU(),\n            zero_module(conv_nd(dims, model_channels, out_channels, 3, padding=1)),\n        )\n        if self.predict_codebook_ids:\n            self.id_predictor = nn.Sequential(\n            normalization(ch),\n            conv_nd(dims, model_channels, n_embed, 1),\n            #nn.LogSoftmax(dim=1)  # change to cross_entropy and produce non-normalized logits\n        )\nattention_head\n在使用多头注意力模块（如 AttentionBlock 或 SpatialTransformerV2）时，需要指定下列两个参数之一：\n\nnum_heads：注意力头的数量（例如 8 表示使用 8 个并行注意力分支）\nnum_head_channels：每个注意力头的通道宽度（例如 64 表示每个头维度为 64）\n\n二者的关系\n二者满足如下关系：\n\\mathrm{num\\_heads} \\times \\mathrm{num\\_head\\_channels} \\leq \\mathrm{total\\_channels}\n你只需要显式指定一个，另一个可以自动推导。\n参数检查逻辑\n源代码中的校验逻辑如下：\nif num_heads == -1:\n    assert num_head_channels != -1, &#039;Either num_heads or num_head_channels has to be set&#039;\n \nif num_head_channels == -1:\n    assert num_heads != -1, &#039;Either num_heads or num_head_channels has to be set&#039;\n也就是说，必须至少指定一个参数，否则将抛出错误。\n️ 注意事项\n\n若 total_channels 无法整除指定参数，可能导致计算出错或维度不一致；\n两者都指定时要确保一致性，即：num_heads * num_head_channels == total_channels；\n推荐做法是：设置你想控制的那一个，留另一个自动计算。\n\n示例\n假设当前层通道数为 320：\n\n若设置 num_heads=8，则 num_head_channels=320 // 8 = 40\n若设置 num_head_channels=64，则 num_heads=320 // 64 = 5\n\n# 推荐示例\nattention_block = AttentionBlock(\n    channels=320,\n    num_heads=8,\n    num_head_channels=-1,  # 自动计算为 40\n)\n \n# 或者\nattention_block = AttentionBlock(\n    channels=320,\n    num_heads=-1,\n    num_head_channels=64,  # 自动计算为 5 heads\n)\nresidual block\n这段代码用于配置UNet的各层中残差块（residual block）的数量。\n        if isinstance(num_res_blocks, int):\n            self.num_res_blocks = len(channel_mult) * [num_res_blocks]\n如果传入的num_res_blocks参数是单一整数，那么每一层将都使用这个数量的残差块。\n        else:\n            if len(num_res_blocks) != len(channel_mult):\n                raise ValueError(&quot;provide num_res_blocks either as an int (globally constant) or &quot;\n                                 &quot;as a list/tuple (per-level) with the same length as channel_mult&quot;)\n            self.num_res_blocks = num_res_blocks\n如果传入的num_res_blocks参数不是整数，那么期望为列表或其他包含整数序列的有序容器，且该容器的长度应和channel_mult的长度（也即UNet的单测深度）相同。\nattention block\n这段代码配置了attention block（自注意力机制）部分的启用情况。\n注意：在StableSR中，自注意力和交叉注意力都是通过统一的transformer模块实现的，其自注意力机制并不是SR3那样传统的dot-product attention。StableSR中，该transformer可以选择是否开启自注意力部分，但默认必须开启交叉注意力以为UNet提供必要的生成条件。\n        if disable_self_attentions is not None:\n            # should be a list of booleans, indicating whether to disable self-attention in TransformerBlocks or not\n            assert len(disable_self_attentions) == len(channel_mult)\ndisable_self_attentions参数期望是None或者与channel_mult长度相同的布尔数组，用于控制UNet内各层是否开启自注意力模块。None表示全部开启，布尔数组则按照其真值控制。\n        if num_attention_blocks is not None:\n            assert len(num_attention_blocks) == len(self.num_res_blocks)\n            assert all(map(lambda i: self.num_res_blocks[i] &gt;= num_attention_blocks[i], range(len(num_attention_blocks))))\n            print(f&quot;Constructor of UNetModel received num_attention_blocks={num_attention_blocks}. &quot;\n                  f&quot;This option has LESS priority than attention_resolutions {attention_resolutions}, &quot;\n                  f&quot;i.e., in cases where num_attention_blocks[i] &gt; 0 but 2**i not in attention_resolutions, &quot;\n                  f&quot;attention will still not be set.&quot;)\n\n\n控制 每一层中最多能插入多少个 attention 模块；\n\n\n不是层级数，而是实际 ResBlock 数量对 attention 的数量限制；\n\n\n必须匹配结构深度，即 num_attention_blocks[i] ≤ num_res_blocks[i]。\n\n\n打印语句更加清晰地表明了配置参数的优先级关系\n\n\n最终是否插入 attention block 的判定，首先看 attention_resolutions，然后才看 num_attention_blocks。\n\n\n也就是说：\n\n\n你可以设置 num_attention_blocks[i] = 1 表示“最多插入 1 个”；\n\n\n但如果 2**i 不在 attention_resolutions（例如 16, 32）中，那 attention 就不会插入；\n\n\n换句话说：你只表达了“允许插入”，插不插要由 attention_resolutions 决定。\n\n\n\n\nUNet 关键参数配置\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n参数说明attention_resolutions控制在哪些分辨率下插入 attention（如 16、32）dropoutdropout 概率，用于 regularizationchannel_mult每一层通道数是基通道数（model_channels）的几倍conv_resample是否使用卷积实现下/上采样（True 为可学习）num_classes是否使用 class-conditional 条件（如标签）use_checkpoint是否使用 gradient checkpointing 减少显存dtype网络中使用的精度（float16 或 float32）num_heads / num_head_channelsAttention 中的 head 设置num_heads_upsample上采样阶段的 head 数predict_codebook_ids是否输出 codebook token（即是否为 VQGAN decoder）\ntime_embed\n注意：这是将时间信息引入UNet的核心途径。\n        time_embed_dim = model_channels * 4\n        self.time_embed = nn.Sequential(\n            linear(model_channels, time_embed_dim),\n            nn.SiLU(),\n            linear(time_embed_dim, time_embed_dim),\n        )\n这段代码构造了一个简单的 MLP（多层感知机），将原始的 timestep embedding 映射成供 ResBlock 使用的时间条件向量。\n\n输入维度：model_channels（例如 320）\n输出维度：time_embed_dim = 4 × model_channels（例如 1280）\n激活函数：SiLU（即 Swish 激活，效果比 ReLU 更平滑）\n\nTODO:time_embed只是time aware encoder的一个模块，在进入他之前会有一个原始的time embeding（可能是正余弦位置编码），将编码结果输入这个time_embed的MLP来进一步添加可学习性，其输出用于调节残差块的工作模式。以上内容应该在后续代码和forward函数中有更多的体现。\n类别条件（Class-Conditional）机制在 UNet 中的实现\n一、什么是类别条件？\n在扩散模型（如 DDPM、StableSR、LDM）中，类别条件是一种用于引导图像生成方向的辅助信息。通过在每一步扩散中注入类别标签，模型能够学习：\n\n如何在第 t 步生成属于类别 y 的图像特征。\n\n该机制适用于分类引导图像生成，例如：\n\n生成一张“猫”而不是“狗”的图像\n合成特定类型的建筑、车辆或自然场景图像\n条件控制任务，如 super-resolution with category hints\n\n\n二、实现方式\n在 UNetModelDualcondV2 中，类别条件通过以下结构实现：\nif isinstance(self.num_classes, int):\n    self.label_emb = nn.Embedding(num_classes, time_embed_dim)\nelif self.num_classes == &quot;continuous&quot;:\n    self.label_emb = nn.Linear(1, time_embed_dim)\n支持两种类别条件格式：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n类型含义模块输入形式离散类别明确类别标签，如 0~9nn.Embeddingy ∈ {0, ..., num_classes}连续变量属性值、实数条件nn.Lineary ∈ ℝ（形如 [B, 1]）\n嵌入后将与时间嵌入相加，用于调节每个 ResBlock：\nemb = time_embed(t) + label_emb(y)\n\n三、类别条件的来源\n类别条件 不是自动生成的，而是 由用户显式提供：\n\n对于分类任务：标签 y 来自数据集；\n对于连续条件任务：如模糊程度、温度等数值，由用户设定；\n不使用类别条件时，设置 num_classes = None 即可关闭。\n\n\n四、关闭类别条件的方法\n只需在初始化模型时设定：\nnum_classes = None\n即可完全关闭类别条件路径：\n\n不构建 label_emb\n时间嵌入 emb = time_embed(t) 不再包含类别信息\n模型仅依赖时间步与其他条件（如结构条件）\n\n\n五、技术意义\n类别条件扩展了扩散模型的能力，使其支持：\n\n分类控制生成（class-conditional generation）\n多模态控制结构（如 time + class + structure）\n通用控制器设计（支持标签、模态、风格等注入）\n\n这一机制也为后续加入 cross-attention 等结构提供了条件输入的通道。"},"StableSR_doc/ldm/modules/diffusionmodules/openaimodel/class-UNetModelDualcondV2/attribute":{"slug":"StableSR_doc/ldm/modules/diffusionmodules/openaimodel/class-UNetModelDualcondV2/attribute","filePath":"StableSR_doc/ldm/modules/diffusionmodules/openaimodel/class UNetModelDualcondV2/attribute.md","title":"attribute","links":[],"tags":[],"content":"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n参数作用与说明image_size输入图像的大小，用于构建 U-Net 结构的层级，一般用于输入前的尺寸校验或推断网络深度。in_channels输入图像的通道数，例如 RGB 为 3，灰度图为 1。model_channels模型的基础通道数，决定了第一层特征图的宽度。U-Net 的通道数通常是 model_channels * mult 形式增长。out_channels输出图像的通道数，通常与 in_channels 相同，例如 3 通道图像。也可以是 codebook 大小（用于 VQ）。num_res_blocks每个 downsample/upsample 层使用的 ResBlock 个数。可为 int（每层相同），也可为 list（不同层不同数量）。attention_resolutions指定在哪些 resolution 下插入 attention 模块。例如包含 4 表示在 1/4 尺度特征图上加入 self-attn 或 cross-attn。dropoutDropout 概率，控制网络的随机失活程度。用于提升泛化能力。channel_multU-Net 每个层级的通道扩展倍率。例如 (1, 2, 4, 8) 表示第4层为基通道的8倍。conv_resample是否使用卷积方式进行上下采样（如 PixelShuffle、ConvTranspose），否则使用简单插值。dims输入数据维度，2 表示 2D 图像，1 或 3 则用于序列或体数据。num_classes分类条件数量。如果设置为整数，则模型是 class-conditional；支持 int 或 &quot;continuous&quot;。use_checkpoint是否开启 gradient checkpointing（反向传播时节省内存）。会牺牲速度换空间。use_fp16是否使用 float16 精度推理，主要用于减少显存。num_heads注意力机制中 head 的数量，如果为 -1，则根据 num_head_channels 自动计算。num_head_channels每个 attention head 的维度，优先级高于 num_heads。二者需至少设置一个。num_heads_upsample用于上采样阶段的 attention head 数，默认与 num_heads 一致。use_scale_shift_norm是否在 ResBlock 中使用 FiLM 风格的 scale-shift 归一化（用于条件建模）。resblock_updown是否使用残差块进行上/下采样，否则使用 Downsample/Upsample 模块。use_new_attention_order控制 attention 顺序的实验性设置。默认为 False。use_spatial_transformer是否使用 Transformer 替代原生 AttentionBlock。开启后需设置 context_dim。transformer_depthTransformer 模块的堆叠深度（层数）。context_dimCross-Attention 中 context（如文本、图像编码）的维度，必须与 transformer 配套。n_embed如果不为 None，表示该模型用于预测 codebook 的离散 token（如 VQ-VAE / VQGAN 场景）。legacy控制是否使用 legacy 的 attention 维度设置逻辑。True 表示保持旧实现兼容性。disable_self_attentions是否禁用某些层中的 self-attn。为一个布尔列表，长度等于 channel_mult。num_attention_blocks控制每个层的 attention block 数量。优先级低于 attention_resolutions。disable_middle_self_attn是否禁用 U-Net 最底部（中间层）的 self-attn。use_linear_in_transformer是否在 transformer 中使用 Linear 形式的投影层。semb_channels结构条件通道数（例如结构图、小波子带等），会传入 ResBlockDual 进行时间/结构融合。\n与 Time-Aware Encoder 的关系\n作为 Time-Aware Encoder，这些参数中以下几项起关键作用：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n参数Time-Aware Encoder 中的意义t_emb（隐含于 time_embed）为每个时刻 t 生成时间嵌入，与结构一起参与生成（类似时间条件扩散）semb_channels支持结构条件的通道输入（如小波子带、深度图、边缘图等），通过 ResBlockDual 融合进入主干网络context_dim + use_spatial_transformer实现 Cross-Attention，用于将文本/图像上下文信息融合进特征流use_checkpoint + use_fp16控制训练时的计算效率，适合大规模时间序列训练"},"StableSR_doc/ldm/modules/diffusionmodules/openaimodel/class-UNetModelDualcondV2/convert_to_fp16":{"slug":"StableSR_doc/ldm/modules/diffusionmodules/openaimodel/class-UNetModelDualcondV2/convert_to_fp16","filePath":"StableSR_doc/ldm/modules/diffusionmodules/openaimodel/class UNetModelDualcondV2/convert_to_fp16.md","title":"convert_to_fp16","links":[],"tags":[],"content":""},"StableSR_doc/ldm/modules/diffusionmodules/openaimodel/class-UNetModelDualcondV2/convert_to_fp32":{"slug":"StableSR_doc/ldm/modules/diffusionmodules/openaimodel/class-UNetModelDualcondV2/convert_to_fp32","filePath":"StableSR_doc/ldm/modules/diffusionmodules/openaimodel/class UNetModelDualcondV2/convert_to_fp32.md","title":"convert_to_fp32","links":[],"tags":[],"content":""},"StableSR_doc/ldm/modules/diffusionmodules/openaimodel/class-UNetModelDualcondV2/forward":{"slug":"StableSR_doc/ldm/modules/diffusionmodules/openaimodel/class-UNetModelDualcondV2/forward","filePath":"StableSR_doc/ldm/modules/diffusionmodules/openaimodel/class UNetModelDualcondV2/forward.md","title":"forward","links":[],"tags":[],"content":""},"StableSR_doc/ldm/utils/Module_info":{"slug":"StableSR_doc/ldm/utils/Module_info","filePath":"StableSR_doc/ldm/utils/Module_info.md","title":"Module_info","links":["StableSR_doc/ldm/utils/get_obj_from_str","StableSR_doc/ldm/utils/instantiate_from_config"],"tags":[],"content":"Functions\n\nget_obj_from_str\ninstantiate_from_config\n"},"StableSR_doc/ldm/utils/get_obj_from_str":{"slug":"StableSR_doc/ldm/utils/get_obj_from_str","filePath":"StableSR_doc/ldm/utils/get_obj_from_str.md","title":"get_obj_from_str","links":[],"tags":[],"content":"def get_obj_from_str(string, reload=False):\n    module, cls = string.rsplit(&quot;.&quot;, 1)\n    if reload:\n        module_imp = importlib.import_module(module)\n        importlib.reload(module_imp)\n    return getattr(importlib.import_module(module, package=None), cls)"},"StableSR_doc/ldm/utils/instantiate_from_config":{"slug":"StableSR_doc/ldm/utils/instantiate_from_config","filePath":"StableSR_doc/ldm/utils/instantiate_from_config.md","title":"instantiate_from_config","links":["StableSR_doc/ldm/utils/get_obj_from_str"],"tags":[],"content":"def instantiate_from_config(config):\n    if not &quot;target&quot; in config:\n        if config == &#039;__is_first_stage__&#039;:\n            return None\n        elif config == &quot;__is_unconditional__&quot;:\n            return None\n        raise KeyError(&quot;Expected key `target` to instantiate.&quot;)\n    return get_obj_from_str(config[&quot;target&quot;])(**config.get(&quot;params&quot;, dict()))\n \n作用\n读取config配置文件,按照其指定规则将target指定的类实例化.同时在第2行if块中给出了不进行实例化的判断逻辑,可以利用它来控制开关某些模块(如注意力机制和结构条件).\nconfig 配置要求\n应该使用yaml文件,包含target项用于指定类名,params项及其子项用于指定实例化时的模型参数.\n具体的实例化逻辑和过程\nget_obj_from_str 返回一个类对象,在get_obj_from_str(…)后面的 (**config.get)(&quot;params&quot;,dict())相当于将params作为参数传入到前面的类对象的__init__中,最终完成实例化."},"StableSR_doc/pytorch-lightning":{"slug":"StableSR_doc/pytorch-lightning","filePath":"StableSR_doc/pytorch lightning.md","title":"pytorch lightning","links":[],"tags":[],"content":"pytorch lighting模块简介\npl.LightningMoudule\npl.LightningModule 是对 torch.nn.Module 的高级封装\n只需要实现下面几个关键方法，它就能帮你自动完成训练流程、GPU 分发、日志记录、checkpoint保存等复杂操作：\n\n\n\n__init__(self): 初始化模型结构、损失函数、超参数等。\n\n\n\n\nforward(self, x): 定义前向传播逻辑（注意：仅在调用 model(x) 时使用，训练逻辑用 training_step）。\n\n\n\n\ntraining_step(self, batch, batch_idx):定义一个训练步骤的行为，返回 loss。\n\n\n通常的步骤是\n\n从 batch 取出数据；\n前向传播；\n计算损失；\n使用 self.log(...) 自动记录日志（如 loss）。\n\n\n\n\n\n\nvalidation_step(...) / test_step(...):验证和测试阶段的行为，结构与 training_step 类似。\n\n\n\n\nconfigure_optimizers(self):返回优化器和（可选的）学习率调度器。\n\n\n\npytorch_Lightning Callback 机制\nPyTorch Lightning 的 Callback（回调机制）是训练过程中的事件钩子系统，允许用户在训练 / 验证 / 测试 / 保存等阶段插入自定义逻辑，类似于钩子（hook）或监听器。\n\n✅ 常见用途\n\n自动保存最佳模型（如根据 val/loss 最小）\nEarly stopping（提前停止训练）\n日志记录 / 学习率可视化\n自定义日志、评估、样本可视化等行为\n\n\n🧩 核心概念：Callback 是一个类\nfrom pytorch_lightning.callbacks import Callback\n \nclass MyCallback(Callback):\n    def on_train_start(self, trainer, pl_module):\n        print(&quot;训练开始！&quot;)\n    \n    def on_validation_end(self, trainer, pl_module):\n        print(&quot;验证阶段结束。&quot;)\n \n    def on_train_batch_end(self, trainer, pl_module, outputs, batch, batch_idx):\n        print(f&quot;训练第 {batch_idx} 个 batch 完成&quot;)\n\n🧪 使用 Callback 的方式\nfrom pytorch_lightning import Trainer\n \ntrainer = Trainer(callbacks=[MyCallback()])\n可以一次性注册多个 callback：\ntrainer = Trainer(callbacks=[\n    MyCallback(),\n    ModelCheckpoint(...),\n    EarlyStopping(...)\n])\n\n📦 官方内置常用回调\n1. ModelCheckpoint: 保存最优模型\nfrom pytorch_lightning.callbacks import ModelCheckpoint\n \ncheckpoint_callback = ModelCheckpoint(\n    monitor=&quot;val/loss&quot;,     # 监控哪个指标\n    save_top_k=1,           # 只保留 top1\n    mode=&quot;min&quot;,             # 目标是最小化 loss\n    filename=&quot;best-checkpoint&quot;,\n    save_last=True\n)\n2. EarlyStopping: 提前停止\nfrom pytorch_lightning.callbacks import EarlyStopping\n \nearly_stop_callback = EarlyStopping(\n    monitor=&quot;val/loss&quot;,\n    patience=5,     # 若 5 个 epoch 没有提升则停止\n    mode=&quot;min&quot;\n)\n\n📚 常用 Callback 钩子方法一览\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n方法名调用时机on_fit_startfit() 开始时on_train_start训练阶段开始on_train_end训练阶段结束on_train_batch_start每个 batch 开始前on_train_batch_end每个 batch 结束后on_validation_end每轮验证结束后on_save_checkpoint保存 checkpoint 时on_load_checkpoint加载 checkpoint 时\n\n🎯 实例：在验证后记录当前模型状态\nclass LogModelNorm(Callback):\n    def on_validation_end(self, trainer, pl_module):\n        total_norm = 0\n        for p in pl_module.parameters():\n            if p.grad is not None:\n                param_norm = p.grad.data.norm(2)\n                total_norm += param_norm.item() ** 2\n        total_norm = total_norm ** 0.5\n        print(f&quot;当前梯度范数：{total_norm:.4f}&quot;)\n\n✅ 小结\n\nCallback 是一种轻量级的插件系统；\n所有模型相关回调都可以集中管理，不污染核心训练逻辑；\n非常适合记录日志、保存中间结果、动态修改训练行为等。\n"},"c语言/1.基本语法/Enumerated-Types":{"slug":"c语言/1.基本语法/Enumerated-Types","filePath":"c语言/1.基本语法/Enumerated Types.md","title":"Enumerated Types","links":[],"tags":[],"content":""},"c语言/1.基本语法/data-type":{"slug":"c语言/1.基本语法/data-type","filePath":"c语言/1.基本语法/data type.md","title":"data type","links":[],"tags":[],"content":"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n数据类型 (关键字)常见定义/声明方式占位符 (printf/scanf)说明charchar c = &#039;A&#039;;%c字符类型（实际上存储整数，对应 ASCII 码）。通常 1 字节 (8 位)。signed charsigned char sc = -10;%c明确带符号的字符，范围一般是 -128 ~ 127。unsigned charunsigned char uc = 250;%c 或 %hhu无符号字符，范围 0 ~ 255。intint x = 42;%d 或 %i整数，通常 4 字节，范围约 -2,147,483,648 ~ 2,147,483,647。short / short intshort s = 100;%hd短整型，一般 2 字节。unsigned shortunsigned short us = 60000;%hu无符号短整型，范围约 0 ~ 65535。long / long intlong l = 123456;%ld长整型，一般 4 或 8 字节（取决于系统）。unsigned longunsigned long ul = 4000000000UL;%lu无符号长整型。long long / long long intlong long ll = 123456789LL;%lld更大的整数，一般 8 字节。unsigned long longunsigned long long ull = 18446744073709551615ULL;%llu最大的标准无符号整数类型。floatfloat f = 3.14f;%f单精度浮点数，约 6~7 位有效数字。doubledouble d = 3.141592653;%lf双精度浮点数，约 15~16 位有效数字。long doublelong double ld = 3.141592653589793L;%Lf扩展精度浮点，精度比 double 高（平台依赖）。_Bool (C99)_Bool flag = 1;%d只能是 0 或 1。需要 &lt;stdbool.h&gt; 头文件时可写作 bool。voidvoid func(void);无表示“无类型”，用于函数返回类型或指针 (void*)。"},"c语言/1.基本语法/typedef":{"slug":"c语言/1.基本语法/typedef","filePath":"c语言/1.基本语法/typedef.md","title":"typedef","links":[],"tags":[],"content":"typedef概念\n\n\ntypedef 是 类型重定义关键字，用来给已有的数据类型起一个新的名字（别名）。\n\n\n它不会创建新的类型，只是让代码更简洁、更易读。\n\n\n基本语法\ntypedef 原类型 新类型名;\n示例\n基本类型重命名\ntypedef unsigned int uint;\n \nuint x = 10;  // 等价于 unsigned int x = 10;\n指针类型别名\ntypedef char* string;\n \nstring s1 = &quot;Hello&quot;;   // 等价于 char* s1 = &quot;Hello&quot;;\n结构体简化\n没有 typedef 时，定义变量必须写 struct：\nstruct Student {\n    int id;\n    char name[20];\n};\nstruct Student s1;\n使用 typedef 可以给 struct 类型起一个别名：\nstruct StudentInfo {\n    int id;\n    char name[20];\n};\n \ntypedef struct StudentInfo Student; // 用 typedef 起一个别名\nStudent s1;   // 等价于 struct Student s1\n也可以简写成匿名结构体 + typedef：\ntypedef struct {\n    int id;\n    char name[20];\n} Student;\n \nStudent s1;   // 不再需要写 struct\n\n两种 typedef struct 的区别\n\n\n有标签的写法\ntypedef struct StudentInfo {\n    char name[20];\n    int id;\n    float score;\n} Student1;\n \nstruct StudentInfo a;  // 用标签\nStudent1 b;            // 用别名\n\n\n定义了 标签 struct StudentInfo 和 别名 Student1。\n\n\n允许 前置声明，因此支持自引用（链表、树等数据结构常用）。\n\n\n\n\n匿名结构体写法\ntypedef struct {\n    char name[20];\n    int id;\n    float score;\n} Student2;\n \nStudent2 c;  // 用别名\n// struct ??? d; 没有标签，不能这样写\n\n\n没有结构体标签，只有 别名 Student2。\n\n\n不能前置声明，因此 不能自引用，只适合简单数据结构。\n\n\n\n\n\n总结\n\n\n有标签的写法功能更完整（能前置声明、自引用），更适合复杂场景。\n\n\n匿名写法更简洁，常用于简单结构或库接口。\n\n\n复杂类型简化\ntypedef int (*FuncPtr)(int, int);  \n \nint add(int a, int b) { return a + b; }\n \nFuncPtr f = add;\nprintf(&quot;%d\\n&quot;, f(3, 4));  // 输出 7\ntypedef 与 #define 的区别\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n特性typedef#define处理方式编译阶段预处理阶段（文本替换）是否有作用域有（仅在定义作用域内有效）无（全局宏替换）能否定义指针类型别名可以需要括号，容易出错代码可读性更安全，更直观容易产生歧义\n例子：\n#define PTR_INT int*\ntypedef int* PtrInt;\n \nPTR_INT a, b;   // 实际是 int* a, b;  (b不是指针)\nPtrInt c, d;    // 两个都是 int* 类型\n常见用法总结\n\n\n给 基本类型 起短名（如 uint）。\n\n\n给 指针类型 起别名（如 string）。\n\n\n给 结构体/联合/枚举 起别名，避免每次写 struct。\n\n\n给 函数指针 起别名，简化复杂声明。\n\n\n小结：\ntypedef 本质上是 类型别名机制，它不创建新类型，只是提高 可读性 和 可维护性。\n在大型项目中，typedef 常与 struct、enum、函数指针一起使用，能让代码更简洁、更清晰。"},"c语言/1.基本语法/宏macro":{"slug":"c语言/1.基本语法/宏macro","filePath":"c语言/1.基本语法/宏macro.md","title":"宏macro","links":[],"tags":[],"content":"在C语言中，宏是通过预处理器进行文本替换的一种功能。宏通常用于简化代码，增加可读性，或者在编译时执行一些条件编译操作。宏在编译过程的预处理阶段展开，它们不会在运行时消耗资源。\n宏的种类\n\n\n对象宏（Object-like Macros）\n对象宏类似于常量的替代，通常用于常量定义。它是直接用一个名称替代某个值或表达式。\n示例：\n#define PI 3.14159\n#define MAX_BUFFER_SIZE 1024\n这样在代码中，PI 会被替换成 3.14159，MAX_BUFFER_SIZE 会被替换成 1024。\n\n\n函数宏（Function-like Macros）\n函数宏类似于函数，但它在预处理阶段被直接替换成对应的代码。函数宏允许带参数，宏展开时会将参数替换到宏定义的位置。\n示例：\n#define SQUARE(x) ((x) * (x))\n#define MAX(a, b) ((a) &gt; (b) ? (a) : (b))\n这样，在代码中，SQUARE(4) 会被展开成 ((4) * (4))，MAX(3, 5) 会被展开成 ((3) &gt; (5) ? (3) : (5))。\n注意：\n\n\n在函数宏中，参数应加上括号，以确保表达式的优先级正确。\n\n\n宏展开时没有类型检查，因此可能会导致一些潜在的错误，比如宏参数中有副作用。\n\n\n\n\n条件编译宏（Conditional Compilation）\n宏也可以用来控制代码的编译条件。通过条件编译，可以根据不同的环境或配置来决定是否编译某些代码块。\n示例：\n#ifdef DEBUG\n    printf(&quot;Debugging enabled\\n&quot;);\n#else\n    printf(&quot;Debugging disabled\\n&quot;);\n#endif\n#ifdef 用来检查是否定义了 DEBUG，如果定义了 DEBUG，那么对应的代码块会被编译，否则跳过。\n\n\n#define与#undef\n\n\n#define 用于定义宏。\n\n\n#undef 用于取消已定义的宏。\n\n\n示例：\n#define DEBUG\n#undef DEBUG\n\n\n宏替换与副作用问题\n由于宏是简单的文本替换，在使用函数宏时，要小心参数中的副作用。比如：\n#define SQUARE(x) ((x) * (x))\nint a = 2;\nint result = SQUARE(a++);\n在这个例子中，a++ 会被展开成 ((a++) * (a++))，这可能会导致意外的副作用（例如 a 的值变得不符合预期）。\n\n\n宏的优缺点\n优点：\n\n\n性能提升：宏替换在编译时进行，因此在运行时没有额外的开销。\n\n\n代码简洁：可以使用宏避免重复编写相同的代码。\n\n\n条件编译：宏可以帮助在不同平台或者配置中编译不同的代码。\n\n\n缺点：\n\n\n缺乏类型安全：宏只是简单的文本替换，没有类型检查，容易产生错误。\n\n\n调试困难：调试宏展开后的代码不如函数直观，因为它们在编译时展开，调试时无法看到展开后的完整代码。\n\n\n副作用问题：宏的参数会多次计算，可能导致副作用，尤其在使用带有副作用的表达式时。\n\n\n总结来说，宏是C语言中非常强大的功能，但在使用时要小心处理副作用和调试问题。如果可能，应该尽量使用 const 或 inline 函数来替代宏，避免一些潜在的错误。"},"c语言/1.基本语法/局部变量、全局变量与静态变量":{"slug":"c语言/1.基本语法/局部变量、全局变量与静态变量","filePath":"c语言/1.基本语法/局部变量、全局变量与静态变量.md","title":"局部变量、全局变量与静态变量","links":["c语言/1.基本语法/遮蔽(shadowing）"],"tags":[],"content":"局部变量\n\n\n作用域：\n\n局部变量的作用域仅限于它所在的函数、if、for 或 while 等代码块内部。在代码块外部无法访问该变量。\n例如，for 循环中声明的变量只在循环内部有效。\n\n\n\n生存期：\n\n局部变量的生存期从它们被声明时开始，直到代码块执行完毕为止。它们通常保存在栈上，因此当程序离开作用域时，局部变量会被销毁。\n\n示例：\n\n\nvoid func() {\n  int x = 10;  // 局部变量 x\n  printf(&quot;%d\\n&quot;, x);\n}\n// x 在 func 函数外部无法访问\n在上面的代码中，x 仅在 func() 函数内部有效，退出函数后 x 被销毁。\n全局变量\n作用域和生存期\n\n\n作用域：\n\n\n全局变量的作用域是整个文件。如果在其他文件中需要访问该全局变量，可以使用 extern 关键字声明。\n\n\n全局变量在程序中只存在一份，可以在程序中的任何地方访问。\n\n\n\n\n生存期：\n\n\n全局变量的生存期是整个程序的生命周期，从程序开始到程序结束。它们通常保存在数据段中。\n\n\n示例：\nint x = 10;  // 全局变量 x\n \nvoid func() {\n    printf(&quot;%d\\n&quot;, x);  // 访问全局变量 x\n}\n \nint main() {\n    printf(&quot;%d\\n&quot;, x);  // 访问全局变量 x\n    func();\n    return 0;\n}\n\n\n在上述代码中，x 是全局变量，可以在 main() 和 func() 中访问，并且它的值会在程序执行期间一直存在。\nextern关键字\n如果使用extern关键字导出全局变量，则在其他文件中也可以访问。\nfile1.c\n#include &lt;stdio.h&gt;\n \nint x = 10;  // 全局变量 x\n \nvoid print_x() {\n    printf(&quot;x = %d\\n&quot;, x);  // 访问全局变量 x\n}\n \nfile2.c\n#include &lt;stdio.h&gt;\n \nextern int x;  // 使用 extern 声明全局变量 x\n \nvoid change_x() {\n    x = 20;  // 修改全局变量 x\n}\n \nint main() {\n    printf(&quot;Before change, x = %d\\n&quot;, x);  // 访问全局变量 x\n    change_x();  // 修改全局变量 x\n    printf(&quot;After change, x = %d\\n&quot;, x);  // 访问修改后的全局变量 x\n    return 0;\n}\n \nfile1.c中定义了全局变量 x,file2.c中使用 extern int x; 声明了 x，表示它在其他文件中已经定义。然后，file2.c 可以访问和修改 x。extern可以在任意文件的任意位置声明，编译器和连接器会自动在所有参与编译的源文件中寻找其定义。\n对于上述两个源文件 file1.c 和 file2.c，可以使用以下命令进行编译和链接：\ngcc file1.c file2.c -o program\n\n运行程序时，输出将会是：\nBefore change, x = 10 \nAfter change, x = 20\n\n静态变量 (static)\n\n\n局部静态变量：\n\n\n作用域：静态局部变量的作用域依然是局部的，只能在定义它的函数或代码块内部访问。\n\n\n生存期：静态局部变量的生存期是整个程序的生命周期。即使函数退出，静态变量的值会被保留，在下一次调用该函数时，静态变量仍然保持之前的值。\n\n\n示例：\nvoid func() {\n    static int counter = 0;  // 静态局部变量 counter\n    counter++;\n    printf(&quot;%d\\n&quot;, counter);\n}\n \nint main() {\n    func();  // 输出 1\n    func();  // 输出 2\n    func();  // 输出 3\n    return 0;\n}\n在上述代码中，counter 是静态局部变量，它的值只有在第一次调用func()时初始化，在后续每次调用 func() 时会跳过初始化，保持之前的值并累加。\n\n\n全局静态变量：\n\n\n作用域：静态全局变量的作用域被限制在当前文件内，其他文件无法访问。它的作用类似于一个局部的全局变量。\n\n\n生存期：静态全局变量的生存期是整个程序的生命周期。\n\n\n示例：\nstatic int x = 10;  // 静态全局变量 x，作用域仅限于当前文件\n \nvoid func() {\n    printf(&quot;%d\\n&quot;, x);  // 访问静态全局变量 x\n}\n在该示例中，x 是静态全局变量，它的作用域仅限于当前文件，其他文件无法访问。\n\n\n总结\n\n\n局部变量：作用域是代码块内，生存期仅在代码块执行期间。\n\n\n全局变量：作用域是整个文件，生存期是程序生命周期。\n\n\n静态变量：\n\n\n静态局部变量：作用域是局部的，生存期是程序生命周期，跨函数调用保持值。\n\n\n静态全局变量：作用域是当前文件，生存期是程序生命周期。\n\n\n\n\n注意：局部声明的变量如果与外部作用域变量重名则会发生遮蔽(shadowing）"},"c语言/1.基本语法/结构体(struct)":{"slug":"c语言/1.基本语法/结构体(struct)","filePath":"c语言/1.基本语法/结构体(struct).md","title":"结构体(struct)","links":["c语言/1.基本语法/typedef"],"tags":[],"content":"结构体概念\n在C语言中，结构体（struct） 是一种用户自定义的数据类型，它可以把多个不同类型的数据组合在一起，形成一个整体。\n结构体适用于描述 复杂对象，比如一个学生（有学号、姓名、成绩等）、一个点（有x、y坐标）、一辆车（有车牌号、颜色、速度等）。\n\n结构体的定义方式\n基本语法\nstruct 结构体名 {\n    数据类型 成员名1;\n    数据类型 成员名2;\n    ...\n};\n示例\nstruct Student {\n    int id;        // 学号\n    char name[20]; // 姓名\n    float score;   // 成绩\n};\n这样就定义了一个 Student 类型。\n\n定义结构体变量\nstruct Student s1;    // 定义一个结构体变量\nstruct Student s2 = {1001, &quot;Alice&quot;, 95.5};  // 定义并初始化\n还可以和typedef配合：\ntypedef struct {\n    int x;\n    int y;\n} Point;\n \nPoint p1 = {10, 20};\n访问结构体成员\n结构体成员通过 . 运算符 来访问：\nprintf(&quot;ID: %d, Name: %s, Score: %.2f\\n&quot;, s2.id, s2.name, s2.score);\n如果是 结构体指针，则通过 -&gt; 运算符访问：\nstruct Student *ps = &amp;s2;\nprintf(&quot;Name = %s\\n&quot;, ps-&gt;name);\n结构体数组\n结构体也能组成数组，方便批量管理。\nstruct Student class[3] = {\n    {1001, &quot;Alice&quot;, 95.5},\n    {1002, &quot;Bob&quot;, 88.0},\n    {1003, &quot;Charlie&quot;, 92.5}\n};\n结构体嵌套\n结构体成员还可以是另一个结构体：\nstruct Date {\n    int year, month, day;\n};\n \nstruct Student {\n    int id;\n    char name[20];\n    struct Date birthday;  // 嵌套的结构体\n};\n \nstruct Student s = {1001, &quot;Alice&quot;, {2003, 5, 10}};\nprintf(&quot;Birthday: %d-%d-%d\\n&quot;, s.birthday.year, s.birthday.month, s.birthday.day);\n结构体与函数\n结构体可以作为函数的 参数 或 返回值：\nstruct Point {\n    int x, y;\n};\n \nstruct Point move(struct Point p, int dx, int dy) {\n    p.x += dx;\n    p.y += dy;\n    return p;\n}\n \nint main() {\n    struct Point p1 = {0, 0};\n    p1 = move(p1, 5, 10);\n    printf(&quot;(%d, %d)\\n&quot;, p1.x, p1.y);  // (5, 10)\n}\n内存与对齐\n\n\n结构体中每个成员在内存中是按顺序存储的，但会有 字节对齐（padding）。\n\n\nsizeof(struct) 的结果可能大于成员大小之和。\n\n\n如果需要优化内存，可以调整成员顺序，或者使用 #pragma pack（依赖编译器）。\n\n\n常见用法总结\n\n\n描述实体对象：如学生、点、日期等。\n\n\n结构体数组：批量存储多个实体。\n\n\n结构体指针：常用于函数参数传递，避免大规模复制。\n\n\n嵌套结构体：描述复杂对象。\n\n"},"c语言/1.基本语法/逻辑运算符":{"slug":"c语言/1.基本语法/逻辑运算符","filePath":"c语言/1.基本语法/逻辑运算符.md","title":"逻辑运算符","links":[],"tags":[],"content":"C 语言的逻辑运算符\nC 语言中共有 3 个逻辑运算符，用于对表达式的真假进行逻辑运算，返回结果为 1（真，true）或 0（假，false）。\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n运算符含义示例结果说明&amp;&amp;逻辑与 ANDa &amp;&amp; b两个操作数都为真时结果为 1，否则为 0||逻辑或ORa || b两个操作数有一个为真时结果为 1，否则为 0!逻辑非 NOT!a如果 a 为真，则结果为 0；如果 a 为假，结果为 1\n逻辑与 &amp;&amp;\n\n\n表达式 a &amp;&amp; b：当且仅当 a 和 b 都为真时，结果为真（1）；否则为假（0）。\n\n\n短路特性：如果 a 为假（0），则 b 不再计算。\n\n\n#include &lt;stdio.h&gt;\nint main() {\n    int a = 1, b = 0;\n    printf(&quot;a &amp;&amp; b = %d\\n&quot;, a &amp;&amp; b);  // 0\n    printf(&quot;a &amp;&amp; 1 = %d\\n&quot;, a &amp;&amp; 1);  // 1\n    return 0;\n}\n\n逻辑或 ||\n\n\n表达式 a || b：只要 a 或 b 有一个为真（非 0），结果就为真（1）。只有当 a 和 b 都为假时，结果才是假（0）。\n\n\n短路特性：如果 a 为真，则 b 不再计算。\n\n\n#include &lt;stdio.h&gt;\nint main() {\n    int a = 1, b = 0;\n    printf(&quot;a || b = %d\\n&quot;, a || b);  // 1\n    printf(&quot;0 || 0 = %d\\n&quot;, 0 || 0);  // 0\n    return 0;\n}\n\n逻辑非 !\n\n表达式 !a：对 a 取反，如果 a 为真（非 0），结果为假（0）；如果 a 为假（0），结果为真（1）。\n\n#include &lt;stdio.h&gt;\nint main() {\n    int a = 1, b = 0;\n    printf(&quot;!a = %d\\n&quot;, !a);  // 0\n    printf(&quot;!b = %d\\n&quot;, !b);  // 1\n    return 0;\n}\n逻辑运算符的特点\n\n\n返回值：逻辑运算的结果要么是 0（假），要么是 1（真）。\n\n\n短路求值：\n\n\na &amp;&amp; b：如果 a 为假，直接返回 0，不再计算 b。\n\n\na || b：如果 a 为真，直接返回 1，不再计算 b。\n这在编程时可以用来避免不必要的计算或错误（如除零）。\n\n\n\n\n结合性：\n\n\n! 的结合性是 右结合；\n\n\n&amp;&amp; 和 || 是 左结合；\n\n\n优先级： ! &gt; &amp;&amp; &gt; ||。\n\n\n\n\n\n示例：结合优先级\n#include &lt;stdio.h&gt;\nint main() {\n    int a = 1, b = 0, c = 0;\n    printf(&quot;%d\\n&quot;, a || b &amp;&amp; c);   // 等价于 a || (b &amp;&amp; c)\n    printf(&quot;%d\\n&quot;, (a || b) &amp;&amp; c); // 加括号改变优先级\n    return 0;\n}\n输出：\n1\n0\n\n\n✅ 总结：\n\n\n&amp;&amp;：逻辑与，两个都真才真。\n\n\n||：逻辑或，有一个真就真。\n\n\n!：逻辑非，真变假，假变真。\n\n\n注意短路特性和优先级，实际编程时建议用括号来提高可读性。\n\n\n\n要不要我再帮你整理一个 逻辑运算符 vs 位运算符（&amp;、|、~、^） 的对比表？这样你在做笔记时能避免混淆。"},"c语言/1.基本语法/遮蔽(shadowing）":{"slug":"c语言/1.基本语法/遮蔽(shadowing）","filePath":"c语言/1.基本语法/遮蔽(shadowing）.md","title":"遮蔽(shadowing）","links":[],"tags":[],"content":"遮蔽（Shadowing）\n在 C 语言中，如果在某个作用域内定义了一个与外层作用域（例如全局作用域或函数外层作用域）同名的变量，那么这个新的变量会在当前作用域内“遮蔽”（shadow）外层作用域中的同名变量。\n这意味着：\n\n\n在当前作用域中，访问到的将是局部定义的新变量；\n\n\n外层的同名变量不会被销毁或修改，只是暂时“不可见”；\n\n\n一旦离开该局部作用域，外层变量重新可见，并且保持原有值。\n\n\n\n函数中的遮蔽\n#include &lt;stdio.h&gt;\n \nint x = 10;  // 全局变量 x\n \nvoid func() {\n    int x = 20;  // 局部变量 x，遮蔽了全局变量 x\n    printf(&quot;Inside func, x = %d\\n&quot;, x);  // 输出局部变量 x 的值 20\n}\n \nint main() {\n    printf(&quot;Before func, x = %d\\n&quot;, x);  // 输出全局变量 x 的值 10\n    func();\n    printf(&quot;After func, x = %d\\n&quot;, x);   // 输出全局变量 x 的值 10\n    return 0;\n}\n输出结果：\nBefore func, x = 10\nInside func, x = 20\nAfter func, x = 10\n\n在 func 内重新声明了一个局部变量 x，它遮蔽了全局变量 x。因此，func 内打印的是局部变量的值，而在 main 中调用 func 前后，全局变量 x 保持不变。\n\n块作用域中的遮蔽\n遮蔽不仅能发生在函数内部，也可以发生在代码块（如循环或条件语句）中：\n#include &lt;stdio.h&gt;\n \nint x = 10;  // 全局变量\n \nint main() {\n    printf(&quot;Global x before block: %d\\n&quot;, x);\n \n    {\n        int x = 30;  // 新的局部变量，遮蔽全局变量\n        printf(&quot;Block x: %d\\n&quot;, x);\n    }\n \n    printf(&quot;Global x after block: %d\\n&quot;, x);\n    return 0;\n}\n输出结果：\nGlobal x before block: 10\nBlock x: 30\nGlobal x after block: 10\n\n在 {} 块内声明了一个新的 x，它遮蔽了全局变量 x。但离开这个块后，新的局部变量生命周期结束，全局变量 x 又恢复可见。\n\n注意事项\n\n\n遮蔽并不会修改外层变量的值\n重新声明的变量只是一个新的实体，生命周期和存储空间都不同，不会影响外层的同名变量。\n\n\n作用域规则优先\n在 C 语言中，就近原则决定了变量的解析：编译器总是优先使用当前作用域内最接近的声明。\n\n\n易引发混淆\n如果在代码中过度使用遮蔽，容易让人误以为操作的是全局变量，实际上却是在修改局部变量。建议实际编程中避免使用相同的变量名。\n\n\n\n如何访问被遮蔽的全局变量\n在 C 语言里，如果局部变量遮蔽了全局变量，可以通过 在局部作用域内使用 extern 显式声明 来访问全局变量：\n#include &lt;stdio.h&gt;\n \nint x = 10;  // 全局变量\n \nvoid func() {\n    int x = 20;  \n    printf(&quot;Local x = %d\\n&quot;, x);  // 输出 20\n \n    extern int x;  // 引用全局变量 x\n    printf(&quot;Global x = %d\\n&quot;, x); // 输出 10\n}\n这样可以区分到底访问的是哪一个 x。不过，代码可读性会变差，一般不推荐。\n总结\n\n\n遮蔽（shadowing）指的是内层作用域的变量与外层作用域的变量同名，从而让外层变量在该作用域内“不可见”。\n\n\n外层变量的值不会因遮蔽而改变，作用域结束后会重新可见。\n\n\n实际编程中应尽量避免使用相同的变量名，以减少混淆。\n\n\n\n要不要我再帮你扩展一个 函数参数遮蔽全局变量 的示例，让这一节更完整？"},"c语言/3.指针、数组与递归算法/指针(Pointer)":{"slug":"c语言/3.指针、数组与递归算法/指针(Pointer)","filePath":"c语言/3.指针、数组与递归算法/指针(Pointer).md","title":"指针(Pointer)","links":[],"tags":[],"content":"指针概念\n指针本身不是一个数据类型，而是一种类型构造器，给定任何一种类型（int、float、char等），可以通过星号生成指向该类型变量的指针。\nint x = 10;\nint* ptr_to_int = &amp;x;\n&amp;是取地址运算符，它可以作用在C语言的任何左值（lvalue）上，并返回该左值的内存地址。\n*是解引用运算符，它作用在一个指针上时，*ptr等价于指针ptr所指向的变量。\nint x = 10;\nint* xptr = &amp;x;\nx = 5;        // 将x的值置为5\n*xptr = 5;    // 将x的值置为5\n\nSwap revisit\n有了指针，我们就可以通过传递变量指针的方式，设计一个函数来访问另一个函数的变量。\nvoid swap(int* x, int* y) {\n    int temp = *x;\n    *x = *y;\n    *y = temp;\n}\n \nint main(void) {\n    int a = 3;\n    int b = 4;\n    printf(&quot;a:%d; b:%d\\n&quot;, a, b);\n    swap(&amp;a, &amp;b);\n    printf(&quot;a:%d; b:%d\\n&quot;, a, b);\n    return EXIT_SUCCESS;\n}\n指针x、y分别指向原先的a、b，所以我们可以用以指针为参数的函数（swap）修改调用该函数的函数（main）中的局部变量的值。\n\n指针的硬件工作原理\n地址寻址\n计算机通过将数据存储在内存中来管理所有信息。硬件使用数值地址来唯一标识内存中的每个存储单元。\n现代计算机通常采用字节寻址内存，即每个不同的地址对应内存中的一个字节。\n\n\n每个内存单元代表一个字节。\n\n\n每个字节都有一个唯一的地址（0, 1, 2, …）。\n\n\n在 32 位机器上，地址由 32 位二进制数表示，因此一个指针变量需要 4 个字节来存储地址值，而与它指向的数据类型大小无关。\n在 64 位机器上，地址为 64 位，因此指针大小通常是 8 个字节。\n指针的硬件实现\n通过理解内存和地址，可以更清楚地认识指针的本质：\n指针本质上就是一个变量，它存储了另一个变量的内存地址。\n\n\n对于占用空间超过一个字节的变量（如 int、double、struct 等），该变量在内存中会占据连续的一段字节。\n\n\n其指针并不是记录这段内存的全部，而是记录该对象起始字节的地址。\n\n\n只要知道起始地址，并结合类型信息（告诉编译器需要读取多少字节），程序就能正确地找到并访问变量的完整数据。\n\n\nPS：\n\n标准类型（如 int、float、double）以及数组在内存中的存储一定是连续的；结构体的成员变量可能存在填充（padding），但整体上依然是连续的一块内存。\n对于链表、树等复杂数据结构，它们的节点通常分散存储，通过指针组合实现逻辑上的关联。\n对于超大对象（如大数组、malloc 分配的大内存块），在虚拟内存中依然表现为连续的地址区间，但在物理内存中可能分散在多个页面上。\n例如：\n\nint x = 42;    // 假设 int 占 4 字节\nint *p = &amp;x;   // p 保存的是 x 的起始地址\n即使 x 占用 4 个字节，指针 p 只存储 x 所在内存区域的第一个字节的地址，编译器通过 int* 类型信息知道要取连续 4 字节来解释为一个整数。\n重要限制\n指针是值为“地址”的变量，这带来一个重要限制：\n指针只能指向可寻址的数据对象。\n这意味着：\n\n\n只有占据实际内存空间的对象（变量、数组、结构体等）才有地址。\n\n\n不对应内存位置的临时结果或字面量不能被取地址。\n\n\n例如：\nint *ptr = &amp;3;        // ❌ 错误：字面量 3 不是可寻址对象\nint *ptr = &amp;(x + y);  // ❌ 错误：表达式 (x+y) 结果是临时值，无存储位置\n这是因为 3 和 (x+y) 都不是 左值（lvalue）。\n\n\n左值指代一个实际存储位置（“内存中的盒子”）。\n\n\n临时值不是存储单元，因此没有地址。\n\n\n编译器会报错，提醒我们只能对变量取地址。\n推论：赋值语句的左边必须是一个左值，因为赋值操作的本质就是“往某个盒子里放数据”。\n因此像下面的语句会报错：\n3 = 4;        // ❌ 错误\nx + y + z = 2; // ❌ 错误\n核心要点总结\n\n\n指针的本质\n\n指针不是独立类型，而是类型构造器，用于创建“指向某类型对象”的新类型。\n\n\n\n地址运算符 &amp;\n\n取出变量的内存地址（必须是左值）。\n\n\n\n解引用运算符 *\n\n根据指针存储的地址访问对应内存中的值。\n\n\n\n内存寻址\n\n每个内存位置都有唯一地址。指针存储的是地址，而不是对象的值。\n\n\n\n类型信息的重要性\n\n指针只存储起始地址，编译器依靠指针的类型来确定访问多少字节。\n\n\n\n限制条件\n\n指针只能指向可寻址的对象，不能指向常量或临时计算结果。\n\n\n\n赋值规则\n\n赋值操作的左边必须是左值（实际内存单元）。\n\n\n\nPointer to strut\nWhen we have pointers to structs, we can just use the * and . operators that we have seen so far, however, the order of operations means that . happens first. If we write *a.b, it means (a.b)—a should be a struct, which we look inside to find a field named b (which should be a pointer), and we dereference that pointer. If we have a pointer to a struct (c, and we want to refer to the field d in the struct at the end of the arrow, we would need parenthesis, and write (c).d (or the → operator we will learn about momentarily).\nIn the figure above, we have a struct which has a field p (which is a pointer to an int), and a field x which is an int. We then declare y (an int), a (a struct), and q (a pointer to a struct), and initialize them. When we write *a.p, the order of operations is to evaluate a.p (which is an arrow pointing at y), then dereference that arrow. If we wrote *q.x, we would receive a compiler error, as q is not a struct, and the order of operations would say to do q.x first (which is not possible, since q is not a struct). We could write parenthesis, as in the figure ((*q).x).\nHowever, pointers to structs are incredibly common, and the above syntax gets quite cumbersome, especially with pointers to structs which have pointers to structs, and so on. For (*q).x, it may not be so bad, but if we have (((*q).r).s).t it becomes incredibly ugly, and confusing. Instead, we should use the → operator, which is shorthand for dereferencing a pointer to a struct and selecting a field—that is, we could write q→x (which means exactly the same thing as (*q).x). For our more complex example, we could instead write q→r→s→t (which is easier to read and modify).\nAliasing\nconst\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n类型Can we change **pCan we change *pCan we change p解读int ** pYesYesYes三层都非 const；可以改底层 int、中间指针的指向、以及最外层指针变量本身。const int ** pNoYesYes最里层是 const int，不能改数据；两层指针本身都可改动其指向。int * const * pYesNoYes中间层是“const 指针指向 int”：不能给 *p 赋新地址；但底层 int 可改、外层 p 可改。int ** const pYesYesNo最外层是“const 指针”：p 不能改；但可改中间层指向与底层 int。const int * const * pNoNoYes中间层是“const 指针指向 const int”：既不能改底层数据，也不能给 *p 换地址；仅能改外层 p 本身。const int ** const pNoYesNo最外层是 const（不能改 p）；底层数据是 const int（不能改 **p）；但能让中间层 *p 指向别处。int * const * const pYesNoNo两层指针都是 const（*p 与 p 都不能改）；但中间层指向的是非常量 int，因此可改底层数据。const int * const * const pNoNoNo三层都被“读写能力”锁死：底层数据是 const，两层指针也都是 const。\n洋葱法\nps： const相当于一个形容词，int float double  * 等等相当于名词，const对“名词”的修饰可以放在“名词之前或名词之后\neg：\nconst int 和 int const完全等价\n解读这类复杂声明时，应先找到变量名，然后按照英语的顺序,以“名词”为一层，一层一层向外解读。const形容词优先和右侧(内层)的名词结合。\neg:\nconst int * const * const p\n\n首先找到变量名p\n向外读：\n\n* const p：p is a const pointer to\n* const :  a const pointer to\nint const : a const int\n\n\n和起来：p is a const pointer to a const pointer to a const int\n翻译过来：\n\np是一个指向（指向常量整型的常量指针）的（常量指针）\np 是一个 常量指针，它指向一个 常量指针，而这个常量指针又指向一个 常量整型\n\n\n\n指针运算 (Pointer Arithmetic)\n在 C 语言中，指针带有类型信息。当你做 p + n、p - n 或两个同类型指针相减时，编译器会按“元素”为单位而不是“字节”为单位计算位移。\n核心公式（概念上）：\np + n == (char*)p + n * sizeof(*p)\n也就是说，步长由“指针所指向的类型”的大小决定。\n常见步长举例\n\n\nint*：p + 1 前进 sizeof(int) 字节（常见为 4）\n\n\nfloat*：q + 1 前进 sizeof(float) 字节（常见为 4）\n\n\ndouble*：r + 1 前进 sizeof(double) 字节（常见为 8）\n\n\nchar*：c + 1 前进 1 字节（逐字节移动，常用于二进制/内存操作）\n\n\n小示例（地址变化对比）\n#include &lt;stdio.h&gt;\n \nint main(void) {\n    int    xi = 42;     int*    pi = &amp;xi;\n    float  xf = 3.14f;  float*  pf = &amp;xf;\n    double xd = 6.28;   double* pd = &amp;xd;\n \n    printf(&quot;pi    = %p, pi+1    = %p\\n&quot;, (void*)pi, (void*)(pi+1));\n    printf(&quot;pf    = %p, pf+1    = %p\\n&quot;, (void*)pf, (void*)(pf+1));\n    printf(&quot;pd    = %p, pd+1    = %p\\n&quot;, (void*)pd, (void*)(pd+1));\n \n    // 逐字节观察\n    char* pc = (char*)&amp;xi;\n    printf(&quot;pc    = %p, pc+1    = %p\\n&quot;, (void*)pc, (void*)(pc+1));\n    return 0;\n}\n具体数值可能因平台不同而变化\n重要规则 &amp; 易错点\n\n\n数组边界规则\n指针运算只在同一数组对象内有定义（含“尾后位置”one-past-the-end）。\n\n\n你可以把 p 移动到 arr + n（n 为数组长度）的“尾后”位置，但不能解引用那个位置。\n\n\n超出这个范围的计算或任何越界解引用都是未定义行为（UB）。\n\n\n对于单个变量 int x; int* p = &amp;x; p+1 只是“算出一个地址”，对其解引用是 UB。\n\n\n\n\nvoid* 不能做算术（标准 C）\n标准 C 不允许对 void* 做加减（某些编译器作为扩展支持）。如需按字节移动，先转成 char* 再运算：\nchar* pc = (char*)p; pc += n;\n\n\n指针对齐（alignment）\n把不同类型指针“硬转换”并解引用，可能触发未对齐访问（某些架构会崩溃/降速）。尽量遵守原始类型的对齐要求。\n\n\n指针相减\n仅当两个指针指向同一数组的元素（或其尾后位置）时，p2 - p1 才有定义，结果类型是 ptrdiff_t，表示元素个数的差，而非字节差。\n\n\n速记总结\n\n\n步长 = sizeof(*p)，不是 1 字节（除 char*）。\n\n\n只在同一数组内做运算并谨慎解引用尾后位置（不可解引用）。\n\n\n逐字节移动请用 char*。\n\n\n避免未对齐与越界，p2 - p1 返回元素差而非字节差。\n\n"},"index":{"slug":"index","filePath":"index.md","title":"首页","links":[],"tags":[],"content":"欢迎来到我的 Quartz\n这是我的数字花园首页。你可以从左边的目录或搜索框进入笔记。"},"分布式/hadoop/HDFS/HDFS体系结构":{"slug":"分布式/hadoop/HDFS/HDFS体系结构","filePath":"分布式/hadoop/HDFS/HDFS体系结构.md","title":"HDFS体系结构","links":[],"tags":[],"content":"命名空间管理\n\n\nHDFS的命名空间包含目录、文件和块\n\n\n在HDFS1.0体系结构中，在整个HDFS集群中只有一个命名空间，并且只有唯一一个名称节点，该节点负责对这个命名空间进行管理\n\n\nHDFS使用的是传统的分级文件体系，因此，用户可以像使用普通文件系统一样，创建、删除目录和文件，在目录间转移文件，重命名文件等\n\n\n通信协议\nClient ↔ NameNode\n协议\n\n\nHadoop RPC（org.apache.hadoop.ipc 提供）\n\n\nNameNode 实现了 ClientProtocol 接口（Java），客户端通过 RPC Stub 调用 NameNode 方法。\n\n\n典型调用\n\n\ncreate()：请求新建文件\n\n\naddBlock()：申请新的 block 并返回 DataNode 列表\n\n\ngetBlockLocations()：查询某个文件的 block 分布\n\n\ncomplete()：关闭文件，标记完成\n\n\n特点\n\n\n基于 TCP\n\n\n默认用 protobuf 序列化\n\n\n端口：在core-site.xml 中使用 fs.defaultFS=hdfs://namenode:9000进行配置，默认是9000\n\n\nClient ↔ DataNode\n协议\n\n\nDataTransferProtocol\n\n\n专门用于数据读写，走 TCP（默认端口 50010，在 docker 环境里可能映射到外部的 9866/9864）。\n\n\n典型场景\n\n\n读流程\n\n\n客户端请求一个 block（block ID + token + 偏移）。\n\n\nDataNode 返回数据流，采用 packet-based streaming：\n\n\n每个 packet 包含若干个 chunk + 校验和。\n\n\n客户端校验后确认。\n\n\n\n\n\n\n写流程\n\n\n客户端先联系 pipeline 第一个 DN，发送写 block 请求。\n\n\nDN1 接收后写本地，同时转发给 DN2；DN2 再转发给 DN3 …\n\n\n最后 ACK 按链路逆序返回 → 客户端。\n\n\n\n\n特点\n\n\n高吞吐流式传输\n\n\n使用 校验和 (CRC32) 确保数据完整性。\n\n\nDataNode ↔ NameNode\n这部分不涉及文件数据，而是 心跳与元数据汇报。\n协议\n\n\nHadoop RPC（ResourceManager 也用这一套）\n\n\nDataNode 向 NameNode 提供 DatanodeProtocol 接口。\n\n\n典型通信\n\n\n心跳（Heartbeat）：默认 3s，汇报 DataNode 状态（磁盘使用量、负载等）。\n\n\nBlock Report：默认 1 小时一次，汇报自己持有的所有 block 列表。\n\n\nIncremental Block Report：增量汇报新增或删除的 block。\n\n\n命令下发：NameNode 也会通过心跳响应下发命令（如复制、删除 block）。\n\n\nDataNode ↔ DataNode\n协议\nDataNode ↔ DataNode 之间使用的协议 并不是新的协议，而是和 Client ↔ DataNode 一样的：\n\n\nDataTransferProtocol\n\n\n基于 TCP\n\n\n用于数据的读写、复制、转发\n\n\n内部是 packet + checksum 的流式格式\n\n\n\n\n也就是说：\n\n\nClient → DN1 → DN2 → DN3 的 流水线写入，用的就是 DataTransferProtocol。\n\n\nDN_A → DN_B 的 副本复制，也是用 DataTransferProtocol，只不过是由 DataNode 发起，而不是客户端。\n\n\n典型场景\n\n\n写入副本（replication pipeline）\n\n\n当客户端写文件时，NameNode 分配副本链（DN1 → DN2 → DN3）。\n\n\n客户端只把数据推给第一个 DataNode（DN1）。\n\n\nDN1 会 转发数据 给 DN2，DN2 再转发给 DN3。\n\n\n这就是 pipeline 写入，实质上是 DataNode 之间的数据转发。\n\n\n\n\n副本恢复 / 冗余复制\n\n\nNameNode 发现某个 block 的副本丢失或不足（例如某个 DataNode 宕机）。\n\n\n它会通过 心跳命令指示某个 DataNode 去“复制 block 到另一个 DataNode”。\n\n\n此时，源 DataNode 会把本地的 block 通过数据传输协议发给目标 DataNode。\n\n\n\n\n\n总结表\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n通信对端协议/接口用途Client ↔ NameNodeHadoop RPC / ClientProtocol元数据操作：文件创建、查询、关闭Client ↔ DataNodeDataTransferProtocol数据流传输（读写 block）DataNode ↔ NameNodeHadoop RPC / DatanodeProtocol心跳、block 报告、命令下发DataNode ↔ DataNodeDataTransferProtocol副本复制、写入流水线转发（replication pipeline）\n补充\n\n\nHadoop RPC 本质上是 TCP + Protobuf + 动态代理，有点像轻量级的 gRPC。\n\n\nDataTransferProtocol 是 面向流的私有协议，不是 RPC，而是固定格式的二进制数据包。\n\n\n客户端一般只跟 NameNode RPC 和 DataNode DataTransfer 打交道；\nDataNode 和 NameNode 则靠心跳 RPC 保持一致性。\n\n\nHDFS体系结构的局限性\n\nHDFS的设计理念是“一次写入，多次读取”，本身不支持文件的随机写入，如果要进行修改，只能将整个文件读取到客户端完成修改后再整个写回HDFS\n命名空间的限制：命名空间保存在名称节点，系统的总容纳量受到名称节点内存的限制\n性能瓶颈：整个分布式文件系统只有一个名称节点，吞吐量受限于名称节点的处理能力\n隔离问题：只有一个名称节点，无法对不同的应用程序进行隔离\n集群可用性：一旦名称节点损坏，集群会变得不可用\n"},"分布式/hadoop/HDFS/HDFS概述":{"slug":"分布式/hadoop/HDFS/HDFS概述","filePath":"分布式/hadoop/HDFS/HDFS概述.md","title":"HDFS概述","links":[],"tags":[],"content":"文件系统基本常识\n在文件系统中，所有的磁盘内容会以文件和目录的形式呈现给用户。不同的文件系统（如 NTFS、ext4、FAT32）有各自独特的命名空间，即文件路径的组织结构。\n物理磁盘结构\n在磁盘的物理层面，磁盘被分为扇区（Sector）。每个扇区的大小通常为512字节或4KB。多个扇区组成簇（Cluster，或称块Block），一个簇是文件系统在存储数据时的基本单位，通常一个簇的大小是4KB、8KB或更大。文件系统将文件数据按簇来存储，簇的大小会影响磁盘空间的利用率。\n文件的数据和元数据\n\n文件数据：是指文件的实际内容，存储在磁盘上用于保存用户信息的部分。\n文件元数据：包含文件的属性信息，如：\n\n文件的时间戳：记录文件的创建时间、修改时间和最后访问时间。\n文件的所有者：表示文件的拥有者，通常与文件的权限系统相关。\n文件的权限：描述谁可以读取、写入或执行文件。\n文件的物理位置：文件在磁盘上的存储位置，指示文件数据存储在哪些簇中。文件系统会根据这些信息管理文件的读写操作。\n\n\n\n此外，文件元数据通常还包括文件名、大小、文件类型等信息。文件系统利用这些元数据来管理文件的存取、删除和权限控制。\n其他补充：\n\n目录结构：文件系统通过目录来组织文件，这些目录形成一个层级结构，类似树状结构，帮助用户和程序更方便地存取文件。\n磁盘管理：文件系统还会管理磁盘的空间使用情况，如空闲空间管理、文件分配表（如FAT表）或inode结构（如在Unix类文件系统中使用）。\n\n分布式文件系统\n节点分为两类：名称节点（namenode）和数据节点（datanode）。\n名称节点负责存储元数据，数据节点负责存储块数据。\nHDFS的特性：\n\n优点\n\n流数据读写\n大型数据读写（tb pb级别）\n一次写入，多次读取\n\n\n缺点\n\n不支持随机写入\n\n\n\n块（Block）\nHDFS默认一个块128mb,HDFS块的大小远远大于普通文件系统，可以最小化寻址开销。\n\n支持大规模文件读写，文件分块存储到不同的节点，所以系统可以存储大于任一节点容量的文件。\n简化系统设计，由于块的大小是固定的，可以很方便地计算出各个节点需要存储多少个块，而且元数据和文件数据想分离，方便管理。\n适合数据冗余备份。\n不适合存储大量小文件，因为每个文件至少占一个块，存储大量小文件会严重影响寻址效率 。\n\n名称节点（NameNode）\n名称节点负责管理分布式文件系统的命名空间（Namespace），保存了两个核心数据结构：Fsimage、EditLog.\n\nFsimage用于维护文件系统树以及文件树中所有文件和文件夹的元数据。\nEditLog操作日志文件记录了所有针对文件的创建、删除、重命名等操作的日志。\n\n命名空间 (Namespace)\nHDFS 的命名空间类似于传统文件系统中的目录结构，它存储文件的路径信息、目录信息和文件的相关属性（如权限、所有者等）。命名空间管理了文件和目录之间的关系，确保文件和目录的路径唯一性。它由 NameNode 管理，NameNode 是 HDFS 中的核心组件，负责所有与文件系统元数据相关的请求。\n\n命名空间 存储着文件系统的结构和文件的所有元数据。它包含了所有的文件和目录信息，如文件路径、权限、所有者、时间戳等。\n\nfsimage\nfsimage 是一个包含整个文件系统命名空间快照的文件。它是 HDFS 元数据的持久化存储，记录了文件系统的状态。每当 HDFS 启动时，NameNode 会加载 fsimage 文件中的内容，恢复文件系统的状态。\n\nfsimage 记录了从文件系统启动以来所有元数据的最终状态，表示文件系统的持久化快照。它是一个完整的文件系统元数据的静态镜像。\n每次 HDFS 启动时，NameNode 会从磁盘加载 fsimage 文件，恢复元数据的最新状态。fsimage 文件的存在保证了即使在系统重启后，也能够恢复到最近的持久化状态。\n\neditlog\neditlog 是一个日志文件，记录了所有对 HDFS 命名空间的修改操作。每次对文件系统进行更改（例如创建文件、删除文件、修改权限等），这些更改都会被写入 editlog 文件。\n\neditlog 记录了每次对命名空间进行修改的操作，且仅记录增量修改。它用于保证在 NameNode 崩溃或重启后能够恢复到修改发生时的状态。\n与 fsimage 不同，editlog 是增量记录，存储了对文件系统的所有修改操作。editlog 会不断增长，会定期通过第二名称节点进行 Checkpointing 合并。\n\n第二名称节点 (Secondary NameNode) 与 Checkpointing\n在 HDFS 中，Secondary NameNode 并不是主 NameNode 的备份，它的主要职责是辅助主 NameNode 进行 Checkpointing，以防止 editlog 文件无限增长，保证文件系统元数据的稳定性和可恢复性。\n主要职责\n\n定期从主 NameNode 下载当前的 fsimage 文件和累积的 editlog 文件。\n将 fsimage 和 editlog 合并，生成新的、包含最新修改的 fsimage 文件。\n将新的 fsimage 文件上传回主 NameNode，并通知主 NameNode 清空已合并的 editlog，从而防止 editlog 无限增长。\n\nCheckpointing 流程\n\n\n获取文件\nSecondary NameNode 定期与主 NameNode 通信，获取当前最新的 fsimage 文件以及自上次 Checkpointing 之后积累的 editlog 文件。\n\n\n合并操作\nSecondary NameNode 在本地将 editlog 文件中的所有操作应用到 fsimage 中，生成一个新的 fsimage 文件。这一步保证了新的 fsimage 包含了最新的文件系统元数据状态。\n\n\n上传更新\n将新的 fsimage 文件上传回主 NameNode，主 NameNode 替换旧的 fsimage，同时清空已经合并到 fsimage 中的 editlog，从而减小 editlog 文件大小，保证系统稳定。\n\n\nSecondary NameNode 的特点\n\n不是备份 NameNode：它不能在主 NameNode 故障时直接替代 NameNode。\n降低恢复成本：通过定期合并 fsimage 和 editlog，减少 NameNode 崩溃时恢复操作所需应用的 editlog 数量。\n提高系统稳定性：避免 editlog 文件过大导致 NameNode 重启和恢复变慢。\n\n总结\nSecondary NameNode 的核心作用是 辅助 Checkpointing：\n\n保证 fsimage 快照与 editlog 的增量修改同步；\n防止 editlog 文件无限增长；\n降低主 NameNode 崩溃后的恢复成本。\n\n通过 Secondary NameNode 的定期 Checkpointing，HDFS 能够保持命名空间元数据的持久性和一致性，同时提高系统的健壮性和可靠性。\n概述总结\n\n命名空间 由 NameNode 管理，存储文件系统的元数据。\nfsimage 是文件系统的快照，包含命名空间的完整状态，作为文件系统元数据的持久化存储。\neditlog 记录文件系统对命名空间的增量修改，确保文件系统的最新状态能够恢复。\nCheckpointing 通过将 fsimage 和 editlog 合并来避免 editlog 文件过大，并定期生成新的 fsimage 文件。\nSecondary NameNode 定期从主 NameNode 获取 fsimage 和 editlog，进行合并操作，并将新的 fsimage 返回给主 NameNode。\n\n这样，fsimage 和 editlog 的相互作用确保了 HDFS 能够高效、持久地管理文件系统元数据，并能够在发生故障时快速恢复。"},"分布式/hadoop/HDFS/HDFS的读写过程":{"slug":"分布式/hadoop/HDFS/HDFS的读写过程","filePath":"分布式/hadoop/HDFS/HDFS的读写过程.md","title":"HDFS的读写过程","links":["分布式/hadoop/HDFS/HDFS体系结构","分布式/hadoop/HDFS/HDFS概述","tags/"],"tags":[""],"content":"相关的 Java 类与 IO 对象\n抽象层次\n\n\norg.apache.hadoop.fs.FileSystem\n\n\nHadoop 的文件系统抽象类。\n\n\n本地文件系统是 LocalFileSystem。\n\n\nHDFS 是 DistributedFileSystem。\n\n\n\n\norg.apache.hadoop.fs.Path\n\n表示 HDFS 的路径对象。\n\n\n\n输入类（读）\n\n\nFSDataInputStream\n\n\nHadoop 的输入流，支持 seek()。\n\n\n内部通过 DFSInputStream 管理与 DataNode 的通信。\n\n\n类似 java.io.DataInputStream，但能随机定位。\n\n\n\n\n输出类（写）\n\n\nFSDataOutputStream\n\n\nHadoop 的输出流，支持写入。\n\n\n内部用 DFSOutputStream 来分片、分块、写 pipeline。\n\n\n类似 java.io.DataOutputStream。\n\n\n\n\nHDFS 读流程 (Read Path)\n\n\n客户端请求文件\n\n\n客户端通过 FileSystem fs = FileSystem.get(conf) 获取一个 DistributedFileSystem 实例。\n\n\n执行 FSDataInputStream in = fs.open(new Path(&quot;/path/file.txt&quot;))。\n\n\n内部会先通过 RPC(Client ↔ NameNode)向 NameNode 请求这个文件的 元数据(名称节点（NameNode）)（block 列表、每个 block 存在哪些 DataNode）。\n\n\n\n\n获取数据块位置\n\n\nNameNode 返回：文件的 block 信息（blockID、偏移量、长度、DataNode 地址列表）。\n\n\n相同的block有存储冗余，客户端会根据块所在的DataNode的距离、负载状况等选择其中合适的一份来读取。\n\n\n\n\n与 DataNode 通信\n\n\n客户端直接与 DataNode 建立 连接进行读取[Client ↔ DataNode。\n\n\n通过 BlockReader 类来逐块读取数据。\n\n\nFSDataInputStream 支持 seek()，所以可以随机访问大文件的任意偏移。\n\n\n\n\nHDFS 写流程 (Write Path)\n\n\n客户端请求创建文件\n\n\n调用 FSDataOutputStream out = fs.create(new Path(&quot;/path/file.txt&quot;))。\n\n\n客户端通过 RPCClient ↔ NameNode 向 NameNode 申请在命名空间中新建文件。\n\n\nNameNode 检查是否存在、权限是否允许，然后返回是否可写。\n\n\n\n\n数据切分为 block\n\n\n客户端将数据写入 DFSOutputStream，它会把数据拆分成 block。\n\n\n每个 block 默认大小 128MB（dfs.blocksize 可配置）。\n\n\n\n\nNameNode 分配 DataNode 管道\n\n\n客户端向 NameNode 请求：我要写下一个 block。\n\n\nNameNode 返回一个 DataNode 列表（如副本数=3，返回3个节点地址）。\n\n\n客户端建立一个 pipeline：client → DN1 → DN2 → DN3。Client ↔ DataNode\n\n\n\n\n流水线写入\n\n\n客户端先把数据流送到第一个 DataNode。\n\n\nDN1 写本地后再转发给 DN2，DN2 再转发 DN3。\n\n\n每个 DataNode 都会返回 ACK，最终确认写成功。\n\n\n\n\n关闭文件\n\n\n客户端调用 out.close()。\n\n\nDFSOutputStream 通知 NameNode 文件写完。\n\n\nNameNode 将最终的文件元数据标记为“完成”，之后其他客户端可以读。\n\n\n\n\n 二、写流程中的 editlog 更新\n写入时 NameNode 要维护 命名空间一致性，它的 editlog（增量日志）记录了对文件系统的元数据修改。\n流程可以分两类更新：\n\n\n文件创建时\n\n\n客户端 create(&quot;/path/file&quot;) → RPC 到 NameNode\n\n\nNameNode 在内存元数据中加一个“正在写”的文件条目\n\n\n并立即写入一条 OP_ADD (新增文件) 到 editlog\n\n\n\n\n分配 block 时\n\n\n客户端缓存数据达到 block 大小或 close() 时 → 请求 NameNode 分配新 block\n\n\nNameNode 在内存中给文件分配一个新的 blockID，并决定副本放在哪些 DataNode\n\n\nNameNode 写入一条 OP_ADD_BLOCK (增加 block) 到 editlog\n\n\n然后把 DataNode 列表返回给客户端\n\n\n客户端才去和 DataNode 建 pipeline，传输数据\n\n\n\n\n文件关闭时\n\n\nDFSOutputStream管理的pipeline会收集所有DataNode的写入ACK,得到所有ACK后返回给客户端\n\n\n客户端 close() → RPC 到 NameNode\n\n\nNameNode 把该文件标记为 complete\n\n\n写入一条 OP_CLOSE (关闭文件) 到 editlog\n\n\n\n\n关键点\n\n\nDataNode pipeline 传输\nDataNode 之间的复制、校验、确认 不涉及 NameNode，完全是客户端和 DataNode 之间协作完成的。\nNameNode 只在“分配 block、完成 block”时写 editlog。\n\n\neditlog 内容\neditlog 是纯元数据操作日志，不记录实际数据内容。\n它记录的操作包括：文件创建、删除、添加 block、副本位置、关闭文件等。\n\n\n最终一致性\n\n客户端写完数据后，只有在 close() 之后，NameNode 才把文件标记为完成（否则文件一直是“正在写”状态）。  这时 editlog 里已经有了完整的 create + addBlock + close 三类记录。\n如果中途客户端宕机，NameNode也可以通过周期性心跳和block report向NomaNode汇报。\n\n\n"},"数据结构与算法/算法技巧笔记/二分法":{"slug":"数据结构与算法/算法技巧笔记/二分法","filePath":"数据结构与算法/算法技巧笔记/二分法.md","title":"二分法","links":[],"tags":[],"content":"算法描述\n在连续且有限的数组中搜索符合条件的值时可以使用二分法，复杂度为O(\\log{n}).\n基本结构如下\nleft=0;\nright=arr.length-1;\nwhile (CONDATION(left,right)){\n\tmid=MID(left,right);\n\tif (P(mid))\t{\n\t\tUPDATE_LEFT(left);\t\n\t}\n\telse{\n\t\tUPDATE_RIGHT(right);\t\n\t}\n}\nreturn CHOICE(left,right,mid);\n\n其中CONDITON,MID,P,UPDATE_LEFT,UPDATE_RIGHT,CHOICE都是需要根据具体问题来确定的算法。\n\n搜索空间是一个以left和right为边界的包含目标值的区间，迭代过程中搜索空间不断缩小，直到求出解，退出while循环，在while循环迭代的过程中维护这个区间有如下两种处理手段：\n\n闭区间\n半开区间（左闭右开,即right值不在搜索空间内）\n\n\nCONDITION表示left与right之间的大小关系规则，用于控制while循环的退出时机，有两种选择\n\nleft&lt;right\nleft&lt;=right\n\n\nMID是根据left和right生成中值mid的规则，一般有两种选择：\n\n上取中(upper-mid):mid=left+(right-left+1)/2\n下取中(lower-mid):mid=left+(right-left)/2\n\n\n单调谓词P是一个关于数组下标i单调的布尔函数(存在j使得i \\leq j,P(i)=1,i&gt;j,P(i)=0 \\text{或} i \\leq j P(i)=0,i&gt;j,P(i)=1，由实际问题决定\nUPDATE_LEFT是二分缩小搜索范围时更新left的规则，一般有如下选择：\n\nleft=mid\nleft=mid+1\n\n\nUPDATE_RIGHT是二分缩小搜索范围时更新right的规则，一般有如下选择：\n\nright=mid\nright=mid-1\n\n\nCHOICE:while循环退出，完成搜索后，根据不同的问题，最终需要的搜索结果可能在left，mid,right所指向的位置，根据实际问题选择\n\n下表揭示了由上述关键点描述的二分法问题的求解思路\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n单调谓词形态区间语义循环条件mid 取法更新规则（真 / 假）退出返回备注000111（第一个为真 / First True）[l, r)l &lt; r下取中P(mid) 真 → r = mid； 否则 l = mid + 1返回 l推荐：标准 lower_bound / upper_bound 改条件即用000111（第一个为真）[l, r]l &lt; r下取中P(mid) 真 → r = mid； 否则 l = mid + 1返回 l（与 r 相等）也可用；闭区间写法，语义清晰111000（最后一个为真 / Last True）[l, r]l &lt; r上取中P(mid) 真 → l = mid； 否则 r = mid - 1返回 l（=r）推荐：找“最后一个满足”的标准模板111000（最后一个为真）[l, r)l &lt; r下取中P(mid) 真 → l = mid + 1； 否则 r = mid返回 l - 1等价于“找第一个假再减一”；同样稳\nleft&lt;right足以描述绝大多数二分法问题，所以这套求解方案没有涉及循环条件为left&lt;=right的选项，但在某些特定情形下，小于等于可能更简洁。\n举例\n000111 × 半开区间 [l, r)（First True / 下界 lower_bound）\n问题：在非降序数组中，找第一个 ≥ x 的位置（下界）。\nP(i)：a[i] ≥ x（形如 000111）。\n区间：[l, r)；\n循环：l &lt; r；\n取中：下取中；\n更新：P(mid) 真 → r = mid； 否则 → l = mid + 1；返回：l。\n示例：a = [1,2,2,3,5]，x=2 → 期望返回 1。\n极端：x=4 → 返回 4；x=6 → 返回 5(=n)。\nint lower_bound(int *a, int n, int x){\n    int l = 0, r = n;                    // [l, r)\n    while (l &lt; r){\n        int mid = l + (r - l) / 2;       // 下取中\n        if (a[mid] &lt; x) l = mid +1;        // P(mid) 真\n        else             r = mid;\n    }\n    return l;\n}\n000111 × 闭区间 [l, r]（First True 的闭区间写法）\n问题：LeetCode 278「第一个错误版本」——找第一个 isBadVersion(i)=true 的版本号。\nP(i)：isBadVersion(i)（000111）。\n区间：[l, r]；\n循环：l &lt; r；\n取中：下取中；\n更新：P(mid) 真 → r = mid； 否则 → l = mid + 1；返回：l(=r)。\n示例：n=7，错误从 4 开始 → 返回 4。\nint first_bad(int n){\n    int l = 1, r = n;                    // 版本号从 1 开始\n    while (l &lt; r){\n        int mid = l + (r - l) / 2;       // 下取中\n        if (isBadVersion(mid)) r = mid;  // P(mid) 真\n        else                    l = mid + 1;\n    }\n    return l;\n}\n111000 × 闭区间 [l, r]（Last True / 最后一个 ≤ x）\n问题：在非降序数组中，找最后一个 ≤ x 的位置（等价于 upper_bound(x)-1）。\nP(i)：a[i] ≤ x（111000）。\n区间：[l, r]；循环：l &lt; r；取中：上取中；\n更新：P(mid) 真 → l = mid； 否则 → r = mid - 1；返回：l(=r)。\n示例：a = [1,2,2,3,5]，x=2 → 返回 2；x=4 → 返回 3；x=0 → 返回 -1（需额外判空）。\nint last_leq(int *a, int n, int x){\n    if (n == 0) return -1;\n    int l = 0, r = n - 1;\n    // 如果最小值都 &gt; x，可提前返回 -1（省略也行，最后判断）\n    if (a[l] &gt; x) return -1;\n    while (l &lt; r){\n        int mid = l + (r - l + 1) / 2;   // 上取中\n        if (a[mid] &lt;= x) l = mid;        // P(mid) 真\n        else             r = mid - 1;\n    }\n    return l;\n}\n111000 × 半开区间 [l, r)（Last True 的半开区间写法：返回 l-1）\n问题：旋转升序数组（无重复）中找最大值下标（pivot）。\nP(i)：a[i] ≥ a[0]（111000）。\n区间：[l, r)；循环：l &lt; r；取中：下取中；\n更新：P(mid) 真 → l = mid + 1； 否则 → r = mid；\n返回：l - 1（因为 l 会停在“第一个假”的位置）。\n示例：a=[4,5,6,7,0,1,2] → 返回 3；未旋转 a=[1,2,3] → 返回 2。\nint pivot_max(int *a, int n){\n    int l = 0, r = n;                    // [l, r)\n    while (l &lt; r){\n        int mid = l + (r - l) / 2;       // 下取中\n        if (a[mid] &gt;= a[0]) l = mid + 1; // P(mid) 真\n        else                r = mid;\n    }\n    return l - 1;                        // 最后一个为真\n}\n\n小结\n\n\nFirst True（000111）：\n\n\n半开模板：[l,r) + 下取中 + r=mid / l=mid+1 → 返回 l。\n\n\n闭区模板：[l,r] + 下取中 + r=mid / l=mid+1 → 返回 l(=r)。\n\n\n\n\nLast True（111000）：\n\n\n闭区模板：[l,r] + 上取中 + l=mid / r=mid-1 → 返回 l。\n\n\n半开模板：[l,r) + 下取中 + l=mid+1 / r=mid → 返回 l-1。\n\n\n\n"},"数理统计2/回归/一元线性回归/1.基本假设":{"slug":"数理统计2/回归/一元线性回归/1.基本假设","filePath":"数理统计2/回归/一元线性回归/1.基本假设.md","title":"1.基本假设","links":[],"tags":[],"content":"解释变量x_,\\cdots,x_p非随机变量，样本\\{(y_i,X_i) \\mid 1\\leq i\\leq n\\}观测值x_{i1},\\cdots ,x_{ip}为常数\n误差项随机变量\\epsilon 满足\nE[\\epsilon_i]=0,i=1\\cdots ,n \n\\begin{cases}\n\\text{Var}(\\epsilon_i) = \\sigma^2, &amp; i = 1, \\cdots, n \\\\\n\\text{Cov}(\\epsilon_i, \\epsilon_j) = 0, &amp; i \\neq j\n\\end{cases}\n即各样本点上的误差项均值为零、方差相同且相互独立。"},"数理统计2/回归/一元线性回归/2.最小二乘估计OLSE":{"slug":"数理统计2/回归/一元线性回归/2.最小二乘估计OLSE","filePath":"数理统计2/回归/一元线性回归/2.最小二乘估计OLSE.md","title":"2.最小二乘估计OLSE","links":[],"tags":[],"content":"求解一元线性回归模型，就是要给出真实回归模型y=\\beta_1x+\\beta_0中\\beta_0,\\beta_1的估计\\hat{\\beta_0},\\hat{\\beta_1}.但由于残差项\\epsilon的分布类型是未知的，无法推理出y的分布类型，进而估计，于是采用最小二乘法估计\\beta_0,\\beta_1.\n最小二乘估计求出的回归方程，成为一元线性经验回归方程。\n\\hat{y}=\\hat{\\beta_1}x+\\hat{\\beta_0}\n算法\n目的为最小化总拟合误差\\left|y_i-\\hat{\\beta_1}x-\\hat{\\beta_0}\\right|.\n构造目标函数\nQ(\\gamma_0,\\gamma_1)=\\Sigma_{i=1}^n(y_i-\\gamma_0-\\gamma_1x)^2\nQ是凸函数，\n\\left\\{\n\\begin{aligned}\n\\frac{\\partial{Q}}{\\partial{\\gamma_0}} &amp;= 0 \\\\\n\\frac{\\partial{Q}}{\\partial{\\gamma_1}} &amp;= 0 \n\\end{aligned}\n\\right.\n满足上述方程组的\\gamma_0,\\gamma_1即为最小二乘估计\\hat{\\beta_0},\\hat{\\beta_1}\n\\left\\{\n\\begin{aligned}\n\\hat{\\beta_1} &amp;= \\frac{L_{xy}}{L_{xx}} \\\\\n\\hat{\\beta_0} &amp;= \\bar{y}-\\hat{\\beta_1}x\n\\end{aligned}\n\\right.\n其中\n\\left\\{\n\\begin{aligned}\nL_{xx}&amp;=\\Sigma(x_i-\\bar{x})^2 \\\\\nL_{xy}&amp;=\\Sigma(x_i-\\bar{x})(y_i-\\bar{y})\n\\end{aligned}\n\\right."},"数理统计2/回归/一元线性回归/3.回归系数的性质":{"slug":"数理统计2/回归/一元线性回归/3.回归系数的性质","filePath":"数理统计2/回归/一元线性回归/3.回归系数的性质.md","title":"3.回归系数的性质","links":[],"tags":[],"content":"线性性\n\\hat{\\beta_1},\\hat{\\beta_0}是 随机变量y_i的线性函数\n无偏性\n\\begin{aligned}\nE\\hat{\\beta_1} &amp;=E[\\frac{\\Sigma_{i=1}^n (x_i-\\bar{x})y_i}{\\Sigma_{i=1}^n(x_i-\\bar{x})^2}] \\\\\n\t\t\t   \n\t\t\t   &amp;=\\frac{\\Sigma_{i=1}^n (x_i-\\bar{x})E[y_i]}{\\Sigma_{i=1}^n(x_i-\\bar{x})^2} \\\\\n\t\t\t   \n\t\t\t   &amp;=\\frac{\\Sigma_{i=1}^n (x_i-\\bar{x})(\\beta_1x_i+\\beta_0)}{\\Sigma_{i=1}^n(x_i-\\bar{x})^2} \\\\\n\t\t\t   \n\t\t\t   &amp;=\\frac{\\Sigma_{i=1}^n (x_i-\\bar{x})x_i}{\\Sigma_{i=1}^n(x_i-\\bar{x})^2}\\beta_1 \\\\\n\t\t\t   \n\\end{aligned}\n其中\\frac{\\Sigma_{i=1}^n (x_i-\\bar{x})x_i}{\\Sigma_{i=1}^n(x_i-\\bar{x})^2}=1 \n故E\\hat{\\beta_1}=\\beta_1,同理可证E\\hat{\\beta_0}=\\beta_0\n方差\n由于y_1,\\cdots,y_n独立，var(y_i)=\\sigma^2\n故$$\n\\begin{aligned}\nVar(\\hat{\\beta_1}) &amp;= \\Sigma_{i=1}^{n} [\\frac{x_i - \\bar{x}}{\\Sigma_{i=1}^n (x_i-\\bar{x})^2}]^2 Var(y_i)\\\n&amp;= \\frac{\\sigma^2}{L_{xx}}\n\\end{aligned}\n\nVar(\\hat{\\beta_0})=[\\frac{1}{n}+\\frac{\\bar{x}^2}{L_{xx}}]\\sigma\n"},"数理统计2/回归/一元线性回归/4.误差随机变量方差的估计":{"slug":"数理统计2/回归/一元线性回归/4.误差随机变量方差的估计","filePath":"数理统计2/回归/一元线性回归/4.误差随机变量方差的估计.md","title":"4.误差随机变量方差的估计","links":[],"tags":[],"content":"\\hat{\\sigma}^2 = \\frac{1}{n-2} \\sum (y_i - \\hat{y}_i)^2\n其中\n\\hat{y}_i = \\hat{\\beta}_0 + \\hat{\\beta}_1 x_i"},"数理统计2/回归/一元线性回归/5.显著性检验":{"slug":"数理统计2/回归/一元线性回归/5.显著性检验","filePath":"数理统计2/回归/一元线性回归/5.显著性检验.md","title":"5.显著性检验","links":[],"tags":[],"content":"H_0: \\beta_1 = 0 \\quad\\text{vs.}\\quad H_1: \\beta_1 \\neq 0\nt检验\n在假定误差项满足独立同分布，且 \\varepsilon_i \\sim N(0, \\sigma^2) 的条件下：\n回归系数估计的分布\n假设\\epsilon_i \\sim N(0,\\sigma^2） 则\\hat{\\beta}_1 \\sim N\\left(\\beta_1, \\dfrac{\\sigma^2}{L_{xx}}\\right)  ，其中  L_{xx} = \\sum (x_i - \\bar{x})^2\n在 H_0 下，有\nt = \\frac{\\hat{\\beta}_1 - 0}{\\sqrt{\\hat{\\sigma}^2 / L_{xx}}} \\sim t_{n-2}\nF检验：直接从回归效果检验显著性\n平方和分解式\n\\sum_{i=1}^{n} (y_i - \\bar{y})^2 = \\sum_{i=1}^{n} (\\hat{y}_i - \\bar{y})^2 + \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2\n\n称 \\sum_{i=1}^{n} (y_i - \\bar{y})^2 为总离差平方和 (SST)，描述观测值 y 本身的方差\n称 \\sum_{i=1}^{n} (\\hat{y}_i - \\bar{y})^2 为回归平方和 (SSR)\n称 \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2 为残差平方和 (SSE)\n\nSST = SSR + SSE\n证明:\n即证\n\\sum_{i=1}^{n} (y_i - \\hat{y}_i + \\hat{y}_i - \\bar{y})^2 = \\sum_{i=1}^{n} (y_i - \\bar{y})^2 + \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2\n即证\n\\sum_{i=1}^{n} (y_i - \\hat{y}_i)(\\hat{y}_i - \\bar{y}) = 0\n记残差 e_i = y_i - \\hat{y}_i\n\\frac{\\partial Q}{\\partial \\beta_1} = 2 \\sum x_i (y_i - \\hat{\\beta_1}x_i-\\hat{\\beta_0}) = 0, \\quad \\frac{\\partial Q}{\\partial \\beta_0} = 2 \\sum (y_i - \\beta_0 - \\beta_1 x_i) = 0\n\\Rightarrow e_i = y_i - \\hat{y}_i = y_i - \\hat{\\beta}_0 - \\hat{\\beta}_1 x_i \n\n\\Rightarrow \\sum x_i e_i = \\sum e_i = 0.\n\\begin{aligned}\n&amp;\\sum_{i=1}^{n} (y_i - \\hat{y}_i)(\\hat{y}_i - \\bar{y}) \\\\ \n=&amp;\\sum e_i (\\hat{y}_i - \\bar{y}) =\\sum e_i\\hat{y_i}+\\bar{y}\\sum e_i \\\\\n=&amp;\\sum e_i (\\hat{\\beta}_0 + \\hat{\\beta}_1 x_i) \\\\\n=&amp; \\hat{\\beta}_0 \\sum e_i + \\hat{\\beta}_1 \\sum (e_i x_i) \\\\\n=&amp; 0\n\\end{aligned}\n证毕\n构造F分布进行检验\nSSR 越大，SSE 越小说明回归越好\nH_0: \\beta_1 = 0 \\leftrightarrow H_1: \\beta_1 \\neq 0\n在 H_0 下，F = \\frac{SSR/1}{SSE/(n-2)}，\\frac{SSE}{n-2} \\sim \\chi^2(n-2)，SSR \\sim \\chi^2(1)\n\\Rightarrow F \\xrightarrow{H_0} F(1, n-2)\n皮尔逊相关系数检验\nr = \\frac{\\sum_{i=1}^{n} (x_i - \\bar{x})(y_i - \\bar{y})}{\\sqrt{\\sum (x_i - \\bar{x})^2 \\sum (y_i - \\bar{y})^2}} = \\frac{l_{xy}}{\\sqrt{l_{xx} l_{yy}}}\nr越接近 1 拟合越好"},"数理统计2/回归/一元线性回归/6.残差分析":{"slug":"数理统计2/回归/一元线性回归/6.残差分析","filePath":"数理统计2/回归/一元线性回归/6.残差分析.md","title":"6.残差分析","links":[],"tags":[],"content":"残差分析：判断真实模型是否为线性模型\n若为线性模型则必满足 Ee_i = Ex_i \\cdot e_i = 0\n残差应在 0 附近随机波动\n残差 e_i 的方差\n\\begin{aligned}\nVar(e_i) &amp;= Var(y_i - \\hat{y}_i) \\\\\n&amp;= Var(y_i) + Var(\\hat{y}_i) - 2Cov(y_i, \\hat{y}_i)\n\\end{aligned}\n(1) Var(y_i) = \\sigma^2\n(2)\n\\begin{aligned}\nVar(\\hat{y}_i) &amp;= Var(\\hat{\\beta}_0 + \\hat{\\beta}_1 x_i) \\\\\n&amp;= Var(\\hat{\\beta}_0) + Var(\\hat{\\beta}_1 x_i) + 2Cov(\\hat{\\beta}_0, \\hat{\\beta}_1 x_i) \\\\\n\\end{aligned}\n其中\n\\begin{aligned}\nVar(\\hat{\\beta}_0) &amp;= \\left(\\frac{1}{n} + \\frac{\\bar{x}^2}{L_{xx}}\\right)\\sigma^2 \\\\\n\\\\\nVar(\\hat{\\beta}_1 x_i) &amp;= x_i^2 \\frac{\\sigma^2}{L_{xx}}\\\\\n\\\\\nCov(\\hat{\\beta}_0, \\hat{\\beta}_1) &amp;= Cov(\\bar{y} - \\hat{\\beta}_1 \\bar{x}, \\hat{\\beta}_1) \\\\\n&amp;= Cov(-\\hat{\\beta}_1 \\bar{x}, \\hat{\\beta}_1) + Cov(\\bar{y}, \\hat{\\beta}_1) \\\\\n&amp;= -\\bar{x} Var(\\hat{\\beta}_1) + \\frac{Var(y_i)}{n \\sum (x_i - \\bar{x})^2} \\cdot \\sum (x_i - \\bar{x}) \\\\\n&amp;= -\\bar{x} \\frac{\\sigma^2}{L_{xx}} + 0 \\\\\n\\end{aligned}\n故Cov(\\hat{\\beta}_0, \\hat{\\beta}_1 x_i) = -\\bar{x} x_i \\frac{\\sigma^2}{L_{xx}}\n故\n\\begin{aligned}\nVar(\\hat{y}_i) &amp;= \\left(\\frac{1}{n} + \\frac{\\bar{x}^2}{L_{xx}}\\right)\\sigma^2 + x_i^2 \\frac{\\sigma^2}{L_{xx}} - 2\\bar{x} x_i \\frac{\\sigma^2}{L_{xx}} \\\\\n&amp;= \\left(\\frac{1}{n} + \\frac{(x_i - \\bar{x})^2}{L_{xx}}\\right)\\sigma^2\n\\end{aligned}\n(3)\n\\begin{aligned}\nCov(y_i, \\hat{y}_i) &amp;= Cov(y_i, \\hat{\\beta}_1 x_i + \\bar{y} - \\hat{\\beta}_1 \\bar{x})\\\\\n&amp;= Cov(y_i, \\hat{\\beta}_1 x_i) + (x_i - \\bar{x}) Cov(y_i, \\hat{\\beta}_1) \\\\\n&amp;= \\frac{1}{n} Var(y_i) + (x_i - \\bar{x}) Cov(y_i, \\frac{\\sum (x_i - \\bar{x}) y_i}{L_{xx}}) \\\\\n&amp;= \\frac{1}{n} Var(y_i) + \\frac{(x_i - \\bar{x})^2}{L_{xx}} Var(y_i) \\\\\n&amp;= \\left(\\frac{1}{n} + \\frac{(x_i - \\bar{x})^2}{L_{xx}}\\right)\\sigma^2\n\\end{aligned}\n综上：Var(e_i) = \\sigma^2 + \\left(\\frac{1}{n} + \\frac{(x_i - \\bar{x})^2}{L_{xx}}\\right)\\sigma^2 - 2\\left(\\frac{1}{n} + \\frac{(x_i - \\bar{x})^2}{L_{xx}}\\right)\\sigma^2 = (1 - \\frac{1}{n} - \\frac{(x_i - \\bar{x})^2}{L_{xx}})\\sigma^2 = (1 - \\hat{h}_i)\\sigma^2"},"数理统计2/回归/回归模型":{"slug":"数理统计2/回归/回归模型","filePath":"数理统计2/回归/回归模型.md","title":"回归模型","links":[],"tags":[],"content":"变量x_1,\\cdots,x_p与随机变量y存在相关关系，即确定x_1,\\cdots,x_p的取值后可以确定y的分布，y与x_1,\\cdots,x_p之间的概率模型为y=f(x_i,\\cdots,x_p)+\\epsilon当f为线性函数时，称模型为线性回归模型。"},"数理统计2/概率论与数理统计基础/常用分布":{"slug":"数理统计2/概率论与数理统计基础/常用分布","filePath":"数理统计2/概率论与数理统计基础/常用分布.md","title":"常用分布","links":[],"tags":[],"content":"t分布\n若\\epsilon \\sim N(0,1),\\eta服从自由度为n的\\chi^2分布\\eta \\sim \\chi^2(n),则称随机变量T=\\frac{\\epsilon}{\\sqrt{\\frac{\\eta}{n}}}服从自由度为n的t分布，T \\sim t(n).\nF 分布\n设\\epsilon,\\eta是自由度为m,n的独立的\\chi^2随机变量，则称随机变量F=\\frac{\\epsilon/m}{\\eta/n}所服从的分布为F分布，自由度为(m,n),记作F \\sim F(m,n)."},"数理统计2/概率论与数理统计基础/方差、协方差的性质":{"slug":"数理统计2/概率论与数理统计基础/方差、协方差的性质","filePath":"数理统计2/概率论与数理统计基础/方差、协方差的性质.md","title":"方差、协方差的性质","links":[],"tags":[],"content":"引理\nX,Y独立则对任何函数h,g成立\n E[g(X)g(Y)]=E[g(X)] \\cdot E[h(Y)]\n方差与协方差常用公式\n\n协方差的定义Cov(X,Y)=E[(X-EX)(Y-EY)]=E[XY]-EX \\cdot EY\n交换性：Cov(X,Y)=Cov(Y,X)\n线性性:Coc(aX,Y)=aCov(X,Y) Cov(\\Sigma_{i=1}^nX_i,\\Sigma_{j=1}^mY_j)=\\Sigma_{i=1}^n\\Sigma_{j=1}^m Cov(X_i,Y_j)\n方差展开式：Var(\\Sigma_{i=1}^nX_i)=\\Sigma_{i=1}^nVar(X_i)+2\\Sigma_{i&lt;j}Cov(X_i,X_j)\n"},"深度学习/CNN/1.卷积":{"slug":"深度学习/CNN/1.卷积","filePath":"深度学习/CNN/1.卷积.md","title":"1.卷积","links":[],"tags":[],"content":""},"深度学习/CNN/2.池化":{"slug":"深度学习/CNN/2.池化","filePath":"深度学习/CNN/2.池化.md","title":"2.池化","links":[],"tags":[],"content":""},"深度学习/CNN/3.归一化":{"slug":"深度学习/CNN/3.归一化","filePath":"深度学习/CNN/3.归一化.md","title":"3.归一化","links":[],"tags":[],"content":""},"深度学习/CNN/4.全连接":{"slug":"深度学习/CNN/4.全连接","filePath":"深度学习/CNN/4.全连接.md","title":"4.全连接","links":[],"tags":[],"content":""},"深度学习/deeplearning-basics/1.K近邻":{"slug":"深度学习/deeplearning-basics/1.K近邻","filePath":"深度学习/deeplearning basics/1.K近邻.md","title":"1.K近邻","links":[],"tags":[],"content":"近邻算法\n首先给出一组数据X_{\\mathbf{N} \\times \\mathbf{D}}以及对应的分类标签Y_\\mathbf{N}作为训练数据，数据量为N,特征数为D,类别数m为Y中各不相同的数字的个数。一般来说N&gt;m。\n推理时给出需要推理的D维向量X_{0}，计算它与所有已知标签的向量(即X行向量)的L1距离。\n向量X_0与向量X_j的L1距离定义为：\nd_{L1}=\\sum_{i=1}^{D} |X_0^i-X_j^i|\n找出其中d_{L1}最小的j,对应的Y_j即为X_0的分类标签。\n代码如下：\nclass NeraestNeibour:\n\tdef __init__(self):\n\t\tpass\n\tdef train(self,Xtr,Ytr):\n\t\tself.Xtr=Xtr\n\t\tself.Ytr=Ytr\n\tdef predict(self,X):\n\t\tnum_test=X.shape[0]\n\t\tYpred=np.zeros(num_test,dtype=self.Xtr.dtype)\n\t\tfor i in range(num_test):\n\t\t\td_L1_vec=np.sum(np.abs(self.Xtr-X[i:]),axis=1)\n\t\t\t# d_L1_vec是一个N维向量，记录了X[i]到所有已知标签向量X的L1距离\n\t\t\t# 这行代码利用了numpy的数组广播，求和时axis=1表示沿着列号增大的方向求和\n\t\t\tmin_index=np.argmin(d_L1_vec)\n\t\t\tYpred=self.Ytr[min_index]\n\t\treturn Ypred\nK近邻算法\nK近邻算法是近邻算法的扩展，近邻算法只关心最近的一个点的标签，而K近邻则用最近的K个点的标签进行投票决定未知点的分类标签预测值。计算出d_L1_vec后，取出其中最小的前K名，找出前K名对应的标签，以其中占众数的标签为未知点的预测值。\n代码如下：\nclass KNearestNeighbor:\n    def __init__(self):\n        pass\n    \n    def train(self, Xtr, Ytr):\n        self.Xtr = Xtr\n        self.Ytr = Ytr\n    \n    def predict(self, X, k=1):\n        num_test = X.shape[0]\n        Ypred = np.zeros(num_test, dtype=self.Ytr.dtype)\n        \n        for i in range(num_test):\n            # 计算测试点X[i]与所有训练点的L1距离\n            d_L1_vec = np.sum(np.abs(self.Xtr - X[i]), axis=1)\n            # d_L1_vec是一个N维向量，记录了X[i]到所有已知标签向量X的L1距离\n            \n            # 找出距离最小的k个点的索引\n            min_indices = np.argsort(d_L1_vec)[:k]\n            \n            # 获取这k个最近邻的标签\n            k_nearest_labels = self.Ytr[min_indices]\n            \n            # 找出出现频率最高的标签（众数）\n            unique_labels, counts = np.unique(\n\t            k_nearest_labels,return_counts=True\n\t            )\n            most_frequent_label = unique_labels[np.argmax(counts)]\n            \n            Ypred[i] = most_frequent_label\n            \n        return Ypred\n由此可见，近邻算法本质上就是K=1的K近邻算法\n距离的定义\n上述算法中使用的L1距离在数学上称为曼哈顿距离，常用的还有欧式距离和余弦距离。\n曼哈顿距离 (L1距离)\nd_{L1} = \\sum_{i=1}^{D} |X_0^i - X_j^i|\n欧式距离 (L2距离)\nd_{L2} = \\sqrt{\\sum_{i=1}^{D} (X_0^i - X_j^i)^2}\n余弦距离\nd_{\\cos} = 1 - \\frac{X_0 \\cdot X_j}{||X_0||_2 \\cdot ||X_j||_2}\n其中：\n\nX_0 和 X_j 分别是两个D维向量\n||X||_2 = \\sqrt{\\sum_{i=1}^{D} X_i^2} 是向量的L2范数\n\n各距离的特点k：\n\n曼哈顿距离：计算路径长度，对异常值相对不敏感\n欧式距离：最直观的距离度量，在欧几里得空间中两点间直线距离\n余弦距离：关注向量的方向而非大小，适用于文本分类等场景\n\n参数K的选择\n上述K近邻算法并不是标准意义上的深度学习，因为它是一套固定的运算机制，只能算作一种程序算法。\n在K近邻算法中，参数K原本是一个需要手动选择的超参数，但在深度学习中，我们可以考虑让模型来自动选择超参数，对超参数的自动选择是深度学习的关键。\n将训练数据分为互不相交的三个部分：训练集(training)、验证集(validation)、测试集(test)\n注：严格来讲，数据的三部分不仅需要不相交，他们需要在概率意义上独立。\n在机器学习和深度学习中，如果数据量较小，往往采用各种重抽样的方式对数据进行增强，将重抽样的数据进行训练集、验证集、测试集划分是错误的，因为尽管每条数据之间各不相同，但它们在概率意义上不独立。正确的做法是先划分再重抽样增强。\n算法遵循以下步骤：\n\n1.我门们先给定K\n2.在训练集上得到分类模型\n3.在验证集上进行推理\n4.比对推理结果与验证集标签并计算正确率\n5.调节参数K并重复步骤2至5直到得到满意的超参数K\n6.在测试集上推理并计算最终模型的准确率\n\n注意：一个常见的误区是，只将数据分为训练集和测试集，在测试集上调节参数K,最终在测试集上计算模型准确率，这种方法是错误的。测试集相当于一场考试，验证集是模拟考试，如果模拟考试和真实的考试题目一样，那么就失去了学习和考试的意义。这样得到的模型准确率是虚高的。"},"深度学习/deeplearning-basics/2.线性分类器":{"slug":"深度学习/deeplearning-basics/2.线性分类器","filePath":"深度学习/deeplearning basics/2.线性分类器.md","title":"2.线性分类器","links":["深度学习/deeplearning-basics/3.softmax损失","深度学习/deeplearning-basics/4.SVM损失"],"tags":[],"content":"基本思想\n线性分类器是一类通过 输入特征的线性组合 来进行分类的模型。\n其核心思想是用一个超平面将不同类别的数据分开。\n数学形式\n给定输入向量 x \\in \\mathbb{R}^d，权重矩阵 W \\in \\mathbb{R}^{d \\times K}，偏置向量 b \\in \\mathbb{R}^K，\n线性分类器的输出（logits）为：\ns = W^\\top x + b\n其中 s \\in \\mathbb{R}^K，表示对 K 个类别的打分。\n预测类别为：\n\\hat{y} = \\arg\\max_j s_j\n常见的线性分类器\n\n\n感知机（Perceptron）\n\n使用符号函数作为分类依据\n仅能处理线性可分的数据\n\n\n\n逻辑回归（Logistic Regression）\n\n使用 sigmoid/softmax3.softmax损失 将线性输出转为概率\n损失函数：对数似然（交叉熵）\n\n\n\n支持向量机（SVM）\n\n通过最大化间隔来寻找最优超平面\n损失函数：合页损失（hinge loss）4.SVM损失\n\n\n"},"深度学习/deeplearning-basics/3.softmax损失":{"slug":"深度学习/deeplearning-basics/3.softmax损失","filePath":"深度学习/deeplearning basics/3.softmax损失.md","title":"3.softmax损失","links":[],"tags":[],"content":"1. 熵（Entropy）\n熵是信息论中的概念，用来度量一个随机变量的不确定性。\n设离散随机变量 X 可能的取值为 {x_1, x_2, \\dots, x_n}，概率分布为\nP(X=x_i) = p_i, \\quad \\sum_{i=1}^n p_i = 1  \n熵的定义是：\nH(P) = -\\sum_{i=1}^n p_i \\log p_i  \n意义：概率分布越均匀，熵越大（不确定性高）。概率分布越集中，熵越小。\n\n2. 交叉熵（Cross-Entropy）\n交叉熵用来度量两个分布 (P) 和 (Q) 之间的差异，其中：\n\n\nP = (p_1, p_2, \\dots, p_n) 表示真实分布（ground truth）\n\n\nQ = (q_1, q_2, \\dots, q_n) 表示预测分布（模型输出）\n\n\n交叉熵定义为：\nH(P, Q) = -\\sum_{i=1}^n p_i \\log q_i  \n在分类问题中，真实标签通常是 one-hot 向量，比如真实类别是第 (k) 类，则：\nH(P, Q) = - \\log q_k  \n这就是常用的分类损失函数 交叉熵损失（Cross-Entropy Loss）。\n3. Softmax\nSoftmax 用于将模型输出的 实数向量 转换为 概率分布。\n设模型输出的 logits 向量为：\nz = (z_1, z_2, \\dots, z_n)  \nSoftmax 公式为：\n\\text{softmax}(z_i) = \\frac{e^{z_i}}{\\sum_{j=1}^n e^{z_j}}, \\quad i=1,\\dots,n  \n性质：\n\n\n输出结果满足 q_i \\geq 0，且 \\sum_i q_i = 1。\n\n\n常作为分类任务最后一层，把 logits 变成概率分布 Q = (q_1, \\dots, q_n)。\n\n\n4. Softmax 损失（Softmax Loss）\n在分类任务里，Softmax 函数通常和 交叉熵损失 结合使用，这个组合有时就被称为 Softmax 损失。\n假设有k类，对于一个样本，设真实标签为 (y)，则该样本在各类的概率分布\\{p_1, \\cdots,p_k\\}并用 one-hot 向量表示：\np_i =\n\\left\\{\n\\begin{array}{ll}\n1, &amp; i = y \\\\\n0, &amp; i \\neq y\n\\end{array}\n\\right.\n预测分布是 q_i = \\text{softmax}(z_i)。\n交叉熵损失是：\nL = -\\sum_{i=1}^n p_i \\log q_i  \n由于 one-hot 的性质，只有正确类别的那一项保留下来，所以：\nL = - \\log q_y  \n再把 q_y 展开：\nq_y = \\frac{e^{z_y}}{\\sum_{j=1}^n e^{z_j}}  \n最终 单个样本的Softmax 损失函数为：\nL = - \\log \\frac{e^{z_y}}{\\sum_{j=1}^n e^{z_j}}  \n= - z_y + \\log \\left( \\sum_{j=1}^n e^{z_j} \\right)  \n对于整个输入batch，将各个样本的Softmax损失取平均，作为该batch的总体损失。\n\n3. 总结\n\n\nSoftmax：把 logits 转为概率分布。\n\n\nCross-Entropy：度量预测分布和真实分布的差异。\n\n\nSoftmax Loss：就是“Softmax + 交叉熵”的组合公式：\nL = - z_y + \\log \\left( \\sum_{j=1}^n e^{z_j} \\right)  \n\n\n示例\nclass SoftmaxClassifier:\n    &quot;&quot;&quot;\n    这是一个基于softmax损失函数的线性分类器\n    &quot;&quot;&quot;\n \n    def __init__(self, Xtr, Ytr):\n        self.Xtr = Xtr\n        self.Ytr = Ytr\n        self.feature_dim = Xtr.shape[1]\n        self.num_classes = len(torch.unique(Ytr))\n        self.W = torch.randn(\n\t        self.feature_dim, self.num_classes, requires_grad=True\n\t        )\n        self.b = torch.zeros(1, self.num_classes, requires_grad=True)\n \n    @staticmethod\n    def softmax(X):\n        X_exp = torch.exp(X)\n        partition = X_exp.sum(1, keepdim=True)\n        return X_exp / partition\n \n    def loss(self, X, Y, reg):\n        num_train = X.shape[0]\n        scores = X.mm(self.W) + self.b\n        probs = self.softmax(scores)\n        correct_logprobs = -torch.log(probs[range(num_train), Y])\n        data_loss = correct_logprobs.mean()\n        reg_loss = 0.5 * reg * (self.W**2).sum()\n        loss = data_loss + reg_loss\n        return loss\n "},"深度学习/deeplearning-basics/4.SVM损失":{"slug":"深度学习/deeplearning-basics/4.SVM损失","filePath":"深度学习/deeplearning basics/4.SVM损失.md","title":"4.SVM损失","links":[],"tags":[],"content":"1. 原始二分类 SVM（Hinge Loss）\n\n输入：logit 分数\ns = w^\\top x + b\n标签：y \\in \\{-1, +1\\}\n损失函数：\nL = \\max(0, 1 - y \\cdot s)\n\n说明：\n\n分类正确且离边界大于 1，损失为 0\n分类正确但靠近边界，损失 &gt; 0\n分类错误，损失很大\n\n2. 深度学习语境下的多分类 SVM（Multi-class Hinge Loss）\n\n模型输出：logits\ns = (s_1, s_2, \\dots, s_K)\n真实类别：y \\in \\{1,2,\\dots,K\\}\n损失函数：\nL = \\sum_{j \\neq y} \\max(0, s_j - s_y + \\Delta), \\quad \\Delta = 1\n\n说明：\n\n要求正确类别得分 s_y 比错误类别得分至少大一个 margin \\Delta\n不依赖 softmax，不需要概率解释\n"},"深度学习/deeplearning-basics/5.正则化":{"slug":"深度学习/deeplearning-basics/5.正则化","filePath":"深度学习/deeplearning basics/5.正则化.md","title":"5.正则化","links":[],"tags":[],"content":"通过将模型的总复杂程度加到损失函数中，可以限制模型的复杂程度，避免过拟合。\n总体形式为：\nL = L_{\\text{data}} + \\lambda \\, \\Omega(\\theta)\n其中：\n\nL_{\\text{data}} ：原始损失（如交叉熵、MSE）\n\\Omega(\\theta) ：正则项，用于衡量模型的复杂程度\n\\lambda ：正则化强度（超参数）\n\n\n常见的正则项\n1. L2 正则化（Ridge, 权重衰减）\n\n定义：\n\\Omega(\\theta) = \\frac{1}{2}\\|\\theta\\|_2^2 = \\frac{1}{2}\\sum_i \\theta_i^2\n特点：\n\n惩罚权重的平方\n倾向于使权重整体较小、分布均匀\n在深度学习中常称为 weight decay\n\n\n\n2. L1 正则化（Lasso）\n\n定义：\n\\Omega(\\theta) = \\|\\theta\\|_1 = \\sum_i |\\theta_i|\n特点：\n\n倾向于产生稀疏解（很多参数变为 0）\n可用于特征选择\n\n\n\n3. 弹性网络（Elastic Net）\n\n定义：\n\\Omega(\\theta) = \\alpha \\|\\theta\\|_1 + (1-\\alpha)\\frac{1}{2}\\|\\theta\\|_2^2\n特点：\n\nL1 与 L2 的结合\n既能稀疏化，又能保持稳定性\n\n\n"},"深度学习/deeplearning-basics/6.优化器":{"slug":"深度学习/deeplearning-basics/6.优化器","filePath":"深度学习/deeplearning basics/6.优化器.md","title":"6.优化器","links":[],"tags":[],"content":""},"深度学习/deeplearning-basics/7.神经网络":{"slug":"深度学习/deeplearning-basics/7.神经网络","filePath":"深度学习/deeplearning basics/7.神经网络.md","title":"7.神经网络","links":[],"tags":[],"content":""},"深度学习/deeplearning-basics/8.梯度回传":{"slug":"深度学习/deeplearning-basics/8.梯度回传","filePath":"深度学习/deeplearning basics/8.梯度回传.md","title":"8.梯度回传","links":[],"tags":[],"content":""},"深度学习/deeplearning-basics/index":{"slug":"深度学习/deeplearning-basics/index","filePath":"深度学习/deeplearning basics/index.md","title":"deeplearning basics","links":["深度学习/deeplearning-basics/1.K近邻","深度学习/deeplearning-basics/2.线性分类器","深度学习/deeplearning-basics/3.softmax损失","深度学习/deeplearning-basics/4.SVM损失","深度学习/deeplearning-basics/5.正则化","深度学习/deeplearning-basics/6.优化器","深度学习/deeplearning-basics/7.神经网络","深度学习/deeplearning-basics/8.梯度回传"],"tags":[],"content":"本章节从图片分类任务入手，以最基本的模型为例介绍了深度学习模型的基本结构。\n\n分类器 1.K近邻 2.线性分类器\n损失函数 3.softmax损失 4.SVM损失\n正则化 5.正则化\n优化器 6.优化器\n神经网络7.神经网络\n梯度回传8.梯度回传\n"}}