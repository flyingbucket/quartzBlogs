{"StableSR_doc/README":{"slug":"StableSR_doc/README","filePath":"StableSR_doc/README.md","title":"README","links":[],"tags":[],"content":"StableSR_doc"},"StableSR_doc/ldm/models/diffusion/ddpm/DiffusionWrapper(pl.LightningModule)":{"slug":"StableSR_doc/ldm/models/diffusion/ddpm/DiffusionWrapper(pl.LightningModule)","filePath":"StableSR_doc/ldm/models/diffusion/ddpm/DiffusionWrapper(pl.LightningModule).md","title":"DiffusionWrapper(pl.LightningModule)","links":[],"tags":[],"content":"class DiffusionWrapper(pl.LightningModule):\n    def __init__(self, diff_model_config, conditioning_key):\n        super().__init__()\n        self.diffusion_model = instantiate_from_config(diff_model_config) # [[instantiate_from_config]]\n        self.conditioning_key = conditioning_key\n        assert self.conditioning_key in [None, &#039;concat&#039;, &#039;crossattn&#039;, &#039;hybrid&#039;, &#039;adm&#039;]\n \n    def forward(self, x, t, c_concat: list = None, c_crossattn: list = None, struct_cond=None, seg_cond=None):\n        if self.conditioning_key is None: # [[#noneæ— æ¡ä»¶æ‰©æ•£unconditional|Noneï¼šæ— æ¡ä»¶æ‰©æ•£ï¼ˆUnconditionalï¼‰]]\n            out = self.diffusion_model(x, t)\n        elif self.conditioning_key == &#039;concat&#039;: # [[#concaté€šé“æ‹¼æ¥channel-concat|concatï¼šé€šé“æ‹¼æ¥ï¼ˆChannel Concatï¼‰]]\n            xc = torch.cat([x] + c_concat, dim=1) \n            out = self.diffusion_model(xc, t)\n        elif self.conditioning_key == &#039;crossattn&#039;: # [[#crossattnäº¤å‰æ³¨æ„åŠ›cross-attention|crossattnï¼šäº¤å‰æ³¨æ„åŠ›ï¼ˆCross-Attentionï¼‰]]\n            cc = torch.cat(c_crossattn, 1)\n            if seg_cond is None:\n                out = self.diffusion_model(x, t, context=cc, struct_cond=struct_cond)\n            else:\n                out = self.diffusion_model(x, t, context=cc, struct_cond=struct_cond, seg_cond=seg_cond)\n        elif self.conditioning_key == &#039;hybrid&#039;: # [[#hybridé€šé“æ‹¼æ¥--äº¤å‰æ³¨æ„åŠ›concat--cross-attn|hybridï¼šé€šé“æ‹¼æ¥ + äº¤å‰æ³¨æ„åŠ›ï¼ˆConcat + Cross-Attnï¼‰]]\n            xc = torch.cat([x] + c_concat, dim=1)\n            cc = torch.cat(c_crossattn, 1)\n            out = self.diffusion_model(xc, t, context=cc)\n        elif self.conditioning_key == &#039;adm&#039;: # [[#admæ ‡ç­¾æ³¨å…¥classifier-free-guidance|admï¼šæ ‡ç­¾æ³¨å…¥ï¼ˆClassifier-free Guidanceï¼‰]]\n            cc = c_crossattn[0]\n            out = self.diffusion_model(x, t, y=cc)\n        else:\n            raise NotImplementedError()\n \n        return out\n \nDiffusionWrapper.forward() ä¸­ conditioning_key çš„äº”ç§æ¨¡å¼è§£æ\nåœ¨ StableSR æˆ– Latent Diffusion ä¸­ï¼Œconditioning_key å†³å®šäº†æ¡ä»¶ä¿¡æ¯å¦‚ä½•æ³¨å…¥åˆ°æ‰©æ•£æ¨¡å‹ï¼ˆé€šå¸¸æ˜¯ UNetï¼Œå¦‚ UNetModelDualConv2dï¼‰ä¸­ã€‚è¯¥å‚æ•°å½±å“çš„æ˜¯ DiffusionWrapper åœ¨ forward é˜¶æ®µå¦‚ä½•ç»„ç»‡è¾“å…¥ï¼Œå¹¶é€šè¿‡å“ªäº›é€šè·¯å°†æ¡ä»¶ä¿¡æ¯ä¼ é€’åˆ°æ‰©æ•£ç½‘ç»œã€‚\n\nNoneï¼šæ— æ¡ä»¶æ‰©æ•£ï¼ˆUnconditionalï¼‰\nout = self.diffusion_model(x, t)\n\nä¸ä½¿ç”¨ä»»ä½•æ¡ä»¶ä¿¡æ¯ï¼›\nè¾“å…¥ä»…ä¸ºå¸¦å™ªå›¾åƒ x å’Œæ—¶é—´æ­¥ tï¼›\né€šå¸¸ç”¨äºçº¯å›¾åƒå»ºæ¨¡ã€åˆæœŸè®­ç»ƒæˆ– unconditional generationã€‚\n\n\nconcatï¼šé€šé“æ‹¼æ¥ï¼ˆChannel Concatï¼‰\nxc = torch.cat([x] + c_concat, dim=1)\nout = self.diffusion_model(xc, t)\n\næ¡ä»¶ä»¥å›¾åƒå½¢å¼æä¾›ï¼ˆå¦‚ä½æ¸…å›¾ã€è¾¹ç¼˜å›¾ã€å°æ³¢å­å¸¦ï¼‰ï¼Œç›´æ¥æ‹¼æ¥åˆ° x ä¸Šï¼›\né€šé“ç»´åº¦å˜ä¸º C + C_condï¼›\næ˜¯ SR3 ä½¿ç”¨çš„å…¸å‹æ¡ä»¶æ³¨å…¥æ–¹æ³•ï¼›\næ˜¯ä¼ ç»Ÿsr3çš„æ–¹æ³•,ç®€å•é«˜æ•ˆï¼Œä½†çµæ´»æ€§è¾ƒå·®ã€‚\n\n\ncrossattnï¼šäº¤å‰æ³¨æ„åŠ›ï¼ˆCross-Attentionï¼‰\ncc = torch.cat(c_crossattn, 1)\nout = self.diffusion_model(x, t, context=cc, struct_cond=..., seg_cond=...)\n\næ¡ä»¶ä¿¡æ¯ï¼ˆå¦‚ç»“æ„å›¾ã€å°æ³¢å›¾ã€æ–‡æœ¬ï¼‰é€šè¿‡ cond_stage_model ç¼–ç ä¸º latent å‘é‡ï¼›\nè¿™äº› latent å‘é‡ä½œä¸º contextï¼Œä¼ å…¥ UNet å†…éƒ¨çš„ CrossAttention æ¨¡å—ï¼›\nå¯é€‰åœ°æ”¯æŒç»“æ„æ¡ä»¶ struct_cond å’Œè¯­ä¹‰æ¡ä»¶ seg_condï¼›\næ˜¯ç°ä»£æ¡ä»¶æ‰©æ•£ï¼ˆå¦‚ Stable Diffusionï¼‰æœ€å¸¸ç”¨ç­–ç•¥ï¼Œçµæ´»ä¸”è¡¨è¾¾åŠ›å¼ºã€‚\n\n\nhybridï¼šé€šé“æ‹¼æ¥ + äº¤å‰æ³¨æ„åŠ›ï¼ˆConcat + Cross-Attnï¼‰\nxc = torch.cat([x] + c_concat, dim=1)\ncc = torch.cat(c_crossattn, 1)\nout = self.diffusion_model(xc, t, context=cc)\n\nåŒæ—¶ä½¿ç”¨ concat å’Œ cross-attention ä¸¤ç§é€šè·¯æ³¨å…¥æ¡ä»¶ï¼›\né€šé“æ‹¼æ¥ä¼ é€’ä½çº§ä¿¡æ¯ï¼ˆç»†èŠ‚ã€è¾¹ç¼˜ï¼‰ï¼›\ncross-attn ä¼ é€’é«˜çº§è¯­ä¹‰ï¼ˆç»“æ„ latentã€å°æ³¢ latentï¼‰ï¼›\nåœ¨ StableSR ä¸­ï¼Œé€šå¸¸ä¸¤è·¯æ¡ä»¶ä¿¡æ¯éƒ½æ¥æºäºåŒä¸€ä¸ªç»“æ„å›¾ï¼Œåªæ˜¯ç»è¿‡ä¸åŒè·¯å¾„å¤„ç†ï¼›\nå¹³è¡¡å¼•å¯¼æ€§ä¸çµæ´»æ€§ï¼Œæ˜¯æ¨èæ¨¡å¼ä¹‹ä¸€ã€‚\n\n\nadmï¼šæ ‡ç­¾æ³¨å…¥ï¼ˆClassifier-free Guidanceï¼‰\ncc = c_crossattn[0]\nout = self.diffusion_model(x, t, y=cc)\n\nç”¨äºç±»åˆ«æˆ– token ä½œä¸ºæ ‡ç­¾æ¡ä»¶ï¼ˆå¦‚ ImageNet class labelï¼‰ï¼›\ny=cc è¡¨ç¤ºå°†æ¡ä»¶ä½œä¸ºç±»æ ‡ç­¾æ³¨å…¥ï¼›\néœ€è¦æ‰©æ•£æ¨¡å‹æ”¯æŒ y è¾“å…¥ï¼ˆå¦‚é€šè¿‡ ConditionalBatchNormã€embedding ç­‰ï¼‰ï¼›\nå¸¸è§äº ADM/DDPMv2 ç­‰åˆ†ç±»æ¡ä»¶ç”Ÿæˆåœºæ™¯ã€‚\n\n\næ€»ç»“\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nconditioning_keyæ¡ä»¶æ³¨å…¥æ–¹å¼å…¸å‹ç”¨é€”Noneæ— æ¡ä»¶çº¯å›¾åƒå»ºæ¨¡&#039;concat&#039;é€šé“æ‹¼æ¥SR3ã€ç»“æ„å›¾å¼•å¯¼&#039;crossattn&#039;äº¤å‰æ³¨æ„åŠ›Stable Diffusionã€ç»“æ„/æ–‡æœ¬å¼•å¯¼&#039;hybrid&#039;æ‹¼æ¥ + æ³¨æ„åŠ›StableSRã€å°æ³¢ + ç»“æ„è”åˆå¼•å¯¼&#039;adm&#039;æ ‡ç­¾è¾“å…¥åˆ†ç±»æ¡ä»¶ç”Ÿæˆï¼ˆå¦‚ class-conditional DDPMï¼‰\nå®é™…åº”ç”¨ä¸­ï¼Œå¯æ ¹æ®æ¡ä»¶ç±»å‹å’Œä»»åŠ¡ç›®æ ‡çµæ´»é€‰æ‹©æˆ–ç»„åˆè¿™äº›æ¨¡å¼ã€‚"},"StableSR_doc/ldm/models/diffusion/ddpm/Module_info":{"slug":"StableSR_doc/ldm/models/diffusion/ddpm/Module_info","filePath":"StableSR_doc/ldm/models/diffusion/ddpm/Module_info.md","title":"Module_info","links":["StableSR_doc/ldm/models/diffusion/ddpm/torch2img","StableSR_doc/ldm/models/diffusion/ddpm/cal_pca_components","StableSR_doc/ldm/models/diffusion/ddpm/visualize_fea","StableSR_doc/ldm/models/diffusion/ddpm/calc_mean_std","StableSR_doc/ldm/models/diffusion/ddpm/adaptive_instance_normalization","StableSR_doc/ldm/models/diffusion/ddpm/space_timesteps","StableSR_doc/ldm/models/diffusion/ddpm/disabled_train","StableSR_doc/ldm/models/diffusion/ddpm/uniform_on_device","StableSR_doc/ldm/models/diffusion/ddpm/class-DDPM/DDPM(pl.LightningModule)","LatentDiffusion(DDPM)","LatentDiffusionSRTextWT(DDPM)","LatentDiffusionSRTextWTFFHQ(LatentDiffusionSRTextWT)","StableSR_doc/ldm/models/diffusion/ddpm/DiffusionWrapper(pl.LightningModule)","Layout2ImgDiffusion(LatentDiffusion)"],"tags":[],"content":"\n\n                  \n                  UML å›¾è§£ï¼šddpm.pyæ–‡ä»¶ç»“æ„ \n                  \n                \n\n\n\nâ€˜ldm.models.diffusion.ddpmâ€™ ä¸­å„ä¸ªç±»çš„å…³ç³»ã€‚\n\n\n\nFunctions\ntorch2img\ncal_pca_components\nvisualize_fea\ncalc_mean_std\nadaptive_instance_normalization\nspace_timesteps\ndisabled_train\nuniform_on_device\nClasses\nDDPM(pl.LightningModule)\nLatentDiffusion(DDPM)\nLatentDiffusionSRTextWT(DDPM)\nLatentDiffusionSRTextWTFFHQ(LatentDiffusionSRTextWT)\nDiffusionWrapper(pl.LightningModule)\nLayout2ImgDiffusion(LatentDiffusion)"},"StableSR_doc/ldm/models/diffusion/ddpm/adaptive_instance_normalization":{"slug":"StableSR_doc/ldm/models/diffusion/ddpm/adaptive_instance_normalization","filePath":"StableSR_doc/ldm/models/diffusion/ddpm/adaptive_instance_normalization.md","title":"adaptive_instance_normalization","links":[],"tags":[],"content":""},"StableSR_doc/ldm/models/diffusion/ddpm/cal_pca_components":{"slug":"StableSR_doc/ldm/models/diffusion/ddpm/cal_pca_components","filePath":"StableSR_doc/ldm/models/diffusion/ddpm/cal_pca_components.md","title":"cal_pca_components","links":[],"tags":[],"content":""},"StableSR_doc/ldm/models/diffusion/ddpm/calc_mean_std":{"slug":"StableSR_doc/ldm/models/diffusion/ddpm/calc_mean_std","filePath":"StableSR_doc/ldm/models/diffusion/ddpm/calc_mean_std.md","title":"calc_mean_std","links":[],"tags":[],"content":""},"StableSR_doc/ldm/models/diffusion/ddpm/class-DDPM/DDPM(pl.LightningModule)":{"slug":"StableSR_doc/ldm/models/diffusion/ddpm/class-DDPM/DDPM(pl.LightningModule)","filePath":"StableSR_doc/ldm/models/diffusion/ddpm/class DDPM/DDPM(pl.LightningModule).md","title":"DDPM(pl.LightningModule)","links":["register_schedule","DDPM","_get_rows_from_list","configure_optimizers","forward","get_input","get_loss","get_v","StableSR_doc/ldm/models/diffusion/ddpm/class-DDPM/init_from_ckpt","on_train_batch_end","p_losses","p_mean_variance","predict_start_from_noise","predict_start_from_z_and_v","q_mean_variance","q_posterior","q_sample","q_sample_respace","shared_step","training_step"],"tags":[],"content":"Class: DDPM\nInheritance Tree (MRO):\n\nDDPM\nLightningModule\nABC\nDeviceDtypeModuleMixin\nHyperparametersMixin\nGradInformation\nModelIO\nModelHooks\nDataHooks\nCheckpointHooks\nModule\nobject\n\nInstance Attributes (from self.xxx assignments):\n\nparameterization (defined in: [[init]])\ncond_stage_model (defined in: [[init]])\nclip_denoised (defined in: [[init]])\nlog_every_t (defined in: [[init]])\nfirst_stage_key (defined in: [[init]])\nimage_size (defined in: [[init]])\nchannels (defined in: [[init]])\nuse_positional_encodings (defined in: [[init]])\nmodel (defined in: [[init]])\nuse_ema (defined in: [[init]])\nuse_scheduler (defined in: [[init]])\nv_posterior (defined in: [[init]])\noriginal_elbo_weight (defined in: [[init]])\nl_simple_weight (defined in: [[init]])\nloss_type (defined in: [[init]])\nlearn_logvar (defined in: [[init]])\nlogvar (defined in: [[init, init]])\nmodel_ema (defined in: [[init]])\nscheduler_config (defined in: [[init]])\nmonitor (defined in: [[init]])\nnum_timesteps (defined in: register_schedule)\nlinear_start (defined in: register_schedule)\nlinear_end (defined in: register_schedule)\n\nProject-defined Methods:\n\n[[init]]  â†  DDPM\n_get_rows_from_list  â†  DDPM\nconfigure_optimizers  â†  DDPM\nforward  â†  DDPM\nget_input  â†  DDPM\nget_loss  â†  DDPM\nget_v  â†  DDPM\ninit_from_ckpt  â†  DDPM\non_train_batch_end  â†  DDPM\np_losses  â†  DDPM\np_mean_variance  â†  DDPM\npredict_start_from_noise  â†  DDPM\npredict_start_from_z_and_v  â†  DDPM\nq_mean_variance  â†  DDPM\nq_posterior  â†  DDPM\nq_sample  â†  DDPM\nq_sample_respace  â†  DDPM\nregister_schedule  â†  DDPM\nshared_step  â†  DDPM\ntraining_step  â†  DDPM\n\nProject-defined Attributes:"},"StableSR_doc/ldm/models/diffusion/ddpm/class-DDPM/__init__":{"slug":"StableSR_doc/ldm/models/diffusion/ddpm/class-DDPM/__init__","filePath":"StableSR_doc/ldm/models/diffusion/ddpm/class DDPM/__init__.md","title":"__init__","links":["StableSR_doc/pytorch-lightning"],"tags":[],"content":"init å‡½æ•°ä»‹ç»\nclass DDPM(pl.LightningModule): # [[pytorch lightning#pllightningmoudule|pl.LightningMoudule]]\n    # classic DDPM with Gaussian diffusion, in image space\n    def __init__(self,\n                 unet_config,\n                 timesteps=1000,\n                 beta_schedule=&quot;linear&quot;,\n                 loss_type=&quot;l2&quot;,\n                 ckpt_path=None,\n                 ignore_keys=[],\n                 load_only_unet=False,\n                 monitor=&quot;val/loss&quot;,\n                 use_ema=True,\n                 first_stage_key=&quot;image&quot;,\n                 image_size=256,\n                 channels=3,\n                 log_every_t=100,\n                 clip_denoised=True,\n                 linear_start=1e-4,\n                 linear_end=2e-2,\n                 cosine_s=8e-3,\n                 given_betas=None,\n                 original_elbo_weight=0.,\n                 v_posterior=0.,  # weight for choosing posterior variance as sigma = (1-v) * beta_tilde + v * beta\n                 l_simple_weight=1.,\n                 conditioning_key=None,\n                 parameterization=&quot;eps&quot;,  # all assuming fixed variance schedules\n                 scheduler_config=None,\n                 use_positional_encodings=False,\n                 learn_logvar=False,\n                 logvar_init=0.,\n                 ):\n        super().__init__() \n        # [[#parameterization|parameterization]]\n        assert parameterization in [&quot;eps&quot;, &quot;x0&quot;, &quot;v&quot;], &#039;currently only supporting &quot;eps&quot; and &quot;x0&quot; and &quot;v&quot;&#039;\n        self.parameterization = parameterization\n        print(f&quot;{self.__class__.__name__}: Running in {self.parameterization}-prediction mode&quot;)\n        self.cond_stage_model = None\n        self.clip_denoised = clip_denoised\n        self.log_every_t = log_every_t\n        self.first_stage_key = first_stage_key\n        self.image_size = image_size  # try conv?\n        self.channels = channels\n        self.use_positional_encodings = use_positional_encodings\n        self.model = DiffusionWrapper(unet_config, conditioning_key) # [[DiffusionWrapper(pl.LightningModule)]]\n        count_params(self.model, verbose=True) # [[#line-45-to-57--ddpm__init__-ä¸­æ¨¡å‹ç®¡ç†è°ƒåº¦å™¨ä¸æŸå¤±æƒé‡éƒ¨åˆ†è§£æ|line 45 to 57 ğŸ”§ `DDPM.__init__` ä¸­æ¨¡å‹ç®¡ç†ã€è°ƒåº¦å™¨ä¸æŸå¤±æƒé‡éƒ¨åˆ†è§£æ]]\n        self.use_ema = use_ema\n        if self.use_ema:\n            self.model_ema = LitEma(self.model)\n            print(f&quot;Keeping EMAs of {len(list(self.model_ema.buffers()))}.&quot;)\n \n        self.use_scheduler = scheduler_config is not None\n        if self.use_scheduler:\n            self.scheduler_config = scheduler_config\n \n        self.v_posterior = v_posterior\n        self.original_elbo_weight = original_elbo_weight\n        self.l_simple_weight = l_simple_weight\n \n        if monitor is not None: # [[#-pytorch-lightning-ä¸­çš„-monitor-å‚æ•°ç®€æ|ğŸ“ˆ PyTorch Lightning ä¸­çš„ `monitor` å‚æ•°ç®€æ]]\n            self.monitor = monitor \n        if ckpt_path is not None: # åŠ è½½é¢„è®­ç»ƒæ¨¡å‹\n            self.init_from_ckpt(ckpt_path, ignore_keys=ignore_keys, only_model=load_only_unet) # [[init_from_ckpt]]\n\t\t# [[#line-64-to-end|line 64 to end]]\n\t\t# [[#1-æ³¨å†Œè°ƒåº¦è¡¨beta-schedule|1. æ³¨å†Œè°ƒåº¦è¡¨ï¼ˆbeta scheduleï¼‰]]\n        self.register_schedule(given_betas=given_betas, beta_schedule=beta_schedule, timesteps=timesteps,\n                               linear_start=linear_start, linear_end=linear_end, cosine_s=cosine_s)\n\t\t# [[#2-è®¾ç½®æŸå¤±å‡½æ•°ç±»å‹|2. è®¾ç½®æŸå¤±å‡½æ•°ç±»å‹]]\n        self.loss_type = loss_type\n\t\t# [[#logvar-åœ¨-ddpm-æ‰©æ•£æ¨¡å‹ä¸­çš„ä½œç”¨ä¸å®ç°|logvar åœ¨ DDPM æ‰©æ•£æ¨¡å‹ä¸­çš„ä½œç”¨ä¸å®ç°]]\n        self.learn_logvar = learn_logvar\n        self.logvar = torch.full(fill_value=logvar_init, size=(self.num_timesteps,))\n        if self.learn_logvar:\n            self.logvar = nn.Parameter(self.logvar, requires_grad=True)\n \nparameterization\n\nparameterization: æ‰©æ•£æ¨¡å‹çš„é¢„æµ‹ç›®æ ‡ï¼Œæœ‰ä¸‰ç§ï¼š\n\n&quot;eps&quot;: å™ªå£°é¢„æµ‹ï¼ˆæœ€å¸¸ç”¨ï¼‰\n&quot;x0&quot;: é¢„æµ‹åŸå§‹å›¾åƒ\n&quot;v&quot;: v-pred æ–¹æ¡ˆï¼Œå¹³è¡¡ä¸¤ä¸ªæç«¯\n\n\næ–­è¨€é™åˆ¶åªæ”¯æŒä¸Šè¿°ä¸‰ç§æ¨¡å¼\n\nline 45 to 57 ğŸ”§ DDPM.__init__ ä¸­æ¨¡å‹ç®¡ç†ã€è°ƒåº¦å™¨ä¸æŸå¤±æƒé‡éƒ¨åˆ†è§£æ\nè¿™éƒ¨åˆ†ä»£ç è´Ÿè´£æ‰©æ•£æ¨¡å‹è®­ç»ƒè¿‡ç¨‹ä¸­çš„å‡ ä¸ªé‡è¦åŠŸèƒ½ç»„ä»¶çš„é…ç½®ï¼ŒåŒ…æ‹¬å‚æ•°ç»Ÿè®¡ã€EMA å¹³æ»‘ã€è°ƒåº¦å™¨è®¾ç½®ï¼Œä»¥åŠæŸå¤±é¡¹çš„åŠ æƒç­–ç•¥ã€‚\n\nğŸ”¢ æ¨¡å‹å‚æ•°ç»Ÿè®¡ä¸æ‰“å°\ncount_params(self.model, verbose=True)\n\nè°ƒç”¨ count_params æ‰“å°æ¨¡å‹å‚æ•°æ•°é‡ï¼›\nself.model æ˜¯ä¹‹å‰åˆ›å»ºçš„ DiffusionWrapperï¼ˆåŒ…å« UNet å’Œæ¡ä»¶æ§åˆ¶ï¼‰ï¼›\nverbose=True è¡¨ç¤ºè¾“å‡ºè¯¦ç»†å±‚çº§å‚æ•°ç»Ÿè®¡ï¼Œæœ‰åŠ©äºæ¨¡å‹è°ƒè¯•ä¸è§„æ¨¡è¯„ä¼°ã€‚\n\n\nğŸ§® EMA æ¨¡å‹é…ç½®ï¼ˆExponential Moving Averageï¼‰\nself.use_ema = use_ema\nif self.use_ema:\n    self.model_ema = LitEma(self.model)\n    print(f&quot;Keeping EMAs of {len(list(self.model_ema.buffers()))}.&quot;)\n\nuse_ema: æ§åˆ¶æ˜¯å¦å¯ç”¨ EMAï¼›\nå¦‚æœå¯ç”¨ï¼Œå°†åˆ›å»º model_emaï¼Œç”¨äºåœ¨è®­ç»ƒä¸­å¯¹æ¨¡å‹å‚æ•°è¿›è¡Œæ»‘åŠ¨å¹³å‡ï¼›\nEMA å¯åœ¨æ¨ç†æ—¶æä¾›æ›´ç¨³å®šçš„ç»“æœï¼ˆå°¤å…¶è®­ç»ƒåæœŸï¼‰ï¼›\nLitEma æ˜¯ä¸€ä¸ªå†…éƒ¨å®ç°çš„ EMA å·¥å…·ç±»ï¼ˆæ¨¡ä»¿ PyTorch EMA å®ç°ï¼‰ï¼›\nbuffers() æä¾›äº†æ‰€æœ‰è¢« EMA è¿½è¸ªçš„å¼ é‡ï¼ˆé€šå¸¸æ˜¯æ¨¡å‹æƒé‡ï¼‰ã€‚\n\nPS. EMAç®€ä»‹\næŒ‡æ•°ç§»åŠ¨å¹³å‡ï¼ˆExponential Moving Averageï¼‰ä¹Ÿå«æƒé‡ç§»åŠ¨å¹³å‡ï¼ˆWeighted Moving Averageï¼‰ï¼Œæ˜¯ä¸€ç§ç»™äºˆè¿‘æœŸæ•°æ®æ›´é«˜æƒé‡çš„å¹³å‡æ–¹æ³•ã€‚\nğŸ“ˆ è®­ç»ƒè°ƒåº¦å™¨é…ç½®ï¼ˆå¦‚å­¦ä¹ ç‡è°ƒåº¦ï¼‰\nself.use_scheduler = scheduler_config is not None\nif self.use_scheduler:\n    self.scheduler_config = scheduler_config\n\nå¦‚æœæä¾›äº† scheduler_configï¼Œåˆ™å°†å…¶ä¿å­˜ï¼›\nåç»­åœ¨ configure_optimizers() æ–¹æ³•ä¸­ä¼šç”¨åˆ°è¯¥é…ç½®ï¼›\nå¯ç”¨äºå®šä¹‰å¦‚ä½™å¼¦é€€ç«ï¼ˆcosine annealingï¼‰ã€çº¿æ€§ warmup ç­‰å­¦ä¹ ç‡è°ƒåº¦ç­–ç•¥ã€‚\n\n\nâš–ï¸ æŸå¤±é¡¹æƒé‡è®¾ç½®\nself.v_posterior = v_posterior\nself.original_elbo_weight = original_elbo_weight\nself.l_simple_weight = l_simple_weight\nè¿™ä¸‰é¡¹å‚æ•°æ§åˆ¶æ‰©æ•£æŸå¤±çš„ç»„æˆï¼š\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nå‚æ•°åå«ä¹‰v_posterioråéªŒæ–¹å·®çš„åŠ æƒæ§åˆ¶é¡¹ã€‚ç”¨äºè®¾ç½®é¢„æµ‹æ–¹å·®çš„ç­–ç•¥ã€‚å…·ä½“è®¡ç®—å½¢å¼ä¸ºï¼šÏƒÂ² = (1 - v) * beta_tilde + v * betaï¼Œå…¶ä¸­ v å°±æ˜¯è¿™ä¸ªå‚æ•°ã€‚original_elbo_weightæ˜¯å¦åŠ å…¥åŸå§‹è®ºæ–‡ä¸­çš„ ELBO loss é¡¹ï¼ˆå¸¸ä¸º 0ï¼Œä»£è¡¨ä¸å¯ç”¨ï¼‰l_simple_weightL2 æˆ– L1 æŸå¤±çš„ä¸»æƒé‡ï¼Œç”¨äºç¨³å®šè®­ç»ƒ\n\nè¿™éƒ¨åˆ†æœ€ç»ˆå°†ä½œç”¨äº get_loss() æˆ– p_losses() ä¸­çš„æŸå¤±å‡½æ•°ç»„åˆï¼›\nå¯¹äºä¸åŒä»»åŠ¡ï¼ˆå¦‚å›¾åƒé‡å»º vs ç”Ÿæˆï¼‰ï¼Œå¯ä»¥é€šè¿‡è°ƒæ•´è¿™äº›å‚æ•°æ¥å¹³è¡¡ç”Ÿæˆè´¨é‡å’Œä¿çœŸåº¦ã€‚\n\n\nâœ… å°ç»“\nè¿™ä¸€éƒ¨åˆ†ä¸ºè®­ç»ƒè¿‡ç¨‹æä¾›äº†å¿…è¦çš„é…ç½®ç®¡ç†ï¼š\n\næ¨¡å‹å‚æ•°ç»Ÿè®¡æœ‰åŠ©äºå¯è§†åŒ–è§„æ¨¡ï¼›\nEMA ç®¡ç†å¯æå‡è®­ç»ƒç¨³å®šæ€§ï¼›\nè°ƒåº¦å™¨è®¾ç½®ä¸ºä¼˜åŒ–å™¨è¡Œä¸ºæä¾›äº†çµæ´»æ€§ï¼›\næŸå¤±é¡¹åŠ æƒæ§åˆ¶ç”Ÿæˆæ¨¡å‹ä¼˜åŒ–ç›®æ ‡çš„ä¾§é‡ç‚¹ã€‚\n\nğŸ“ˆ PyTorch Lightning ä¸­çš„ monitor å‚æ•°ç®€æ\nmonitor æ˜¯ PyTorch Lightning ä¸­å›è°ƒï¼ˆCallbackï¼‰æœºåˆ¶çš„ä¸€éƒ¨åˆ†ï¼Œç”¨äºæŒ‡å®šè®­ç»ƒè¿‡ç¨‹ä¸­è¦ç›‘æ§çš„æŒ‡æ ‡åç§°ï¼Œä¾›å¦‚ ModelCheckpointã€EarlyStopping ç­‰å›è°ƒä¾æ®è¯¥æŒ‡æ ‡æ‰§è¡Œç›¸åº”é€»è¾‘ï¼ˆå¦‚ä¿å­˜æ¨¡å‹ã€æå‰åœæ­¢ç­‰ï¼‰ã€‚\nè¯¦è§pytorch_Lightning Callback æœºåˆ¶\n\nâœ… å…³é”®ç”¨é€”\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nç»„ä»¶ç”¨é€”ModelCheckpointä¿å­˜æ€§èƒ½æœ€å¥½çš„æ¨¡å‹EarlyStoppingåœ¨éªŒè¯æŒ‡æ ‡åœæ­¢æå‡æ—¶ä¸­æ­¢è®­ç»ƒ\n\nğŸ§© monitor çš„å·¥ä½œæµç¨‹\n\n\næ¨¡å‹å†…éƒ¨è®°å½•æŒ‡æ ‡ï¼š\nself.log(&quot;val/loss&quot;, val_loss, prog_bar=True)\n\n\næŒ‡å®š monitor çš„å›è°ƒç›‘å¬è¿™ä¸ªæŒ‡æ ‡ï¼š\nModelCheckpoint(monitor=&quot;val/loss&quot;, mode=&quot;min&quot;)\n\n\nLightning è‡ªåŠ¨æ¯”è¾ƒå¹¶è§¦å‘ä¿å­˜ / åœæ­¢é€»è¾‘ã€‚\n\n\n\nâš™ï¸ monitor ç¤ºä¾‹é…ç½®\nfrom pytorch_lightning.callbacks import ModelCheckpoint\n \ncheckpoint = ModelCheckpoint(\n    monitor=&quot;val/psnr&quot;,   # ç›‘å¬ PSNR æŒ‡æ ‡\n    mode=&quot;max&quot;,           # æŒ‡æ ‡è¶Šå¤§è¶Šå¥½\n    save_top_k=1,\n    filename=&quot;best-psnr&quot;\n)\nfrom pytorch_lightning.callbacks import EarlyStopping\n \nearly_stop = EarlyStopping(\n    monitor=&quot;val/loss&quot;,\n    mode=&quot;min&quot;,\n    patience=5\n)\n\nğŸ§  è¯´æ˜\n\nmonitor æ˜¯ä¸€ä¸ªå­—ç¬¦ä¸²ï¼Œå¿…é¡»å’Œ .log(...) ä¸­è®°å½•çš„åå­—ä¸€è‡´ï¼›\nä¸ä¼šè‡ªåŠ¨åˆ›å»ºæŒ‡æ ‡å€¼ï¼Œåªæ˜¯å¼•ç”¨å·²æœ‰æŒ‡æ ‡ï¼›\nå’Œ mode ä¸€èµ·å†³å®šä½•æ—¶è§¦å‘æ“ä½œï¼ˆmin â†’ è¶Šå°è¶Šå¥½ï¼Œmax â†’ è¶Šå¤§è¶Šå¥½ï¼‰ï¼›\nåœ¨æ¨¡å‹ç±»ä¸­å¯ç”¨ self.monitor ä¼ é€’ç»™ callback å®ç°åŠ¨æ€é…ç½®ã€‚\n\n\nâœ… æ€»ç»“\n\nmonitor æ˜¯ å›è°ƒç³»ç»Ÿç›‘å¬çš„æŒ‡æ ‡åç§°ï¼›\né…åˆ .log(...) ä½¿ç”¨ï¼›\nå†³å®šæ˜¯å¦ä¿å­˜æ¨¡å‹ / æå‰åœæ­¢ï¼›\næœ¬èº«ä¸è®¡ç®—æŒ‡æ ‡ï¼Œä»…ä½œä¸ºå¼•ç”¨å­—æ®µä½¿ç”¨ã€‚\n\nline 64 to end\nè¿™ä¸€éƒ¨åˆ†ä¸»è¦å®Œæˆäº†å™ªå£°è°ƒåº¦ä¸æŸå¤±é…ç½®,å…·ä½“æ¥è¯´,\næœ¬éƒ¨åˆ†ä»£ç å®Œæˆäº†æ‰©æ•£è¿‡ç¨‹ä¸­çš„betaè°ƒåº¦è¡¨æ„å»º(å³å™ªå£°è°ƒåº¦)ã€æŸå¤±å‡½æ•°ç±»å‹è®¾å®šå’Œå¯¹æ•°æ–¹å·®çš„åˆå§‹åŒ–ï¼Œæ˜¯ DDPM å»ºæ¨¡æ ¸å¿ƒå‚æ•°çš„å…³é”®é…ç½®æ­¥éª¤ã€‚\n\n1. æ³¨å†Œè°ƒåº¦è¡¨ï¼ˆbeta scheduleï¼‰\nself.register_schedule(\n    given_betas=given_betas,\n    beta_schedule=beta_schedule,\n    timesteps=timesteps,\n    linear_start=linear_start,\n    linear_end=linear_end,\n    cosine_s=cosine_s\n)\n\nè¯¥å‡½æ•°æ ¹æ® beta_schedule çš„ç±»å‹ï¼ˆå¦‚ â€œlinearâ€ æˆ– â€œcosineâ€ï¼‰æ„å»ºæ‰©æ•£è¿‡ç¨‹ä¸­çš„æ—¶é—´æ­¥å™ªå£°ç³»æ•°è¡¨ï¼›\né€šå¸¸ä¼šç”Ÿæˆå¦‚ä¸‹å‚æ•°ï¼š\n\nbetasï¼šæ¯ä¸€æ­¥çš„å™ªå£°å¹…åº¦ï¼›\nalphas, alphas_cumprod, sqrt_alphas_cumprod, sqrt_one_minus_alphas_cumprod ç­‰ï¼›\n\n\nè¿™äº›ç³»æ•°ä¼šåœ¨åç»­ q_sample, q_posterior, predict_start_from_noise ç­‰å‡½æ•°ä¸­ä½¿ç”¨ï¼›\nå‚æ•°è¯´æ˜ï¼š\n\nlinear_start, linear_end: ç”¨äºçº¿æ€§ beta è°ƒåº¦èµ·æ­¢å€¼ï¼›\ncosine_s: ç”¨äºè°ƒæ•´ä½™å¼¦è°ƒåº¦çš„å½¢çŠ¶ï¼›\ngiven_betas: è‹¥æä¾›ï¼Œä¼˜å…ˆä½¿ç”¨ç”¨æˆ·è‡ªå®šä¹‰ beta è¡¨ã€‚\n\n\n\n\n2. è®¾ç½®æŸå¤±å‡½æ•°ç±»å‹\nself.loss_type = loss_type\n\næ§åˆ¶è®­ç»ƒæ—¶ä½¿ç”¨å“ªç§æŸå¤±ï¼š\n\n&quot;l2&quot;ï¼ˆé»˜è®¤ï¼‰ï¼šé¢„æµ‹çš„å™ªå£°ä¸çœŸå®å™ªå£°ä¹‹é—´çš„å‡æ–¹è¯¯å·®ï¼›\n&quot;l1&quot;ï¼šé¢„æµ‹æ®‹å·®çš„ç»å¯¹å€¼æŸå¤±ï¼›\nä¹Ÿå¯èƒ½æ”¯æŒå…¶ä»–è‡ªå®šä¹‰æŸå¤±ç±»å‹ï¼Œå¦‚ perceptual lossã€hybrid loss ç­‰ï¼›\n\n\nå®é™…ä½¿ç”¨åœ¨ get_loss() æˆ– p_losses() ä¸­å¤„ç†ã€‚\n\n\n3. åˆå§‹åŒ–å¯¹æ•°æ–¹å·®ï¼ˆlog-varianceï¼‰\nself.learn_logvar = learn_logvar\nself.logvar = torch.full(fill_value=logvar_init, size=(self.num_timesteps,))\nif self.learn_logvar:\n    self.logvar = nn.Parameter(self.logvar, requires_grad=True)\n\nlogvar æ˜¯ä¸€ä¸ªé•¿åº¦ä¸º num_timesteps çš„å¼ é‡ï¼Œè¡¨ç¤ºæ¯ä¸€æ‰©æ•£æ—¶é—´æ­¥çš„å¯¹æ•°æ–¹å·®ï¼›\nå¦‚æœå¯ç”¨ learn_logvar=Trueï¼Œåˆ™å°†å…¶è®¾ä¸ºå¯å­¦ä¹ å‚æ•°ï¼ˆnn.Parameterï¼‰ï¼Œå…è®¸æ¨¡å‹è‡ªåŠ¨ä¼˜åŒ–æ¯ä¸€æ—¶é—´æ­¥çš„ä¸ç¡®å®šæ€§ï¼›\nå¦‚æœä¸å¯ç”¨ï¼Œlogvar å°±æ˜¯ä¸€ä¸ªå›ºå®šçš„å¸¸é‡å€¼å¼ é‡ï¼›\nåœ¨ get_loss() ä¸­ä¼šå‚ä¸ KL é¡¹æˆ– likelihood çš„æƒé‡è°ƒæ•´ã€‚\n\nlogvar åœ¨ DDPM æ‰©æ•£æ¨¡å‹ä¸­çš„ä½œç”¨ä¸å®ç°\nlogvarï¼ˆå¯¹æ•°æ–¹å·®ï¼‰æ˜¯æ‰©æ•£æ¨¡å‹ï¼ˆå¦‚ DDPMï¼‰ä¸­ç”¨äºæ§åˆ¶è®­ç»ƒæŸå¤±æƒé‡å’Œä¸ç¡®å®šæ€§å»ºæ¨¡çš„ä¸€ä¸ªé‡è¦å˜é‡ã€‚åœ¨ StableSR å’Œ DDPM å®ç°ä¸­ï¼Œå®ƒæ˜¯ diffusion æ¨¡å‹çš„ä¸€éƒ¨åˆ†ï¼Œè€Œé encoder æˆ– decoder çš„ç»„æˆéƒ¨åˆ†ã€‚\n\n1. èƒŒæ™¯ï¼šä¸ºä½•éœ€è¦ logvar\næ‰©æ•£æ¨¡å‹è®­ç»ƒæ—¶é€šå¸¸ä»¥é¢„æµ‹å™ªå£°ä¸ºç›®æ ‡ï¼ŒåŸºæœ¬æŸå¤±å½¢å¼ä¸º(ä»¥L2æŸå¤±ä¸ºä¾‹)ï¼š\nL_t = \\left\\| \\varepsilon_{\\text{pred}} - \\varepsilon_{\\text{true}} \\right\\|^2\nä¸ºäº†å¢å¼ºçµæ´»æ€§ã€ç¨³å®šæ€§æˆ–é€¼è¿‘å¯¹æ•°ä¼¼ç„¶ï¼Œä¸€äº›å˜ä½“å¼•å…¥äº†å¯¹æ•°æ–¹å·® logvarï¼Œä½¿å¾—æŸå¤±å‡½æ•°å˜ä¸ºï¼š\nL_t = \\frac{1}{2} \\cdot \\exp(-\\text{logvar}_t) \\cdot \\left\\| \\varepsilon_{\\text{pred}} - \\varepsilon_{\\text{true}} \\right\\|^2 + \\frac{1}{2} \\cdot \\text{logvar}_t\nè¿™ç›¸å½“äºä½¿ç”¨ä¸€ä¸ªå¯å˜çš„æ—¶é—´æ­¥æƒé‡é¡¹ï¼Œç”¨äºï¼š\n\næ§åˆ¶æ¯ä¸€æ—¶é—´æ­¥æŸå¤±çš„ç›¸å¯¹é‡è¦æ€§ï¼›\næ¨¡æ‹Ÿé«˜æ–¯ä¼¼ç„¶ä¸­çš„åˆ†å¸ƒä¸ç¡®å®šæ€§ï¼›\nä½¿å¾—æ¨¡å‹å¯¹æŸäº›æ—¶é—´æ­¥é¢„æµ‹æ›´åŠ ç¨³å¥ã€‚\n\n\n2. åˆå§‹åŒ–æ–¹å¼\nlogvar é€šå¸¸è¢«åˆå§‹åŒ–ä¸ºå¸¸æ•°å¼ é‡ï¼š\nself.logvar = torch.full(fill_value=logvar_init, size=(self.num_timesteps,))\n\nlogvar_init: å¯¹æ•°æ–¹å·®çš„åˆå§‹å€¼ï¼ˆå¸¸ä¸º 0ï¼‰ï¼›\nnum_timesteps: æ‰©æ•£æ€»æ­¥æ•°ï¼ˆå¦‚ 1000ï¼‰ï¼›\nå¾—åˆ°å½¢çŠ¶ä¸º (T,) çš„ logvar å¼ é‡ï¼Œå…¶ä¸­ T æ˜¯æ—¶é—´æ­¥æ•°ã€‚\n\nè‹¥å¯ç”¨å¯å­¦ä¹ æ–¹å·®ï¼š\nif self.learn_logvar:\n    self.logvar = nn.Parameter(self.logvar, requires_grad=True)\nåˆ™è¯¥å¼ é‡åœ¨è®­ç»ƒä¸­ä¼šè‡ªåŠ¨æ›´æ–°ï¼Œæ¯ä¸€æ—¶é—´æ­¥éƒ½æœ‰ä¸åŒçš„å¯å­¦ä¹ ä¸ç¡®å®šæ€§ã€‚\n\n3. ä½¿ç”¨æ–¹å¼ï¼ˆè®­ç»ƒæ—¶ï¼‰\nlogvar é€šå¸¸å‚ä¸æŸå¤±å‡½æ•°å®šä¹‰ï¼Œåœ¨ get_loss() æˆ– p_losses() ä¸­ç”¨ä½œåŠ¨æ€æƒé‡ï¼š\nloss = weighted_mse / torch.exp(self.logvar[t]) + self.logvar[t]\næˆ–æ›´å¤æ‚çš„ï¼š\nloss = loss_weight * loss_raw + offset * logvar[t]\n\n4. logvaræ€»ç»“\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\né¡¹ç›®å†…å®¹åç§°logvarï¼ˆå¯¹æ•°æ–¹å·®ï¼‰ç±»å‹Tensor / nn.Parameterç»´åº¦(num_timesteps,)ç”¨é€”æ§åˆ¶ä¸åŒæ—¶é—´æ­¥çš„æŸå¤±æƒé‡ä¸ä¸ç¡®å®šæ€§å»ºæ¨¡åˆå§‹åŒ–æ–¹æ³•torch.full(size, fill_value)æ˜¯å¦å¯è®­ç»ƒç”± learn_logvar å‚æ•°æ§åˆ¶\nlogvar æ˜¯ä¸€ä¸ªæ‰©æ•£è¿‡ç¨‹ä¸­çš„æƒé‡è°ƒèŠ‚å™¨ï¼Œå°¤å…¶åœ¨åŠ å…¥ ELBOã€VLB ç­‰ç›®æ ‡æ—¶å°¤ä¸ºå…³é”®ã€‚\n\næ€»ç»“\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\né¡¹ç›®åŠŸèƒ½è¯´æ˜register_schedule()æ„é€ æ‰©æ•£è¿‡ç¨‹ä¸­æ¯ä¸€æ­¥çš„ beta å‚æ•°ï¼Œç”¨äºæ§åˆ¶åŠ å™ªè¿‡ç¨‹loss_typeå†³å®šè®­ç»ƒæ—¶çš„æŸå¤±å‡½æ•°ç±»å‹ï¼Œå¦‚ L2 æˆ– L1learn_logvar å’Œ logvaræ§åˆ¶æ˜¯å¦å­¦ä¹ æ¯ä¸ªæ—¶é—´æ­¥çš„å¯¹æ•°æ–¹å·®ï¼Œä»¥é€‚é…ä¸åŒçš„ä¸ç¡®å®šæ€§å»ºæ¨¡ç­–ç•¥\nè¿™äº›è®¾ç½®æ„æˆäº†æ‰©æ•£æ¨¡å‹è®­ç»ƒé˜¶æ®µçš„æ ¸å¿ƒæ•°å­¦åŸºç¡€ã€‚"},"StableSR_doc/ldm/models/diffusion/ddpm/class-DDPM/forward":{"slug":"StableSR_doc/ldm/models/diffusion/ddpm/class-DDPM/forward","filePath":"StableSR_doc/ldm/models/diffusion/ddpm/class DDPM/forward.md","title":"forward","links":[],"tags":[],"content":""},"StableSR_doc/ldm/models/diffusion/ddpm/class-DDPM/init_from_ckpt":{"slug":"StableSR_doc/ldm/models/diffusion/ddpm/class-DDPM/init_from_ckpt","filePath":"StableSR_doc/ldm/models/diffusion/ddpm/class DDPM/init_from_ckpt.md","title":"init_from_ckpt","links":[],"tags":[],"content":"    def init_from_ckpt(self, path, ignore_keys=list(), only_model=False):\n        sd = torch.load(path, map_location=&quot;cpu&quot;)\n        if &quot;state_dict&quot; in list(sd.keys()):\n            sd = sd[&quot;state_dict&quot;]\n        keys = list(sd.keys())\n        for k in keys:\n            for ik in ignore_keys:\n                if k.startswith(ik):\n                    print(&quot;Deleting key {} from state_dict.&quot;.format(k))\n                    del sd[k]\n        missing, unexpected = self.load_state_dict(sd, strict=False) if not only_model else self.model.load_state_dict(\n            sd, strict=False)\n        print(&#039;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&#039;)\n        print(f&quot;Restored from {path} with {len(missing)} missing and {len(unexpected)} unexpected keys&quot;)\n        if len(missing) &gt; 0:\n            print(f&quot;Missing Keys: {missing}&quot;)\n        if len(unexpected) &gt; 0:\n            print(f&quot;Unexpected Keys: {unexpected}&quot;)\ninit_from_ckpt(path, ignore_keys=list(), only_model=False) å‡½æ•°è§£æ\nè¯¥å‡½æ•°ç”¨äºä» checkpoint æ–‡ä»¶ä¸­åŠ è½½æ¨¡å‹å‚æ•°ï¼Œå¯é€‰æ‹©åªåŠ è½½ UNetï¼ˆself.modelï¼‰ï¼Œæˆ–åŠ è½½æ•´ä¸ª DDPM æ¨¡å‹æœ¬èº«ã€‚æ”¯æŒå¿½ç•¥éƒ¨åˆ†å‚æ•°é”®åï¼Œé€‚ç”¨äºå¾®è°ƒã€è¿ç§»å­¦ä¹ ç­‰åœºæ™¯ã€‚\n\nå‡½æ•°ç­¾å\ndef init_from_ckpt(self, path, ignore_keys=list(), only_model=False):\n\npath: checkpoint æ–‡ä»¶è·¯å¾„ï¼ˆé€šå¸¸ä¸º .ckpt æˆ– .pthï¼‰\nignore_keys: å­—ç¬¦ä¸²åˆ—è¡¨ï¼ŒæŒ‡å®šå“ªäº› key åº”ä» state_dict ä¸­æ’é™¤ï¼ˆå¸¸ç”¨äºå¿½ç•¥ä¸å…¼å®¹çš„æ¨¡å—ï¼‰\nonly_model: è‹¥ä¸º Trueï¼Œåˆ™åªåŠ è½½ self.model çš„å‚æ•°ï¼Œä¸åŠ è½½æ•´ä¸ª DDPM ç±»ç»“æ„ï¼ˆé€‚ç”¨äºä»…æ›´æ–° UNet æ—¶ï¼‰\n\n\n1. åŠ è½½ checkpoint å­—å…¸\nsd = torch.load(path, map_location=&quot;cpu&quot;)\nif &quot;state_dict&quot; in list(sd.keys()):\n    sd = sd[&quot;state_dict&quot;]\n\nä½¿ç”¨ torch.load åŠ è½½æƒé‡ï¼›\næœ‰äº› checkpoint æ˜¯é€šè¿‡ PyTorch Lightning ä¿å­˜çš„ï¼Œå¤–å±‚æ˜¯ä¸ªå­—å…¸ï¼Œå†…éƒ¨çš„æ¨¡å‹æƒé‡ä½äº state_dict é”®ä¸‹ï¼›\nè¿™ä¸€æ­¥å…¼å®¹è¿™ä¸¤ç§ç»“æ„ã€‚\n\n\n2. æ ¹æ® ignore_keys åˆ é™¤ä¸éœ€è¦çš„å‚æ•°\nkeys = list(sd.keys())\nfor k in keys:\n    for ik in ignore_keys:\n        if k.startswith(ik):\n            print(&quot;Deleting key {} from state_dict.&quot;.format(k))\n            del sd[k]\n\néå†æ‰€æœ‰å‚æ•°åï¼ˆkeyï¼‰ï¼Œå¦‚æœä»¥ ik ä¸­ä»»ä¸€å­—ç¬¦ä¸²å¼€å¤´ï¼Œåˆ™åˆ é™¤è¯¥ keyï¼›\nå…¸å‹ç”¨é€”ï¼šè·³è¿‡ cond_stage_model, model_ema, scheduler ç­‰ä¸å½“å‰ä»»åŠ¡æ— å…³çš„éƒ¨åˆ†ã€‚\n\n\n3. åŠ è½½æƒé‡åˆ°æ¨¡å‹ä¸­\nmissing, unexpected = self.load_state_dict(sd, strict=False) if not only_model else self.model.load_state_dict(sd, strict=False)\n\nstrict=Falseï¼šå…è®¸ checkpoint å’Œå½“å‰æ¨¡å‹ç»“æ„ä¸å®Œå…¨ä¸€è‡´ï¼ˆå¦åˆ™ä¼šæŠ¥é”™ï¼‰ï¼›\nmissingï¼šå½“å‰æ¨¡å‹ä¸­å­˜åœ¨è€Œ checkpoint ä¸­æ²¡æœ‰çš„ keyï¼›\nunexpectedï¼šcheckpoint ä¸­å­˜åœ¨ä½†å½“å‰æ¨¡å‹æ²¡æœ‰çš„ keyï¼›\næ ¹æ® only_model å†³å®šåŠ è½½æ•´ä¸ª DDPM æ¨¡å‹æˆ–ä»…åŠ è½½å…¶ self.modelï¼ˆé€šå¸¸æ˜¯ UNetï¼‰ã€‚\n\n\n4. æ‰“å°åŠ è½½ç»“æœ\nprint(&#039;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&#039;)\nprint(f&quot;Restored from {path} with {len(missing)} missing and {len(unexpected)} unexpected keys&quot;)\nif len(missing) &gt; 0:\n    print(f&quot;Missing Keys: {missing}&quot;)\nif len(unexpected) &gt; 0:\n    print(f&quot;Unexpected Keys: {unexpected}&quot;)\n\næ¸…æ™°åœ°æ±‡æŠ¥æ¢å¤æƒ…å†µï¼›\nè‹¥ missing/unexpected è¿‡å¤šï¼Œå¯èƒ½è¯´æ˜æ¨¡å‹ç»“æ„ä¸åŒ¹é…ï¼Œéœ€è¦è°ƒæ•´é…ç½®æˆ– ignore_keysã€‚\n\n\næ€»ç»“è¡¨æ ¼\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nå‚æ•°ä½œç”¨pathæŒ‡å®šåŠ è½½çš„ checkpoint æ–‡ä»¶è·¯å¾„ignore_keyså¿½ç•¥æ‰å…·æœ‰ç‰¹å®šå‰ç¼€çš„å‚æ•°é”®ï¼ˆå¦‚ model_emaï¼‰only_modelæ˜¯å¦åªåŠ è½½ self.modelï¼ˆé€šå¸¸ä¸º UNetï¼‰strict=Falseå®½æ¾åŠ è½½ï¼Œä¸è¦æ±‚ç»“æ„å®Œå…¨ä¸€è‡´missing / unexpectedåˆ†åˆ«è®°å½•ç¼ºå¤±å’Œå¤šä½™çš„å‚æ•° key å\næ­¤å‡½æ•°å¹¿æ³›ç”¨äº StableSR/LDMS/LatentDiffusion çš„é¢„è®­ç»ƒæ¨¡å‹åŠ è½½ä¸å¾®è°ƒæµç¨‹ä¸­ï¼Œæ¨èé…åˆ YAML é…ç½®ä¸ callback ä¸€èµ·ä½¿ç”¨ã€‚"},"StableSR_doc/ldm/models/diffusion/ddpm/disabled_train":{"slug":"StableSR_doc/ldm/models/diffusion/ddpm/disabled_train","filePath":"StableSR_doc/ldm/models/diffusion/ddpm/disabled_train.md","title":"disabled_train","links":[],"tags":[],"content":""},"StableSR_doc/ldm/models/diffusion/ddpm/space_timesteps":{"slug":"StableSR_doc/ldm/models/diffusion/ddpm/space_timesteps","filePath":"StableSR_doc/ldm/models/diffusion/ddpm/space_timesteps.md","title":"space_timesteps","links":[],"tags":[],"content":""},"StableSR_doc/ldm/models/diffusion/ddpm/torch2img":{"slug":"StableSR_doc/ldm/models/diffusion/ddpm/torch2img","filePath":"StableSR_doc/ldm/models/diffusion/ddpm/torch2img.md","title":"torch2img","links":[],"tags":[],"content":"def torch2img(input):\n    input_ = input[0]\n    input_ = input_.permute(1,2,0)\n    input_ = input_.data.cpu().numpy()\n    input_ = (input_ + 1.0) / 2\n    cv2.imwrite(&#039;./test.png&#039;, input_[:,:,::-1]*255.0)"},"StableSR_doc/ldm/models/diffusion/ddpm/uniform_on_device":{"slug":"StableSR_doc/ldm/models/diffusion/ddpm/uniform_on_device","filePath":"StableSR_doc/ldm/models/diffusion/ddpm/uniform_on_device.md","title":"uniform_on_device","links":[],"tags":[],"content":""},"StableSR_doc/ldm/models/diffusion/ddpm/visualize_fea":{"slug":"StableSR_doc/ldm/models/diffusion/ddpm/visualize_fea","filePath":"StableSR_doc/ldm/models/diffusion/ddpm/visualize_fea.md","title":"visualize_fea","links":[],"tags":[],"content":""},"StableSR_doc/ldm/modules/diffusionmodules/openaimodel/Module_info":{"slug":"StableSR_doc/ldm/modules/diffusionmodules/openaimodel/Module_info","filePath":"StableSR_doc/ldm/modules/diffusionmodules/openaimodel/Module_info.md","title":"Module_info","links":["convert_module_to_f16","convert_module_to_f32","exists","cal_fea_cossim","count_flops_attn","AttentionPool2d","TimestepBlock","TimestepBlockDual","TimestepBlock3cond","TimestepEmbedSequential","Upsample","TransposedUpsample","Downsample","ResBlock","ResBlockDual","AttentionBlock","QKVAttentionLegacy","QKVAttention","UNetModel","StableSR_doc/ldm/modules/diffusionmodules/openaimodel/class-UNetModelDualcondV2/UNetModelDualcondV2","EncoderUNetModelWT"],"tags":[],"content":"ldm/modules/diffusionmodules/openaimodel.py\n\n\n                  \n                  UMLå›¾è§£ï¼šopenaimodels.py \n                  \n                \n\n\n\n\n\n\nFunctions\n\nconvert_module_to_f16\nconvert_module_to_f32\nexists\ncal_fea_cossim\ncount_flops_attn\n\nClasses\n\nAttentionPool2d\nTimestepBlock\nTimestepBlockDual\nTimestepBlock3cond\nTimestepEmbedSequential\nUpsample\nTransposedUpsample\nDownsample\nResBlock\nResBlockDual\nAttentionBlock\nQKVAttentionLegacy\nQKVAttention\nUNetModel\nUNetModelDualcondV2\nEncoderUNetModelWT\n"},"StableSR_doc/ldm/modules/diffusionmodules/openaimodel/class-UNetModelDualcondV2/UNetModelDualcondV2":{"slug":"StableSR_doc/ldm/modules/diffusionmodules/openaimodel/class-UNetModelDualcondV2/UNetModelDualcondV2","filePath":"StableSR_doc/ldm/modules/diffusionmodules/openaimodel/class UNetModelDualcondV2/UNetModelDualcondV2.md","title":"UNetModelDualcondV2","links":["StableSR_doc/ldm/modules/diffusionmodules/openaimodel/class-UNetModelDualcondV2/attribute","StableSR_doc/ldm/modules/diffusionmodules/openaimodel/class-UNetModelDualcondV2/UNetModelDualcondV2","StableSR_doc/ldm/modules/diffusionmodules/openaimodel/class-UNetModelDualcondV2/convert_to_fp16","StableSR_doc/ldm/modules/diffusionmodules/openaimodel/class-UNetModelDualcondV2/convert_to_fp32","forward"],"tags":[],"content":"Class: UNetModelDualcondV2\nInheritance Tree (MRO):\n\nUNetModelDualcondV2\nnn.Module\nobject\n\nInstance Attributes (from self.xxx assignments):\n\nimage_size (defined in: init)\nin_channels (defined in: init)\nmodel_channels (defined in: init)\nout_channels (defined in: init)\nattention_resolutions (defined in: init)\ndropout (defined in: init)\nchannel_mult (defined in: init)\nconv_resample (defined in: init)\nnum_classes (defined in: init)\nuse_checkpoint (defined in: init)\ndtype (defined in: init)\nnum_heads (defined in: init)\nnum_head_channels (defined in: init)\nnum_heads_upsample (defined in: init)\npredict_codebook_ids (defined in: init)\ntime_embed (defined in: init)\ninput_blocks (defined in: init)\n_feature_size (defined in: init)\nmiddle_block (defined in: init)\noutput_blocks (defined in: init)\nout (defined in: init)\nnum_res_blocks (defined in: init, init)\nid_predictor (defined in: init)\nlabel_emb (defined in: init, init)\nattribute\n\nProject-defined Methods:\n\n[[init]]  â†  UNetModelDualcondV2\nconvert_to_fp16  â†  UNetModelDualcondV2\nconvert_to_fp32  â†  UNetModelDualcondV2\nforward  â†  UNetModelDualcondV2\n\nProject-defined Class Attributes:"},"StableSR_doc/ldm/modules/diffusionmodules/openaimodel/class-UNetModelDualcondV2/__init__":{"slug":"StableSR_doc/ldm/modules/diffusionmodules/openaimodel/class-UNetModelDualcondV2/__init__","filePath":"StableSR_doc/ldm/modules/diffusionmodules/openaimodel/class UNetModelDualcondV2/__init__.md","title":"__init__","links":[],"tags":[],"content":"init\n    def __init__(\n        self,\n        image_size,\n        in_channels,\n        model_channels,\n        out_channels,\n        num_res_blocks,\n        attention_resolutions,\n        dropout=0,\n        channel_mult=(1, 2, 4, 8),\n        conv_resample=True,\n        dims=2,\n        num_classes=None,\n        use_checkpoint=False,\n        use_fp16=False,\n        num_heads=-1,\n        num_head_channels=-1,\n        num_heads_upsample=-1,\n        use_scale_shift_norm=False,\n        resblock_updown=False,\n        use_new_attention_order=False,\n        use_spatial_transformer=False,    # custom transformer support\n        transformer_depth=1,              # custom transformer support\n        context_dim=None,                 # custom transformer support\n        n_embed=None,                     # custom support for prediction of discrete ids into codebook of first stage vq model\n        legacy=True,\n        disable_self_attentions=None,\n        num_attention_blocks=None,\n        disable_middle_self_attn=False,\n        use_linear_in_transformer=False,\n        semb_channels=None\n    ):\n        super().__init__()\n        if use_spatial_transformer:\n            assert context_dim is not None, &#039;Fool!! You forgot to include the dimension of your cross-attention conditioning...&#039;\n \n        if context_dim is not None:\n            assert use_spatial_transformer, &#039;Fool!! You forgot to use the spatial transformer for your cross-attention conditioning...&#039;\n            from omegaconf.listconfig import ListConfig\n            if type(context_dim) == ListConfig:\n                context_dim = list(context_dim)\n \n        if num_heads_upsample == -1:\n            num_heads_upsample = num_heads\n \n        if num_heads == -1:\n            assert num_head_channels != -1, &#039;Either num_heads or num_head_channels has to be set&#039;\n \n        if num_head_channels == -1:\n            assert num_heads != -1, &#039;Either num_heads or num_head_channels has to be set&#039;\n \n        self.image_size = image_size\n        self.in_channels = in_channels\n        self.model_channels = model_channels\n        self.out_channels = out_channels\n        if isinstance(num_res_blocks, int): # [[#residual-block|residual block]]\n            self.num_res_blocks = len(channel_mult) * [num_res_blocks]\n        else:\n            if len(num_res_blocks) != len(channel_mult):\n                raise ValueError(&quot;provide num_res_blocks either as an int (globally constant) or &quot;\n                                 &quot;as a list/tuple (per-level) with the same length as channel_mult&quot;)\n            self.num_res_blocks = num_res_blocks\n        if disable_self_attentions is not None: # [[#attention-block|attention block]]\n            # should be a list of booleans, indicating whether to disable self-attention in TransformerBlocks or not\n            assert len(disable_self_attentions) == len(channel_mult)\n        if num_attention_blocks is not None:\n            assert len(num_attention_blocks) == len(self.num_res_blocks)\n            assert all(map(lambda i: self.num_res_blocks[i] &gt;= num_attention_blocks[i], range(len(num_attention_blocks))))\n            print(f&quot;Constructor of UNetModel received num_attention_blocks={num_attention_blocks}. &quot;\n                  f&quot;This option has LESS priority than attention_resolutions {attention_resolutions}, &quot;\n                  f&quot;i.e., in cases where num_attention_blocks[i] &gt; 0 but 2**i not in attention_resolutions, &quot;\n                  f&quot;attention will still not be set.&quot;)\n\t\t# [[#unet-å…³é”®å‚æ•°é…ç½®|UNet å…³é”®å‚æ•°é…ç½®]] \n        self.attention_resolutions = attention_resolutions\n        self.dropout = dropout\n        self.channel_mult = channel_mult\n        self.conv_resample = conv_resample\n        self.num_classes = num_classes\n        self.use_checkpoint = use_checkpoint\n        self.dtype = th.float16 if use_fp16 else th.float32\n        self.num_heads = num_heads\n        self.num_head_channels = num_head_channels\n        self.num_heads_upsample = num_heads_upsample\n        self.predict_codebook_ids = n_embed is not None\n\t\t# [[#time_embed|time_embed]]\n        time_embed_dim = model_channels * 4\n        self.time_embed = nn.Sequential(\n            linear(model_channels, time_embed_dim),\n            nn.SiLU(),\n            linear(time_embed_dim, time_embed_dim),\n        )\n\t\t# [[#ç±»åˆ«æ¡ä»¶class-conditionalæœºåˆ¶åœ¨-unet-ä¸­çš„å®ç°|ç±»åˆ«æ¡ä»¶ï¼ˆClass-Conditionalï¼‰æœºåˆ¶åœ¨ UNet ä¸­çš„å®ç°]]\n        if self.num_classes is not None:\n            if isinstance(self.num_classes, int):\n                self.label_emb = nn.Embedding(num_classes, time_embed_dim)\n            elif self.num_classes == &quot;continuous&quot;:\n                print(&quot;setting up linear c_adm embedding layer&quot;)\n                self.label_emb = nn.Linear(1, time_embed_dim)\n            else:\n                raise ValueError()\n \n        self.input_blocks = nn.ModuleList(\n            [\n                TimestepEmbedSequential(\n                    conv_nd(dims, in_channels, model_channels, 3, padding=1)\n                )\n            ]\n        )\n        self._feature_size = model_channels\n        input_block_chans = [model_channels]\n        ch = model_channels\n        ds = 1\n        for level, mult in enumerate(channel_mult):\n            for nr in range(self.num_res_blocks[level]):\n                layers = [\n                    ResBlockDual(\n                        ch,\n                        time_embed_dim,\n                        dropout,\n                        semb_channels=semb_channels,\n                        out_channels=mult * model_channels,\n                        dims=dims,\n                        use_checkpoint=use_checkpoint,\n                        use_scale_shift_norm=use_scale_shift_norm,\n                    )\n                ]\n                ch = mult * model_channels\n                if ds in attention_resolutions:\n                    if num_head_channels == -1:\n                        dim_head = ch // num_heads\n                    else:\n                        num_heads = ch // num_head_channels\n                        dim_head = num_head_channels\n                    if legacy:\n                        #num_heads = 1\n                        dim_head = ch // num_heads if use_spatial_transformer else num_head_channels\n                    if exists(disable_self_attentions):\n                        disabled_sa = disable_self_attentions[level]\n                    else:\n                        disabled_sa = False\n \n                    if not exists(num_attention_blocks) or nr &lt; num_attention_blocks[level]:\n                        layers.append(\n                            AttentionBlock(\n                                ch,\n                                use_checkpoint=use_checkpoint,\n                                num_heads=num_heads,\n                                num_head_channels=dim_head,\n                                use_new_attention_order=use_new_attention_order,\n                            ) if not use_spatial_transformer else SpatialTransformerV2(\n                                ch, num_heads, dim_head, depth=transformer_depth, context_dim=context_dim,\n                                disable_self_attn=disabled_sa, use_linear=use_linear_in_transformer,\n                                use_checkpoint=use_checkpoint\n                            )\n                        )\n                self.input_blocks.append(TimestepEmbedSequential(*layers))\n                self._feature_size += ch\n                input_block_chans.append(ch)\n            if level != len(channel_mult) - 1:\n                out_ch = ch\n                self.input_blocks.append(\n                    TimestepEmbedSequential(\n                        ResBlockDual(\n                            ch,\n                            time_embed_dim,\n                            dropout,\n                            semb_channels=semb_channels,\n                            out_channels=out_ch,\n                            dims=dims,\n                            use_checkpoint=use_checkpoint,\n                            use_scale_shift_norm=use_scale_shift_norm,\n                            down=True,\n                        )\n                        if resblock_updown\n                        else Downsample(\n                            ch, conv_resample, dims=dims, out_channels=out_ch\n                        )\n                    )\n                )\n                ch = out_ch\n                input_block_chans.append(ch)\n                ds *= 2\n                self._feature_size += ch\n\t\t# [[#attention_head|attention_head]] \n        if num_head_channels == -1:\n            dim_head = ch // num_heads\n        else:\n            num_heads = ch // num_head_channels\n            dim_head = num_head_channels\n        if legacy:\n            #num_heads = 1\n            dim_head = ch // num_heads if use_spatial_transformer else num_head_channels\n        self.middle_block = TimestepEmbedSequential(\n            ResBlockDual(\n                ch,\n                time_embed_dim,\n                dropout,\n                semb_channels=semb_channels,\n                dims=dims,\n                use_checkpoint=use_checkpoint,\n                use_scale_shift_norm=use_scale_shift_norm,\n            ),\n            AttentionBlock(\n                ch,\n                use_checkpoint=use_checkpoint,\n                num_heads=num_heads,\n                num_head_channels=dim_head,\n                use_new_attention_order=use_new_attention_order,\n            ) if not use_spatial_transformer else SpatialTransformerV2(  # always uses a self-attn\n                            ch, num_heads, dim_head, depth=transformer_depth, context_dim=context_dim,\n                            disable_self_attn=disable_middle_self_attn, use_linear=use_linear_in_transformer,\n                            use_checkpoint=use_checkpoint\n                        ),\n            ResBlockDual(\n                ch,\n                time_embed_dim,\n                dropout,\n                semb_channels=semb_channels,\n                dims=dims,\n                use_checkpoint=use_checkpoint,\n                use_scale_shift_norm=use_scale_shift_norm,\n            ),\n        )\n        self._feature_size += ch\n \n        self.output_blocks = nn.ModuleList([])\n        for level, mult in list(enumerate(channel_mult))[::-1]:\n            for i in range(self.num_res_blocks[level] + 1):\n                ich = input_block_chans.pop()\n                layers = [\n                    ResBlockDual(\n                        ch + ich,\n                        time_embed_dim,\n                        dropout,\n                        semb_channels=semb_channels,\n                        out_channels=model_channels * mult,\n                        dims=dims,\n                        use_checkpoint=use_checkpoint,\n                        use_scale_shift_norm=use_scale_shift_norm,\n                    )\n                ]\n                ch = model_channels * mult\n                if ds in attention_resolutions:\n                    if num_head_channels == -1:\n                        dim_head = ch // num_heads\n                    else:\n                        num_heads = ch // num_head_channels\n                        dim_head = num_head_channels\n                    if legacy:\n                        #num_heads = 1\n                        dim_head = ch // num_heads if use_spatial_transformer else num_head_channels\n                    if exists(disable_self_attentions):\n                        disabled_sa = disable_self_attentions[level]\n                    else:\n                        disabled_sa = False\n \n                    if not exists(num_attention_blocks) or i &lt; num_attention_blocks[level]:\n                        layers.append(\n                            AttentionBlock(\n                                ch,\n                                use_checkpoint=use_checkpoint,\n                                num_heads=num_heads_upsample,\n                                num_head_channels=dim_head,\n                                use_new_attention_order=use_new_attention_order,\n                            ) if not use_spatial_transformer else SpatialTransformerV2(\n                                ch, num_heads, dim_head, depth=transformer_depth, context_dim=context_dim,\n                                disable_self_attn=disabled_sa, use_linear=use_linear_in_transformer,\n                                use_checkpoint=use_checkpoint\n                            )\n                        )\n                if level and i == self.num_res_blocks[level]:\n                    out_ch = ch\n                    layers.append(\n                        ResBlockDual(\n                            ch,\n                            time_embed_dim,\n                            dropout,\n                            semb_channels=semb_channels,\n                            out_channels=out_ch,\n                            dims=dims,\n                            use_checkpoint=use_checkpoint,\n                            use_scale_shift_norm=use_scale_shift_norm,\n                            up=True,\n                        )\n                        if resblock_updown\n                        else Upsample(ch, conv_resample, dims=dims, out_channels=out_ch)\n                    )\n                    ds //= 2\n                self.output_blocks.append(TimestepEmbedSequential(*layers))\n                self._feature_size += ch\n \n        self.out = nn.Sequential(\n            normalization(ch),\n            nn.SiLU(),\n            zero_module(conv_nd(dims, model_channels, out_channels, 3, padding=1)),\n        )\n        if self.predict_codebook_ids:\n            self.id_predictor = nn.Sequential(\n            normalization(ch),\n            conv_nd(dims, model_channels, n_embed, 1),\n            #nn.LogSoftmax(dim=1)  # change to cross_entropy and produce non-normalized logits\n        )\nattention_head\nåœ¨ä½¿ç”¨å¤šå¤´æ³¨æ„åŠ›æ¨¡å—ï¼ˆå¦‚ AttentionBlock æˆ– SpatialTransformerV2ï¼‰æ—¶ï¼Œéœ€è¦æŒ‡å®šä¸‹åˆ—ä¸¤ä¸ªå‚æ•°ä¹‹ä¸€ï¼š\n\nnum_headsï¼šæ³¨æ„åŠ›å¤´çš„æ•°é‡ï¼ˆä¾‹å¦‚ 8 è¡¨ç¤ºä½¿ç”¨ 8 ä¸ªå¹¶è¡Œæ³¨æ„åŠ›åˆ†æ”¯ï¼‰\nnum_head_channelsï¼šæ¯ä¸ªæ³¨æ„åŠ›å¤´çš„é€šé“å®½åº¦ï¼ˆä¾‹å¦‚ 64 è¡¨ç¤ºæ¯ä¸ªå¤´ç»´åº¦ä¸º 64ï¼‰\n\näºŒè€…çš„å…³ç³»\näºŒè€…æ»¡è¶³å¦‚ä¸‹å…³ç³»ï¼š\n\\mathrm{num\\_heads} \\times \\mathrm{num\\_head\\_channels} \\leq \\mathrm{total\\_channels}\nä½ åªéœ€è¦æ˜¾å¼æŒ‡å®šä¸€ä¸ªï¼Œå¦ä¸€ä¸ªå¯ä»¥è‡ªåŠ¨æ¨å¯¼ã€‚\nå‚æ•°æ£€æŸ¥é€»è¾‘\næºä»£ç ä¸­çš„æ ¡éªŒé€»è¾‘å¦‚ä¸‹ï¼š\nif num_heads == -1:\n    assert num_head_channels != -1, &#039;Either num_heads or num_head_channels has to be set&#039;\n \nif num_head_channels == -1:\n    assert num_heads != -1, &#039;Either num_heads or num_head_channels has to be set&#039;\nä¹Ÿå°±æ˜¯è¯´ï¼Œå¿…é¡»è‡³å°‘æŒ‡å®šä¸€ä¸ªå‚æ•°ï¼Œå¦åˆ™å°†æŠ›å‡ºé”™è¯¯ã€‚\nï¸ æ³¨æ„äº‹é¡¹\n\nè‹¥ total_channels æ— æ³•æ•´é™¤æŒ‡å®šå‚æ•°ï¼Œå¯èƒ½å¯¼è‡´è®¡ç®—å‡ºé”™æˆ–ç»´åº¦ä¸ä¸€è‡´ï¼›\nä¸¤è€…éƒ½æŒ‡å®šæ—¶è¦ç¡®ä¿ä¸€è‡´æ€§ï¼Œå³ï¼šnum_heads * num_head_channels == total_channelsï¼›\næ¨èåšæ³•æ˜¯ï¼šè®¾ç½®ä½ æƒ³æ§åˆ¶çš„é‚£ä¸€ä¸ªï¼Œç•™å¦ä¸€ä¸ªè‡ªåŠ¨è®¡ç®—ã€‚\n\nç¤ºä¾‹\nå‡è®¾å½“å‰å±‚é€šé“æ•°ä¸º 320ï¼š\n\nè‹¥è®¾ç½® num_heads=8ï¼Œåˆ™ num_head_channels=320 // 8 = 40\nè‹¥è®¾ç½® num_head_channels=64ï¼Œåˆ™ num_heads=320 // 64 = 5\n\n# æ¨èç¤ºä¾‹\nattention_block = AttentionBlock(\n    channels=320,\n    num_heads=8,\n    num_head_channels=-1,  # è‡ªåŠ¨è®¡ç®—ä¸º 40\n)\n \n# æˆ–è€…\nattention_block = AttentionBlock(\n    channels=320,\n    num_heads=-1,\n    num_head_channels=64,  # è‡ªåŠ¨è®¡ç®—ä¸º 5 heads\n)\nresidual block\nè¿™æ®µä»£ç ç”¨äºé…ç½®UNetçš„å„å±‚ä¸­æ®‹å·®å—ï¼ˆresidual blockï¼‰çš„æ•°é‡ã€‚\n        if isinstance(num_res_blocks, int):\n            self.num_res_blocks = len(channel_mult) * [num_res_blocks]\nå¦‚æœä¼ å…¥çš„num_res_blockså‚æ•°æ˜¯å•ä¸€æ•´æ•°ï¼Œé‚£ä¹ˆæ¯ä¸€å±‚å°†éƒ½ä½¿ç”¨è¿™ä¸ªæ•°é‡çš„æ®‹å·®å—ã€‚\n        else:\n            if len(num_res_blocks) != len(channel_mult):\n                raise ValueError(&quot;provide num_res_blocks either as an int (globally constant) or &quot;\n                                 &quot;as a list/tuple (per-level) with the same length as channel_mult&quot;)\n            self.num_res_blocks = num_res_blocks\nå¦‚æœä¼ å…¥çš„num_res_blockså‚æ•°ä¸æ˜¯æ•´æ•°ï¼Œé‚£ä¹ˆæœŸæœ›ä¸ºåˆ—è¡¨æˆ–å…¶ä»–åŒ…å«æ•´æ•°åºåˆ—çš„æœ‰åºå®¹å™¨ï¼Œä¸”è¯¥å®¹å™¨çš„é•¿åº¦åº”å’Œchannel_multçš„é•¿åº¦ï¼ˆä¹Ÿå³UNetçš„å•æµ‹æ·±åº¦ï¼‰ç›¸åŒã€‚\nattention block\nè¿™æ®µä»£ç é…ç½®äº†attention blockï¼ˆè‡ªæ³¨æ„åŠ›æœºåˆ¶ï¼‰éƒ¨åˆ†çš„å¯ç”¨æƒ…å†µã€‚\næ³¨æ„ï¼šåœ¨StableSRä¸­ï¼Œè‡ªæ³¨æ„åŠ›å’Œäº¤å‰æ³¨æ„åŠ›éƒ½æ˜¯é€šè¿‡ç»Ÿä¸€çš„transformeræ¨¡å—å®ç°çš„ï¼Œå…¶è‡ªæ³¨æ„åŠ›æœºåˆ¶å¹¶ä¸æ˜¯SR3é‚£æ ·ä¼ ç»Ÿçš„dot-product attentionã€‚StableSRä¸­ï¼Œè¯¥transformerå¯ä»¥é€‰æ‹©æ˜¯å¦å¼€å¯è‡ªæ³¨æ„åŠ›éƒ¨åˆ†ï¼Œä½†é»˜è®¤å¿…é¡»å¼€å¯äº¤å‰æ³¨æ„åŠ›ä»¥ä¸ºUNetæä¾›å¿…è¦çš„ç”Ÿæˆæ¡ä»¶ã€‚\n        if disable_self_attentions is not None:\n            # should be a list of booleans, indicating whether to disable self-attention in TransformerBlocks or not\n            assert len(disable_self_attentions) == len(channel_mult)\ndisable_self_attentionså‚æ•°æœŸæœ›æ˜¯Noneæˆ–è€…ä¸channel_multé•¿åº¦ç›¸åŒçš„å¸ƒå°”æ•°ç»„ï¼Œç”¨äºæ§åˆ¶UNetå†…å„å±‚æ˜¯å¦å¼€å¯è‡ªæ³¨æ„åŠ›æ¨¡å—ã€‚Noneè¡¨ç¤ºå…¨éƒ¨å¼€å¯ï¼Œå¸ƒå°”æ•°ç»„åˆ™æŒ‰ç…§å…¶çœŸå€¼æ§åˆ¶ã€‚\n        if num_attention_blocks is not None:\n            assert len(num_attention_blocks) == len(self.num_res_blocks)\n            assert all(map(lambda i: self.num_res_blocks[i] &gt;= num_attention_blocks[i], range(len(num_attention_blocks))))\n            print(f&quot;Constructor of UNetModel received num_attention_blocks={num_attention_blocks}. &quot;\n                  f&quot;This option has LESS priority than attention_resolutions {attention_resolutions}, &quot;\n                  f&quot;i.e., in cases where num_attention_blocks[i] &gt; 0 but 2**i not in attention_resolutions, &quot;\n                  f&quot;attention will still not be set.&quot;)\n\n\næ§åˆ¶ æ¯ä¸€å±‚ä¸­æœ€å¤šèƒ½æ’å…¥å¤šå°‘ä¸ª attention æ¨¡å—ï¼›\n\n\nä¸æ˜¯å±‚çº§æ•°ï¼Œè€Œæ˜¯å®é™… ResBlock æ•°é‡å¯¹ attention çš„æ•°é‡é™åˆ¶ï¼›\n\n\nå¿…é¡»åŒ¹é…ç»“æ„æ·±åº¦ï¼Œå³ num_attention_blocks[i] â‰¤ num_res_blocks[i]ã€‚\n\n\næ‰“å°è¯­å¥æ›´åŠ æ¸…æ™°åœ°è¡¨æ˜äº†é…ç½®å‚æ•°çš„ä¼˜å…ˆçº§å…³ç³»\n\n\næœ€ç»ˆæ˜¯å¦æ’å…¥ attention block çš„åˆ¤å®šï¼Œé¦–å…ˆçœ‹ attention_resolutionsï¼Œç„¶åæ‰çœ‹ num_attention_blocksã€‚\n\n\nä¹Ÿå°±æ˜¯è¯´ï¼š\n\n\nä½ å¯ä»¥è®¾ç½® num_attention_blocks[i] = 1 è¡¨ç¤ºâ€œæœ€å¤šæ’å…¥ 1 ä¸ªâ€ï¼›\n\n\nä½†å¦‚æœ 2**i ä¸åœ¨ attention_resolutionsï¼ˆä¾‹å¦‚ 16, 32ï¼‰ä¸­ï¼Œé‚£ attention å°±ä¸ä¼šæ’å…¥ï¼›\n\n\næ¢å¥è¯è¯´ï¼šä½ åªè¡¨è¾¾äº†â€œå…è®¸æ’å…¥â€ï¼Œæ’ä¸æ’è¦ç”± attention_resolutions å†³å®šã€‚\n\n\n\n\nUNet å…³é”®å‚æ•°é…ç½®\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nå‚æ•°è¯´æ˜attention_resolutionsæ§åˆ¶åœ¨å“ªäº›åˆ†è¾¨ç‡ä¸‹æ’å…¥ attentionï¼ˆå¦‚ 16ã€32ï¼‰dropoutdropout æ¦‚ç‡ï¼Œç”¨äº regularizationchannel_multæ¯ä¸€å±‚é€šé“æ•°æ˜¯åŸºé€šé“æ•°ï¼ˆmodel_channelsï¼‰çš„å‡ å€conv_resampleæ˜¯å¦ä½¿ç”¨å·ç§¯å®ç°ä¸‹/ä¸Šé‡‡æ ·ï¼ˆTrue ä¸ºå¯å­¦ä¹ ï¼‰num_classesæ˜¯å¦ä½¿ç”¨ class-conditional æ¡ä»¶ï¼ˆå¦‚æ ‡ç­¾ï¼‰use_checkpointæ˜¯å¦ä½¿ç”¨ gradient checkpointing å‡å°‘æ˜¾å­˜dtypeç½‘ç»œä¸­ä½¿ç”¨çš„ç²¾åº¦ï¼ˆfloat16 æˆ– float32ï¼‰num_heads / num_head_channelsAttention ä¸­çš„ head è®¾ç½®num_heads_upsampleä¸Šé‡‡æ ·é˜¶æ®µçš„ head æ•°predict_codebook_idsæ˜¯å¦è¾“å‡º codebook tokenï¼ˆå³æ˜¯å¦ä¸º VQGAN decoderï¼‰\ntime_embed\næ³¨æ„ï¼šè¿™æ˜¯å°†æ—¶é—´ä¿¡æ¯å¼•å…¥UNetçš„æ ¸å¿ƒé€”å¾„ã€‚\n        time_embed_dim = model_channels * 4\n        self.time_embed = nn.Sequential(\n            linear(model_channels, time_embed_dim),\n            nn.SiLU(),\n            linear(time_embed_dim, time_embed_dim),\n        )\nè¿™æ®µä»£ç æ„é€ äº†ä¸€ä¸ªç®€å•çš„ MLPï¼ˆå¤šå±‚æ„ŸçŸ¥æœºï¼‰ï¼Œå°†åŸå§‹çš„ timestep embedding æ˜ å°„æˆä¾› ResBlock ä½¿ç”¨çš„æ—¶é—´æ¡ä»¶å‘é‡ã€‚\n\nè¾“å…¥ç»´åº¦ï¼šmodel_channelsï¼ˆä¾‹å¦‚ 320ï¼‰\nè¾“å‡ºç»´åº¦ï¼štime_embed_dim = 4 Ã— model_channelsï¼ˆä¾‹å¦‚ 1280ï¼‰\næ¿€æ´»å‡½æ•°ï¼šSiLUï¼ˆå³ Swish æ¿€æ´»ï¼Œæ•ˆæœæ¯” ReLU æ›´å¹³æ»‘ï¼‰\n\nTODO:time_embedåªæ˜¯time aware encoderçš„ä¸€ä¸ªæ¨¡å—ï¼Œåœ¨è¿›å…¥ä»–ä¹‹å‰ä¼šæœ‰ä¸€ä¸ªåŸå§‹çš„time embedingï¼ˆå¯èƒ½æ˜¯æ­£ä½™å¼¦ä½ç½®ç¼–ç ï¼‰ï¼Œå°†ç¼–ç ç»“æœè¾“å…¥è¿™ä¸ªtime_embedçš„MLPæ¥è¿›ä¸€æ­¥æ·»åŠ å¯å­¦ä¹ æ€§ï¼Œå…¶è¾“å‡ºç”¨äºè°ƒèŠ‚æ®‹å·®å—çš„å·¥ä½œæ¨¡å¼ã€‚ä»¥ä¸Šå†…å®¹åº”è¯¥åœ¨åç»­ä»£ç å’Œforwardå‡½æ•°ä¸­æœ‰æ›´å¤šçš„ä½“ç°ã€‚\nç±»åˆ«æ¡ä»¶ï¼ˆClass-Conditionalï¼‰æœºåˆ¶åœ¨ UNet ä¸­çš„å®ç°\nä¸€ã€ä»€ä¹ˆæ˜¯ç±»åˆ«æ¡ä»¶ï¼Ÿ\nåœ¨æ‰©æ•£æ¨¡å‹ï¼ˆå¦‚ DDPMã€StableSRã€LDMï¼‰ä¸­ï¼Œç±»åˆ«æ¡ä»¶æ˜¯ä¸€ç§ç”¨äºå¼•å¯¼å›¾åƒç”Ÿæˆæ–¹å‘çš„è¾…åŠ©ä¿¡æ¯ã€‚é€šè¿‡åœ¨æ¯ä¸€æ­¥æ‰©æ•£ä¸­æ³¨å…¥ç±»åˆ«æ ‡ç­¾ï¼Œæ¨¡å‹èƒ½å¤Ÿå­¦ä¹ ï¼š\n\nå¦‚ä½•åœ¨ç¬¬ t æ­¥ç”Ÿæˆå±äºç±»åˆ« y çš„å›¾åƒç‰¹å¾ã€‚\n\nè¯¥æœºåˆ¶é€‚ç”¨äºåˆ†ç±»å¼•å¯¼å›¾åƒç”Ÿæˆï¼Œä¾‹å¦‚ï¼š\n\nç”Ÿæˆä¸€å¼ â€œçŒ«â€è€Œä¸æ˜¯â€œç‹—â€çš„å›¾åƒ\nåˆæˆç‰¹å®šç±»å‹çš„å»ºç­‘ã€è½¦è¾†æˆ–è‡ªç„¶åœºæ™¯å›¾åƒ\næ¡ä»¶æ§åˆ¶ä»»åŠ¡ï¼Œå¦‚ super-resolution with category hints\n\n\näºŒã€å®ç°æ–¹å¼\nåœ¨ UNetModelDualcondV2 ä¸­ï¼Œç±»åˆ«æ¡ä»¶é€šè¿‡ä»¥ä¸‹ç»“æ„å®ç°ï¼š\nif isinstance(self.num_classes, int):\n    self.label_emb = nn.Embedding(num_classes, time_embed_dim)\nelif self.num_classes == &quot;continuous&quot;:\n    self.label_emb = nn.Linear(1, time_embed_dim)\næ”¯æŒä¸¤ç§ç±»åˆ«æ¡ä»¶æ ¼å¼ï¼š\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nç±»å‹å«ä¹‰æ¨¡å—è¾“å…¥å½¢å¼ç¦»æ•£ç±»åˆ«æ˜ç¡®ç±»åˆ«æ ‡ç­¾ï¼Œå¦‚ 0~9nn.Embeddingy âˆˆ {0, ..., num_classes}è¿ç»­å˜é‡å±æ€§å€¼ã€å®æ•°æ¡ä»¶nn.Lineary âˆˆ â„ï¼ˆå½¢å¦‚ [B, 1]ï¼‰\nåµŒå…¥åå°†ä¸æ—¶é—´åµŒå…¥ç›¸åŠ ï¼Œç”¨äºè°ƒèŠ‚æ¯ä¸ª ResBlockï¼š\nemb = time_embed(t) + label_emb(y)\n\nä¸‰ã€ç±»åˆ«æ¡ä»¶çš„æ¥æº\nç±»åˆ«æ¡ä»¶ ä¸æ˜¯è‡ªåŠ¨ç”Ÿæˆçš„ï¼Œè€Œæ˜¯ ç”±ç”¨æˆ·æ˜¾å¼æä¾›ï¼š\n\nå¯¹äºåˆ†ç±»ä»»åŠ¡ï¼šæ ‡ç­¾ y æ¥è‡ªæ•°æ®é›†ï¼›\nå¯¹äºè¿ç»­æ¡ä»¶ä»»åŠ¡ï¼šå¦‚æ¨¡ç³Šç¨‹åº¦ã€æ¸©åº¦ç­‰æ•°å€¼ï¼Œç”±ç”¨æˆ·è®¾å®šï¼›\nä¸ä½¿ç”¨ç±»åˆ«æ¡ä»¶æ—¶ï¼Œè®¾ç½® num_classes = None å³å¯å…³é—­ã€‚\n\n\nå››ã€å…³é—­ç±»åˆ«æ¡ä»¶çš„æ–¹æ³•\nåªéœ€åœ¨åˆå§‹åŒ–æ¨¡å‹æ—¶è®¾å®šï¼š\nnum_classes = None\nå³å¯å®Œå…¨å…³é—­ç±»åˆ«æ¡ä»¶è·¯å¾„ï¼š\n\nä¸æ„å»º label_emb\næ—¶é—´åµŒå…¥ emb = time_embed(t) ä¸å†åŒ…å«ç±»åˆ«ä¿¡æ¯\næ¨¡å‹ä»…ä¾èµ–æ—¶é—´æ­¥ä¸å…¶ä»–æ¡ä»¶ï¼ˆå¦‚ç»“æ„æ¡ä»¶ï¼‰\n\n\näº”ã€æŠ€æœ¯æ„ä¹‰\nç±»åˆ«æ¡ä»¶æ‰©å±•äº†æ‰©æ•£æ¨¡å‹çš„èƒ½åŠ›ï¼Œä½¿å…¶æ”¯æŒï¼š\n\nåˆ†ç±»æ§åˆ¶ç”Ÿæˆï¼ˆclass-conditional generationï¼‰\nå¤šæ¨¡æ€æ§åˆ¶ç»“æ„ï¼ˆå¦‚ time + class + structureï¼‰\né€šç”¨æ§åˆ¶å™¨è®¾è®¡ï¼ˆæ”¯æŒæ ‡ç­¾ã€æ¨¡æ€ã€é£æ ¼ç­‰æ³¨å…¥ï¼‰\n\nè¿™ä¸€æœºåˆ¶ä¹Ÿä¸ºåç»­åŠ å…¥ cross-attention ç­‰ç»“æ„æä¾›äº†æ¡ä»¶è¾“å…¥çš„é€šé“ã€‚"},"StableSR_doc/ldm/modules/diffusionmodules/openaimodel/class-UNetModelDualcondV2/attribute":{"slug":"StableSR_doc/ldm/modules/diffusionmodules/openaimodel/class-UNetModelDualcondV2/attribute","filePath":"StableSR_doc/ldm/modules/diffusionmodules/openaimodel/class UNetModelDualcondV2/attribute.md","title":"attribute","links":[],"tags":[],"content":"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nå‚æ•°ä½œç”¨ä¸è¯´æ˜image_sizeè¾“å…¥å›¾åƒçš„å¤§å°ï¼Œç”¨äºæ„å»º U-Net ç»“æ„çš„å±‚çº§ï¼Œä¸€èˆ¬ç”¨äºè¾“å…¥å‰çš„å°ºå¯¸æ ¡éªŒæˆ–æ¨æ–­ç½‘ç»œæ·±åº¦ã€‚in_channelsè¾“å…¥å›¾åƒçš„é€šé“æ•°ï¼Œä¾‹å¦‚ RGB ä¸º 3ï¼Œç°åº¦å›¾ä¸º 1ã€‚model_channelsæ¨¡å‹çš„åŸºç¡€é€šé“æ•°ï¼Œå†³å®šäº†ç¬¬ä¸€å±‚ç‰¹å¾å›¾çš„å®½åº¦ã€‚U-Net çš„é€šé“æ•°é€šå¸¸æ˜¯ model_channels * mult å½¢å¼å¢é•¿ã€‚out_channelsè¾“å‡ºå›¾åƒçš„é€šé“æ•°ï¼Œé€šå¸¸ä¸ in_channels ç›¸åŒï¼Œä¾‹å¦‚ 3 é€šé“å›¾åƒã€‚ä¹Ÿå¯ä»¥æ˜¯ codebook å¤§å°ï¼ˆç”¨äº VQï¼‰ã€‚num_res_blocksæ¯ä¸ª downsample/upsample å±‚ä½¿ç”¨çš„ ResBlock ä¸ªæ•°ã€‚å¯ä¸º intï¼ˆæ¯å±‚ç›¸åŒï¼‰ï¼Œä¹Ÿå¯ä¸º listï¼ˆä¸åŒå±‚ä¸åŒæ•°é‡ï¼‰ã€‚attention_resolutionsæŒ‡å®šåœ¨å“ªäº› resolution ä¸‹æ’å…¥ attention æ¨¡å—ã€‚ä¾‹å¦‚åŒ…å« 4 è¡¨ç¤ºåœ¨ 1/4 å°ºåº¦ç‰¹å¾å›¾ä¸ŠåŠ å…¥ self-attn æˆ– cross-attnã€‚dropoutDropout æ¦‚ç‡ï¼Œæ§åˆ¶ç½‘ç»œçš„éšæœºå¤±æ´»ç¨‹åº¦ã€‚ç”¨äºæå‡æ³›åŒ–èƒ½åŠ›ã€‚channel_multU-Net æ¯ä¸ªå±‚çº§çš„é€šé“æ‰©å±•å€ç‡ã€‚ä¾‹å¦‚ (1, 2, 4, 8) è¡¨ç¤ºç¬¬4å±‚ä¸ºåŸºé€šé“çš„8å€ã€‚conv_resampleæ˜¯å¦ä½¿ç”¨å·ç§¯æ–¹å¼è¿›è¡Œä¸Šä¸‹é‡‡æ ·ï¼ˆå¦‚ PixelShuffleã€ConvTransposeï¼‰ï¼Œå¦åˆ™ä½¿ç”¨ç®€å•æ’å€¼ã€‚dimsè¾“å…¥æ•°æ®ç»´åº¦ï¼Œ2 è¡¨ç¤º 2D å›¾åƒï¼Œ1 æˆ– 3 åˆ™ç”¨äºåºåˆ—æˆ–ä½“æ•°æ®ã€‚num_classesåˆ†ç±»æ¡ä»¶æ•°é‡ã€‚å¦‚æœè®¾ç½®ä¸ºæ•´æ•°ï¼Œåˆ™æ¨¡å‹æ˜¯ class-conditionalï¼›æ”¯æŒ int æˆ– &quot;continuous&quot;ã€‚use_checkpointæ˜¯å¦å¼€å¯ gradient checkpointingï¼ˆåå‘ä¼ æ’­æ—¶èŠ‚çœå†…å­˜ï¼‰ã€‚ä¼šç‰ºç‰²é€Ÿåº¦æ¢ç©ºé—´ã€‚use_fp16æ˜¯å¦ä½¿ç”¨ float16 ç²¾åº¦æ¨ç†ï¼Œä¸»è¦ç”¨äºå‡å°‘æ˜¾å­˜ã€‚num_headsæ³¨æ„åŠ›æœºåˆ¶ä¸­ head çš„æ•°é‡ï¼Œå¦‚æœä¸º -1ï¼Œåˆ™æ ¹æ® num_head_channels è‡ªåŠ¨è®¡ç®—ã€‚num_head_channelsæ¯ä¸ª attention head çš„ç»´åº¦ï¼Œä¼˜å…ˆçº§é«˜äº num_headsã€‚äºŒè€…éœ€è‡³å°‘è®¾ç½®ä¸€ä¸ªã€‚num_heads_upsampleç”¨äºä¸Šé‡‡æ ·é˜¶æ®µçš„ attention head æ•°ï¼Œé»˜è®¤ä¸ num_heads ä¸€è‡´ã€‚use_scale_shift_normæ˜¯å¦åœ¨ ResBlock ä¸­ä½¿ç”¨ FiLM é£æ ¼çš„ scale-shift å½’ä¸€åŒ–ï¼ˆç”¨äºæ¡ä»¶å»ºæ¨¡ï¼‰ã€‚resblock_updownæ˜¯å¦ä½¿ç”¨æ®‹å·®å—è¿›è¡Œä¸Š/ä¸‹é‡‡æ ·ï¼Œå¦åˆ™ä½¿ç”¨ Downsample/Upsample æ¨¡å—ã€‚use_new_attention_orderæ§åˆ¶ attention é¡ºåºçš„å®éªŒæ€§è®¾ç½®ã€‚é»˜è®¤ä¸º Falseã€‚use_spatial_transformeræ˜¯å¦ä½¿ç”¨ Transformer æ›¿ä»£åŸç”Ÿ AttentionBlockã€‚å¼€å¯åéœ€è®¾ç½® context_dimã€‚transformer_depthTransformer æ¨¡å—çš„å †å æ·±åº¦ï¼ˆå±‚æ•°ï¼‰ã€‚context_dimCross-Attention ä¸­ contextï¼ˆå¦‚æ–‡æœ¬ã€å›¾åƒç¼–ç ï¼‰çš„ç»´åº¦ï¼Œå¿…é¡»ä¸ transformer é…å¥—ã€‚n_embedå¦‚æœä¸ä¸º Noneï¼Œè¡¨ç¤ºè¯¥æ¨¡å‹ç”¨äºé¢„æµ‹ codebook çš„ç¦»æ•£ tokenï¼ˆå¦‚ VQ-VAE / VQGAN åœºæ™¯ï¼‰ã€‚legacyæ§åˆ¶æ˜¯å¦ä½¿ç”¨ legacy çš„ attention ç»´åº¦è®¾ç½®é€»è¾‘ã€‚True è¡¨ç¤ºä¿æŒæ—§å®ç°å…¼å®¹æ€§ã€‚disable_self_attentionsæ˜¯å¦ç¦ç”¨æŸäº›å±‚ä¸­çš„ self-attnã€‚ä¸ºä¸€ä¸ªå¸ƒå°”åˆ—è¡¨ï¼Œé•¿åº¦ç­‰äº channel_multã€‚num_attention_blocksæ§åˆ¶æ¯ä¸ªå±‚çš„ attention block æ•°é‡ã€‚ä¼˜å…ˆçº§ä½äº attention_resolutionsã€‚disable_middle_self_attnæ˜¯å¦ç¦ç”¨ U-Net æœ€åº•éƒ¨ï¼ˆä¸­é—´å±‚ï¼‰çš„ self-attnã€‚use_linear_in_transformeræ˜¯å¦åœ¨ transformer ä¸­ä½¿ç”¨ Linear å½¢å¼çš„æŠ•å½±å±‚ã€‚semb_channelsç»“æ„æ¡ä»¶é€šé“æ•°ï¼ˆä¾‹å¦‚ç»“æ„å›¾ã€å°æ³¢å­å¸¦ç­‰ï¼‰ï¼Œä¼šä¼ å…¥ ResBlockDual è¿›è¡Œæ—¶é—´/ç»“æ„èåˆã€‚\nä¸ Time-Aware Encoder çš„å…³ç³»\nä½œä¸º Time-Aware Encoderï¼Œè¿™äº›å‚æ•°ä¸­ä»¥ä¸‹å‡ é¡¹èµ·å…³é”®ä½œç”¨ï¼š\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nå‚æ•°Time-Aware Encoder ä¸­çš„æ„ä¹‰t_embï¼ˆéšå«äº time_embedï¼‰ä¸ºæ¯ä¸ªæ—¶åˆ» t ç”Ÿæˆæ—¶é—´åµŒå…¥ï¼Œä¸ç»“æ„ä¸€èµ·å‚ä¸ç”Ÿæˆï¼ˆç±»ä¼¼æ—¶é—´æ¡ä»¶æ‰©æ•£ï¼‰semb_channelsæ”¯æŒç»“æ„æ¡ä»¶çš„é€šé“è¾“å…¥ï¼ˆå¦‚å°æ³¢å­å¸¦ã€æ·±åº¦å›¾ã€è¾¹ç¼˜å›¾ç­‰ï¼‰ï¼Œé€šè¿‡ ResBlockDual èåˆè¿›å…¥ä¸»å¹²ç½‘ç»œcontext_dim + use_spatial_transformerå®ç° Cross-Attentionï¼Œç”¨äºå°†æ–‡æœ¬/å›¾åƒä¸Šä¸‹æ–‡ä¿¡æ¯èåˆè¿›ç‰¹å¾æµuse_checkpoint + use_fp16æ§åˆ¶è®­ç»ƒæ—¶çš„è®¡ç®—æ•ˆç‡ï¼Œé€‚åˆå¤§è§„æ¨¡æ—¶é—´åºåˆ—è®­ç»ƒ"},"StableSR_doc/ldm/modules/diffusionmodules/openaimodel/class-UNetModelDualcondV2/convert_to_fp16":{"slug":"StableSR_doc/ldm/modules/diffusionmodules/openaimodel/class-UNetModelDualcondV2/convert_to_fp16","filePath":"StableSR_doc/ldm/modules/diffusionmodules/openaimodel/class UNetModelDualcondV2/convert_to_fp16.md","title":"convert_to_fp16","links":[],"tags":[],"content":""},"StableSR_doc/ldm/modules/diffusionmodules/openaimodel/class-UNetModelDualcondV2/convert_to_fp32":{"slug":"StableSR_doc/ldm/modules/diffusionmodules/openaimodel/class-UNetModelDualcondV2/convert_to_fp32","filePath":"StableSR_doc/ldm/modules/diffusionmodules/openaimodel/class UNetModelDualcondV2/convert_to_fp32.md","title":"convert_to_fp32","links":[],"tags":[],"content":""},"StableSR_doc/ldm/modules/diffusionmodules/openaimodel/class-UNetModelDualcondV2/forward":{"slug":"StableSR_doc/ldm/modules/diffusionmodules/openaimodel/class-UNetModelDualcondV2/forward","filePath":"StableSR_doc/ldm/modules/diffusionmodules/openaimodel/class UNetModelDualcondV2/forward.md","title":"forward","links":[],"tags":[],"content":""},"StableSR_doc/ldm/utils/Module_info":{"slug":"StableSR_doc/ldm/utils/Module_info","filePath":"StableSR_doc/ldm/utils/Module_info.md","title":"Module_info","links":["StableSR_doc/ldm/utils/get_obj_from_str","StableSR_doc/ldm/utils/instantiate_from_config"],"tags":[],"content":"Functions\n\nget_obj_from_str\ninstantiate_from_config\n"},"StableSR_doc/ldm/utils/get_obj_from_str":{"slug":"StableSR_doc/ldm/utils/get_obj_from_str","filePath":"StableSR_doc/ldm/utils/get_obj_from_str.md","title":"get_obj_from_str","links":[],"tags":[],"content":"def get_obj_from_str(string, reload=False):\n    module, cls = string.rsplit(&quot;.&quot;, 1)\n    if reload:\n        module_imp = importlib.import_module(module)\n        importlib.reload(module_imp)\n    return getattr(importlib.import_module(module, package=None), cls)"},"StableSR_doc/ldm/utils/instantiate_from_config":{"slug":"StableSR_doc/ldm/utils/instantiate_from_config","filePath":"StableSR_doc/ldm/utils/instantiate_from_config.md","title":"instantiate_from_config","links":["StableSR_doc/ldm/utils/get_obj_from_str"],"tags":[],"content":"def instantiate_from_config(config):\n    if not &quot;target&quot; in config:\n        if config == &#039;__is_first_stage__&#039;:\n            return None\n        elif config == &quot;__is_unconditional__&quot;:\n            return None\n        raise KeyError(&quot;Expected key `target` to instantiate.&quot;)\n    return get_obj_from_str(config[&quot;target&quot;])(**config.get(&quot;params&quot;, dict()))\n \nä½œç”¨\nè¯»å–configé…ç½®æ–‡ä»¶,æŒ‰ç…§å…¶æŒ‡å®šè§„åˆ™å°†targetæŒ‡å®šçš„ç±»å®ä¾‹åŒ–.åŒæ—¶åœ¨ç¬¬2è¡Œifå—ä¸­ç»™å‡ºäº†ä¸è¿›è¡Œå®ä¾‹åŒ–çš„åˆ¤æ–­é€»è¾‘,å¯ä»¥åˆ©ç”¨å®ƒæ¥æ§åˆ¶å¼€å…³æŸäº›æ¨¡å—(å¦‚æ³¨æ„åŠ›æœºåˆ¶å’Œç»“æ„æ¡ä»¶).\nconfig é…ç½®è¦æ±‚\nåº”è¯¥ä½¿ç”¨yamlæ–‡ä»¶,åŒ…å«targeté¡¹ç”¨äºæŒ‡å®šç±»å,paramsé¡¹åŠå…¶å­é¡¹ç”¨äºæŒ‡å®šå®ä¾‹åŒ–æ—¶çš„æ¨¡å‹å‚æ•°.\nå…·ä½“çš„å®ä¾‹åŒ–é€»è¾‘å’Œè¿‡ç¨‹\nget_obj_from_str è¿”å›ä¸€ä¸ªç±»å¯¹è±¡,åœ¨get_obj_from_str(â€¦)åé¢çš„ (**config.get)(&quot;params&quot;,dict())ç›¸å½“äºå°†paramsä½œä¸ºå‚æ•°ä¼ å…¥åˆ°å‰é¢çš„ç±»å¯¹è±¡çš„__init__ä¸­,æœ€ç»ˆå®Œæˆå®ä¾‹åŒ–."},"StableSR_doc/pytorch-lightning":{"slug":"StableSR_doc/pytorch-lightning","filePath":"StableSR_doc/pytorch lightning.md","title":"pytorch lightning","links":[],"tags":[],"content":"pytorch lightingæ¨¡å—ç®€ä»‹\npl.LightningMoudule\npl.LightningModule æ˜¯å¯¹ torch.nn.Module çš„é«˜çº§å°è£…\nåªéœ€è¦å®ç°ä¸‹é¢å‡ ä¸ªå…³é”®æ–¹æ³•ï¼Œå®ƒå°±èƒ½å¸®ä½ è‡ªåŠ¨å®Œæˆè®­ç»ƒæµç¨‹ã€GPU åˆ†å‘ã€æ—¥å¿—è®°å½•ã€checkpointä¿å­˜ç­‰å¤æ‚æ“ä½œï¼š\n\n\n\n__init__(self): åˆå§‹åŒ–æ¨¡å‹ç»“æ„ã€æŸå¤±å‡½æ•°ã€è¶…å‚æ•°ç­‰ã€‚\n\n\n\n\nforward(self, x): å®šä¹‰å‰å‘ä¼ æ’­é€»è¾‘ï¼ˆæ³¨æ„ï¼šä»…åœ¨è°ƒç”¨ model(x) æ—¶ä½¿ç”¨ï¼Œè®­ç»ƒé€»è¾‘ç”¨ training_stepï¼‰ã€‚\n\n\n\n\ntraining_step(self, batch, batch_idx):å®šä¹‰ä¸€ä¸ªè®­ç»ƒæ­¥éª¤çš„è¡Œä¸ºï¼Œè¿”å› lossã€‚\n\n\né€šå¸¸çš„æ­¥éª¤æ˜¯\n\nä» batch å–å‡ºæ•°æ®ï¼›\nå‰å‘ä¼ æ’­ï¼›\nè®¡ç®—æŸå¤±ï¼›\nä½¿ç”¨ self.log(...) è‡ªåŠ¨è®°å½•æ—¥å¿—ï¼ˆå¦‚ lossï¼‰ã€‚\n\n\n\n\n\n\nvalidation_step(...) / test_step(...):éªŒè¯å’Œæµ‹è¯•é˜¶æ®µçš„è¡Œä¸ºï¼Œç»“æ„ä¸ training_step ç±»ä¼¼ã€‚\n\n\n\n\nconfigure_optimizers(self):è¿”å›ä¼˜åŒ–å™¨å’Œï¼ˆå¯é€‰çš„ï¼‰å­¦ä¹ ç‡è°ƒåº¦å™¨ã€‚\n\n\n\npytorch_Lightning Callback æœºåˆ¶\nPyTorch Lightning çš„ Callbackï¼ˆå›è°ƒæœºåˆ¶ï¼‰æ˜¯è®­ç»ƒè¿‡ç¨‹ä¸­çš„äº‹ä»¶é’©å­ç³»ç»Ÿï¼Œå…è®¸ç”¨æˆ·åœ¨è®­ç»ƒ / éªŒè¯ / æµ‹è¯• / ä¿å­˜ç­‰é˜¶æ®µæ’å…¥è‡ªå®šä¹‰é€»è¾‘ï¼Œç±»ä¼¼äºé’©å­ï¼ˆhookï¼‰æˆ–ç›‘å¬å™¨ã€‚\n\nâœ… å¸¸è§ç”¨é€”\n\nè‡ªåŠ¨ä¿å­˜æœ€ä½³æ¨¡å‹ï¼ˆå¦‚æ ¹æ® val/loss æœ€å°ï¼‰\nEarly stoppingï¼ˆæå‰åœæ­¢è®­ç»ƒï¼‰\næ—¥å¿—è®°å½• / å­¦ä¹ ç‡å¯è§†åŒ–\nè‡ªå®šä¹‰æ—¥å¿—ã€è¯„ä¼°ã€æ ·æœ¬å¯è§†åŒ–ç­‰è¡Œä¸º\n\n\nğŸ§© æ ¸å¿ƒæ¦‚å¿µï¼šCallback æ˜¯ä¸€ä¸ªç±»\nfrom pytorch_lightning.callbacks import Callback\n \nclass MyCallback(Callback):\n    def on_train_start(self, trainer, pl_module):\n        print(&quot;è®­ç»ƒå¼€å§‹ï¼&quot;)\n    \n    def on_validation_end(self, trainer, pl_module):\n        print(&quot;éªŒè¯é˜¶æ®µç»“æŸã€‚&quot;)\n \n    def on_train_batch_end(self, trainer, pl_module, outputs, batch, batch_idx):\n        print(f&quot;è®­ç»ƒç¬¬ {batch_idx} ä¸ª batch å®Œæˆ&quot;)\n\nğŸ§ª ä½¿ç”¨ Callback çš„æ–¹å¼\nfrom pytorch_lightning import Trainer\n \ntrainer = Trainer(callbacks=[MyCallback()])\nå¯ä»¥ä¸€æ¬¡æ€§æ³¨å†Œå¤šä¸ª callbackï¼š\ntrainer = Trainer(callbacks=[\n    MyCallback(),\n    ModelCheckpoint(...),\n    EarlyStopping(...)\n])\n\nğŸ“¦ å®˜æ–¹å†…ç½®å¸¸ç”¨å›è°ƒ\n1. ModelCheckpoint: ä¿å­˜æœ€ä¼˜æ¨¡å‹\nfrom pytorch_lightning.callbacks import ModelCheckpoint\n \ncheckpoint_callback = ModelCheckpoint(\n    monitor=&quot;val/loss&quot;,     # ç›‘æ§å“ªä¸ªæŒ‡æ ‡\n    save_top_k=1,           # åªä¿ç•™ top1\n    mode=&quot;min&quot;,             # ç›®æ ‡æ˜¯æœ€å°åŒ– loss\n    filename=&quot;best-checkpoint&quot;,\n    save_last=True\n)\n2. EarlyStopping: æå‰åœæ­¢\nfrom pytorch_lightning.callbacks import EarlyStopping\n \nearly_stop_callback = EarlyStopping(\n    monitor=&quot;val/loss&quot;,\n    patience=5,     # è‹¥ 5 ä¸ª epoch æ²¡æœ‰æå‡åˆ™åœæ­¢\n    mode=&quot;min&quot;\n)\n\nğŸ“š å¸¸ç”¨ Callback é’©å­æ–¹æ³•ä¸€è§ˆ\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\næ–¹æ³•åè°ƒç”¨æ—¶æœºon_fit_startfit() å¼€å§‹æ—¶on_train_startè®­ç»ƒé˜¶æ®µå¼€å§‹on_train_endè®­ç»ƒé˜¶æ®µç»“æŸon_train_batch_startæ¯ä¸ª batch å¼€å§‹å‰on_train_batch_endæ¯ä¸ª batch ç»“æŸåon_validation_endæ¯è½®éªŒè¯ç»“æŸåon_save_checkpointä¿å­˜ checkpoint æ—¶on_load_checkpointåŠ è½½ checkpoint æ—¶\n\nğŸ¯ å®ä¾‹ï¼šåœ¨éªŒè¯åè®°å½•å½“å‰æ¨¡å‹çŠ¶æ€\nclass LogModelNorm(Callback):\n    def on_validation_end(self, trainer, pl_module):\n        total_norm = 0\n        for p in pl_module.parameters():\n            if p.grad is not None:\n                param_norm = p.grad.data.norm(2)\n                total_norm += param_norm.item() ** 2\n        total_norm = total_norm ** 0.5\n        print(f&quot;å½“å‰æ¢¯åº¦èŒƒæ•°ï¼š{total_norm:.4f}&quot;)\n\nâœ… å°ç»“\n\nCallback æ˜¯ä¸€ç§è½»é‡çº§çš„æ’ä»¶ç³»ç»Ÿï¼›\næ‰€æœ‰æ¨¡å‹ç›¸å…³å›è°ƒéƒ½å¯ä»¥é›†ä¸­ç®¡ç†ï¼Œä¸æ±¡æŸ“æ ¸å¿ƒè®­ç»ƒé€»è¾‘ï¼›\néå¸¸é€‚åˆè®°å½•æ—¥å¿—ã€ä¿å­˜ä¸­é—´ç»“æœã€åŠ¨æ€ä¿®æ”¹è®­ç»ƒè¡Œä¸ºç­‰ã€‚\n"},"index":{"slug":"index","filePath":"index.md","title":"é¦–é¡µ","links":[],"tags":[],"content":"æ¬¢è¿æ¥åˆ°æˆ‘çš„ Quartz Blogs\nWeclome!\nè¿™æ˜¯æˆ‘çš„æ•°å­—èŠ±å›­é¦–é¡µ,ä½ å¯ä»¥ä»å·¦è¾¹çš„ç›®å½•æˆ–æœç´¢æ¡†è¿›å…¥ç¬”è®°ã€‚"},"learn_c/data-type":{"slug":"learn_c/data-type","filePath":"learn_c/data type.md","title":"data type","links":[],"tags":[],"content":"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\næ•°æ®ç±»å‹ (å…³é”®å­—)å¸¸è§å£°æ˜æ–¹å¼å ä½ç¬¦ (printf/scanf)è¯´æ˜charchar c = &#039;A&#039;;%cå­—ç¬¦ç±»å‹ï¼ˆå®é™…ä¸Šå­˜å‚¨æ•´æ•°ï¼Œå¯¹åº” ASCII ç ï¼‰ã€‚é€šå¸¸ 1 å­—èŠ‚ (8 ä½)ã€‚signed charsigned char sc = -10;%cæ˜ç¡®å¸¦ç¬¦å·çš„å­—ç¬¦ï¼ŒèŒƒå›´ä¸€èˆ¬æ˜¯ -128 ~ 127ã€‚unsigned charunsigned char uc = 250;%c æˆ– %hhuæ— ç¬¦å·å­—ç¬¦ï¼ŒèŒƒå›´ 0 ~ 255ã€‚intint x = 42;%d æˆ– %iæ•´æ•°ï¼Œé€šå¸¸ 4 å­—èŠ‚ï¼ŒèŒƒå›´çº¦ -2,147,483,648 ~ 2,147,483,647ã€‚short / short intshort s = 100;%hdçŸ­æ•´å‹ï¼Œä¸€èˆ¬ 2 å­—èŠ‚ã€‚unsigned shortunsigned short us = 60000;%huæ— ç¬¦å·çŸ­æ•´å‹ï¼ŒèŒƒå›´çº¦ 0 ~ 65535ã€‚long / long intlong l = 123456;%ldé•¿æ•´å‹ï¼Œä¸€èˆ¬ 4 æˆ– 8 å­—èŠ‚ï¼ˆå–å†³äºç³»ç»Ÿï¼‰ã€‚unsigned longunsigned long ul = 4000000000UL;%luæ— ç¬¦å·é•¿æ•´å‹ã€‚long long / long long intlong long ll = 123456789LL;%lldæ›´å¤§çš„æ•´æ•°ï¼Œä¸€èˆ¬ 8 å­—èŠ‚ã€‚unsigned long longunsigned long long ull = 18446744073709551615ULL;%lluæœ€å¤§çš„æ ‡å‡†æ— ç¬¦å·æ•´æ•°ç±»å‹ã€‚floatfloat f = 3.14f;%få•ç²¾åº¦æµ®ç‚¹æ•°ï¼Œçº¦ 6~7 ä½æœ‰æ•ˆæ•°å­—ã€‚doubledouble d = 3.141592653;%lfåŒç²¾åº¦æµ®ç‚¹æ•°ï¼Œçº¦ 15~16 ä½æœ‰æ•ˆæ•°å­—ã€‚long doublelong double ld = 3.141592653589793L;%Lfæ‰©å±•ç²¾åº¦æµ®ç‚¹ï¼Œç²¾åº¦æ¯” double é«˜ï¼ˆå¹³å°ä¾èµ–ï¼‰ã€‚_Bool (C99)_Bool flag = 1;%dåªèƒ½æ˜¯ 0 æˆ– 1ã€‚éœ€è¦ &lt;stdbool.h&gt; å¤´æ–‡ä»¶æ—¶å¯å†™ä½œ boolã€‚voidvoid func(void);æ— è¡¨ç¤ºâ€œæ— ç±»å‹â€ï¼Œç”¨äºå‡½æ•°è¿”å›ç±»å‹æˆ–æŒ‡é’ˆ (void*)ã€‚"},"åˆ†å¸ƒå¼/Welcome":{"slug":"åˆ†å¸ƒå¼/Welcome","filePath":"åˆ†å¸ƒå¼/Welcome.md","title":"Welcome","links":["create-a-link"],"tags":[],"content":"This is your new vault.\nMake a note of something, create a link, or try the Importer!\nWhen youâ€™re ready, delete this note and make the vault your own."},"æ•°ç†ç»Ÿè®¡2/å›å½’/ä¸€å…ƒçº¿æ€§å›å½’/1.åŸºæœ¬å‡è®¾":{"slug":"æ•°ç†ç»Ÿè®¡2/å›å½’/ä¸€å…ƒçº¿æ€§å›å½’/1.åŸºæœ¬å‡è®¾","filePath":"æ•°ç†ç»Ÿè®¡2/å›å½’/ä¸€å…ƒçº¿æ€§å›å½’/1.åŸºæœ¬å‡è®¾.md","title":"1.åŸºæœ¬å‡è®¾","links":[],"tags":[],"content":"è§£é‡Šå˜é‡x_,\\cdots,x_pééšæœºå˜é‡ï¼Œæ ·æœ¬\\{(y_i,X_i) \\mid 1\\leq i\\leq n\\}è§‚æµ‹å€¼x_{i1},\\cdots ,x_{ip}ä¸ºå¸¸æ•°\nè¯¯å·®é¡¹éšæœºå˜é‡\\epsilon æ»¡è¶³\nE[\\epsilon_i]=0,i=1\\cdots ,n \n\\begin{cases}\n\\text{Var}(\\epsilon_i) = \\sigma^2, &amp; i = 1, \\cdots, n \\\\\n\\text{Cov}(\\epsilon_i, \\epsilon_j) = 0, &amp; i \\neq j\n\\end{cases}\nå³å„æ ·æœ¬ç‚¹ä¸Šçš„è¯¯å·®é¡¹å‡å€¼ä¸ºé›¶ã€æ–¹å·®ç›¸åŒä¸”ç›¸äº’ç‹¬ç«‹ã€‚"},"æ•°ç†ç»Ÿè®¡2/å›å½’/ä¸€å…ƒçº¿æ€§å›å½’/2.æœ€å°äºŒä¹˜ä¼°è®¡OLSE":{"slug":"æ•°ç†ç»Ÿè®¡2/å›å½’/ä¸€å…ƒçº¿æ€§å›å½’/2.æœ€å°äºŒä¹˜ä¼°è®¡OLSE","filePath":"æ•°ç†ç»Ÿè®¡2/å›å½’/ä¸€å…ƒçº¿æ€§å›å½’/2.æœ€å°äºŒä¹˜ä¼°è®¡OLSE.md","title":"2.æœ€å°äºŒä¹˜ä¼°è®¡OLSE","links":[],"tags":[],"content":"æ±‚è§£ä¸€å…ƒçº¿æ€§å›å½’æ¨¡å‹ï¼Œå°±æ˜¯è¦ç»™å‡ºçœŸå®å›å½’æ¨¡å‹y=\\beta_1x+\\beta_0ä¸­\\beta_0,\\beta_1çš„ä¼°è®¡\\hat{\\beta_0},\\hat{\\beta_1}.ä½†ç”±äºæ®‹å·®é¡¹\\epsilonçš„åˆ†å¸ƒç±»å‹æ˜¯æœªçŸ¥çš„ï¼Œæ— æ³•æ¨ç†å‡ºyçš„åˆ†å¸ƒç±»å‹ï¼Œè¿›è€Œä¼°è®¡ï¼Œäºæ˜¯é‡‡ç”¨æœ€å°äºŒä¹˜æ³•ä¼°è®¡\\beta_0,\\beta_1.\næœ€å°äºŒä¹˜ä¼°è®¡æ±‚å‡ºçš„å›å½’æ–¹ç¨‹ï¼Œæˆä¸ºä¸€å…ƒçº¿æ€§ç»éªŒå›å½’æ–¹ç¨‹ã€‚\n\\hat{y}=\\hat{\\beta_1}x+\\hat{\\beta_0}\nç®—æ³•\nç›®çš„ä¸ºæœ€å°åŒ–æ€»æ‹Ÿåˆè¯¯å·®\\left|y_i-\\hat{\\beta_1}x-\\hat{\\beta_0}\\right|.\næ„é€ ç›®æ ‡å‡½æ•°\nQ(\\gamma_0,\\gamma_1)=\\Sigma_{i=1}^n(y_i-\\gamma_0-\\gamma_1x)^2\nQæ˜¯å‡¸å‡½æ•°ï¼Œ\n\\left\\{\n\\begin{aligned}\n\\frac{\\partial{Q}}{\\partial{\\gamma_0}} &amp;= 0 \\\\\n\\frac{\\partial{Q}}{\\partial{\\gamma_1}} &amp;= 0 \n\\end{aligned}\n\\right.\næ»¡è¶³ä¸Šè¿°æ–¹ç¨‹ç»„çš„\\gamma_0,\\gamma_1å³ä¸ºæœ€å°äºŒä¹˜ä¼°è®¡\\hat{\\beta_0},\\hat{\\beta_1}\n\\left\\{\n\\begin{aligned}\n\\hat{\\beta_1} &amp;= \\frac{L_{xy}}{L_{xx}} \\\\\n\\hat{\\beta_0} &amp;= \\bar{y}-\\hat{\\beta_1}x\n\\end{aligned}\n\\right.\nå…¶ä¸­\n\\left\\{\n\\begin{aligned}\nL_{xx}&amp;=\\Sigma(x_i-\\bar{x})^2 \\\\\nL_{xy}&amp;=\\Sigma(x_i-\\bar{x})(y_i-\\bar{y})\n\\end{aligned}\n\\right."},"æ•°ç†ç»Ÿè®¡2/å›å½’/ä¸€å…ƒçº¿æ€§å›å½’/3.å›å½’ç³»æ•°çš„æ€§è´¨":{"slug":"æ•°ç†ç»Ÿè®¡2/å›å½’/ä¸€å…ƒçº¿æ€§å›å½’/3.å›å½’ç³»æ•°çš„æ€§è´¨","filePath":"æ•°ç†ç»Ÿè®¡2/å›å½’/ä¸€å…ƒçº¿æ€§å›å½’/3.å›å½’ç³»æ•°çš„æ€§è´¨.md","title":"3.å›å½’ç³»æ•°çš„æ€§è´¨","links":[],"tags":[],"content":"çº¿æ€§æ€§\n\\hat{\\beta_1},\\hat{\\beta_0}æ˜¯ éšæœºå˜é‡y_içš„çº¿æ€§å‡½æ•°\næ— åæ€§\n\\begin{aligned}\nE\\hat{\\beta_1} &amp;=E[\\frac{\\Sigma_{i=1}^n (x_i-\\bar{x})y_i}{\\Sigma_{i=1}^n(x_i-\\bar{x})^2}] \\\\\n\t\t\t   \n\t\t\t   &amp;=\\frac{\\Sigma_{i=1}^n (x_i-\\bar{x})E[y_i]}{\\Sigma_{i=1}^n(x_i-\\bar{x})^2} \\\\\n\t\t\t   \n\t\t\t   &amp;=\\frac{\\Sigma_{i=1}^n (x_i-\\bar{x})(\\beta_1x_i+\\beta_0)}{\\Sigma_{i=1}^n(x_i-\\bar{x})^2} \\\\\n\t\t\t   \n\t\t\t   &amp;=\\frac{\\Sigma_{i=1}^n (x_i-\\bar{x})x_i}{\\Sigma_{i=1}^n(x_i-\\bar{x})^2}\\beta_1 \\\\\n\t\t\t   \n\\end{aligned}\nå…¶ä¸­\\frac{\\Sigma_{i=1}^n (x_i-\\bar{x})x_i}{\\Sigma_{i=1}^n(x_i-\\bar{x})^2}=1 \næ•…E\\hat{\\beta_1}=\\beta_1,åŒç†å¯è¯E\\hat{\\beta_0}=\\beta_0\næ–¹å·®\nç”±äºy_1,\\cdots,y_nç‹¬ç«‹ï¼Œvar(y_i)=\\sigma^2\næ•…$$\n\\begin{aligned}\nVar(\\hat{\\beta_1}) &amp;= \\Sigma_{i=1}^{n} [\\frac{x_i - \\bar{x}}{\\Sigma_{i=1}^n (x_i-\\bar{x})^2}]^2 Var(y_i)\\\n&amp;= \\frac{\\sigma^2}{L_{xx}}\n\\end{aligned}\n\nVar(\\hat{\\beta_0})=[\\frac{1}{n}+\\frac{\\bar{x}^2}{L_{xx}}]\\sigma\n"},"æ•°ç†ç»Ÿè®¡2/å›å½’/ä¸€å…ƒçº¿æ€§å›å½’/4.è¯¯å·®éšæœºå˜é‡æ–¹å·®çš„ä¼°è®¡":{"slug":"æ•°ç†ç»Ÿè®¡2/å›å½’/ä¸€å…ƒçº¿æ€§å›å½’/4.è¯¯å·®éšæœºå˜é‡æ–¹å·®çš„ä¼°è®¡","filePath":"æ•°ç†ç»Ÿè®¡2/å›å½’/ä¸€å…ƒçº¿æ€§å›å½’/4.è¯¯å·®éšæœºå˜é‡æ–¹å·®çš„ä¼°è®¡.md","title":"4.è¯¯å·®éšæœºå˜é‡æ–¹å·®çš„ä¼°è®¡","links":[],"tags":[],"content":"\\hat{\\sigma}^2 = \\frac{1}{n-2} \\sum (y_i - \\hat{y}_i)^2\nå…¶ä¸­\n\\hat{y}_i = \\hat{\\beta}_0 + \\hat{\\beta}_1 x_i"},"æ•°ç†ç»Ÿè®¡2/å›å½’/ä¸€å…ƒçº¿æ€§å›å½’/5.æ˜¾è‘—æ€§æ£€éªŒ":{"slug":"æ•°ç†ç»Ÿè®¡2/å›å½’/ä¸€å…ƒçº¿æ€§å›å½’/5.æ˜¾è‘—æ€§æ£€éªŒ","filePath":"æ•°ç†ç»Ÿè®¡2/å›å½’/ä¸€å…ƒçº¿æ€§å›å½’/5.æ˜¾è‘—æ€§æ£€éªŒ.md","title":"5.æ˜¾è‘—æ€§æ£€éªŒ","links":[],"tags":[],"content":"H_0: \\beta_1 = 0 \\quad\\text{vs.}\\quad H_1: \\beta_1 \\neq 0\ntæ£€éªŒ\nåœ¨å‡å®šè¯¯å·®é¡¹æ»¡è¶³ç‹¬ç«‹åŒåˆ†å¸ƒï¼Œä¸” \\varepsilon_i \\sim N(0, \\sigma^2) çš„æ¡ä»¶ä¸‹ï¼š\nå›å½’ç³»æ•°ä¼°è®¡çš„åˆ†å¸ƒ\nå‡è®¾\\epsilon_i \\sim N(0,\\sigma^2ï¼‰ åˆ™\\hat{\\beta}_1 \\sim N\\left(\\beta_1, \\dfrac{\\sigma^2}{L_{xx}}\\right)  ï¼Œå…¶ä¸­  L_{xx} = \\sum (x_i - \\bar{x})^2\nåœ¨ H_0 ä¸‹ï¼Œæœ‰\nt = \\frac{\\hat{\\beta}_1 - 0}{\\sqrt{\\hat{\\sigma}^2 / L_{xx}}} \\sim t_{n-2}\nFæ£€éªŒï¼šç›´æ¥ä»å›å½’æ•ˆæœæ£€éªŒæ˜¾è‘—æ€§\nå¹³æ–¹å’Œåˆ†è§£å¼\n\\sum_{i=1}^{n} (y_i - \\bar{y})^2 = \\sum_{i=1}^{n} (\\hat{y}_i - \\bar{y})^2 + \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2\n\nç§° \\sum_{i=1}^{n} (y_i - \\bar{y})^2 ä¸ºæ€»ç¦»å·®å¹³æ–¹å’Œ (SST)ï¼Œæè¿°è§‚æµ‹å€¼ y æœ¬èº«çš„æ–¹å·®\nç§° \\sum_{i=1}^{n} (\\hat{y}_i - \\bar{y})^2 ä¸ºå›å½’å¹³æ–¹å’Œ (SSR)\nç§° \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2 ä¸ºæ®‹å·®å¹³æ–¹å’Œ (SSE)\n\nSST = SSR + SSE\nè¯æ˜:\nå³è¯\n\\sum_{i=1}^{n} (y_i - \\hat{y}_i + \\hat{y}_i - \\bar{y})^2 = \\sum_{i=1}^{n} (y_i - \\bar{y})^2 + \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2\nå³è¯\n\\sum_{i=1}^{n} (y_i - \\hat{y}_i)(\\hat{y}_i - \\bar{y}) = 0\nè®°æ®‹å·® e_i = y_i - \\hat{y}_i\n\\frac{\\partial Q}{\\partial \\beta_1} = 2 \\sum x_i (y_i - \\hat{\\beta_1}x_i-\\hat{\\beta_0}) = 0, \\quad \\frac{\\partial Q}{\\partial \\beta_0} = 2 \\sum (y_i - \\beta_0 - \\beta_1 x_i) = 0\n\\Rightarrow e_i = y_i - \\hat{y}_i = y_i - \\hat{\\beta}_0 - \\hat{\\beta}_1 x_i \n\n\\Rightarrow \\sum x_i e_i = \\sum e_i = 0.\n\\begin{aligned}\n&amp;\\sum_{i=1}^{n} (y_i - \\hat{y}_i)(\\hat{y}_i - \\bar{y}) \\\\ \n=&amp;\\sum e_i (\\hat{y}_i - \\bar{y}) =\\sum e_i\\hat{y_i}+\\bar{y}\\sum e_i \\\\\n=&amp;\\sum e_i (\\hat{\\beta}_0 + \\hat{\\beta}_1 x_i) \\\\\n=&amp; \\hat{\\beta}_0 \\sum e_i + \\hat{\\beta}_1 \\sum (e_i x_i) \\\\\n=&amp; 0\n\\end{aligned}\nè¯æ¯•\næ„é€ Fåˆ†å¸ƒè¿›è¡Œæ£€éªŒ\nSSR è¶Šå¤§ï¼ŒSSE è¶Šå°è¯´æ˜å›å½’è¶Šå¥½\nH_0: \\beta_1 = 0 \\leftrightarrow H_1: \\beta_1 \\neq 0\nåœ¨ H_0 ä¸‹ï¼ŒF = \\frac{SSR/1}{SSE/(n-2)}ï¼Œ\\frac{SSE}{n-2} \\sim \\chi^2(n-2)ï¼ŒSSR \\sim \\chi^2(1)\n\\Rightarrow F \\xrightarrow{H_0} F(1, n-2)\nçš®å°”é€Šç›¸å…³ç³»æ•°æ£€éªŒ\nr = \\frac{\\sum_{i=1}^{n} (x_i - \\bar{x})(y_i - \\bar{y})}{\\sqrt{\\sum (x_i - \\bar{x})^2 \\sum (y_i - \\bar{y})^2}} = \\frac{l_{xy}}{\\sqrt{l_{xx} l_{yy}}}\nrè¶Šæ¥è¿‘ 1 æ‹Ÿåˆè¶Šå¥½"},"æ•°ç†ç»Ÿè®¡2/å›å½’/ä¸€å…ƒçº¿æ€§å›å½’/6.æ®‹å·®åˆ†æ":{"slug":"æ•°ç†ç»Ÿè®¡2/å›å½’/ä¸€å…ƒçº¿æ€§å›å½’/6.æ®‹å·®åˆ†æ","filePath":"æ•°ç†ç»Ÿè®¡2/å›å½’/ä¸€å…ƒçº¿æ€§å›å½’/6.æ®‹å·®åˆ†æ.md","title":"6.æ®‹å·®åˆ†æ","links":[],"tags":[],"content":"æ®‹å·®åˆ†æï¼šåˆ¤æ–­çœŸå®æ¨¡å‹æ˜¯å¦ä¸ºçº¿æ€§æ¨¡å‹\nè‹¥ä¸ºçº¿æ€§æ¨¡å‹åˆ™å¿…æ»¡è¶³ Ee_i = Ex_i \\cdot e_i = 0\næ®‹å·®åº”åœ¨ 0 é™„è¿‘éšæœºæ³¢åŠ¨\næ®‹å·® e_i çš„æ–¹å·®\n\\begin{aligned}\nVar(e_i) &amp;= Var(y_i - \\hat{y}_i) \\\\\n&amp;= Var(y_i) + Var(\\hat{y}_i) - 2Cov(y_i, \\hat{y}_i)\n\\end{aligned}\n(1) Var(y_i) = \\sigma^2\n(2)\n\\begin{aligned}\nVar(\\hat{y}_i) &amp;= Var(\\hat{\\beta}_0 + \\hat{\\beta}_1 x_i) \\\\\n&amp;= Var(\\hat{\\beta}_0) + Var(\\hat{\\beta}_1 x_i) + 2Cov(\\hat{\\beta}_0, \\hat{\\beta}_1 x_i) \\\\\n\\end{aligned}\nå…¶ä¸­\n\\begin{aligned}\nVar(\\hat{\\beta}_0) &amp;= \\left(\\frac{1}{n} + \\frac{\\bar{x}^2}{L_{xx}}\\right)\\sigma^2 \\\\\n\\\\\nVar(\\hat{\\beta}_1 x_i) &amp;= x_i^2 \\frac{\\sigma^2}{L_{xx}}\\\\\n\\\\\nCov(\\hat{\\beta}_0, \\hat{\\beta}_1) &amp;= Cov(\\bar{y} - \\hat{\\beta}_1 \\bar{x}, \\hat{\\beta}_1) \\\\\n&amp;= Cov(-\\hat{\\beta}_1 \\bar{x}, \\hat{\\beta}_1) + Cov(\\bar{y}, \\hat{\\beta}_1) \\\\\n&amp;= -\\bar{x} Var(\\hat{\\beta}_1) + \\frac{Var(y_i)}{n \\sum (x_i - \\bar{x})^2} \\cdot \\sum (x_i - \\bar{x}) \\\\\n&amp;= -\\bar{x} \\frac{\\sigma^2}{L_{xx}} + 0 \\\\\n\\end{aligned}\næ•…Cov(\\hat{\\beta}_0, \\hat{\\beta}_1 x_i) = -\\bar{x} x_i \\frac{\\sigma^2}{L_{xx}}\næ•…\n\\begin{aligned}\nVar(\\hat{y}_i) &amp;= \\left(\\frac{1}{n} + \\frac{\\bar{x}^2}{L_{xx}}\\right)\\sigma^2 + x_i^2 \\frac{\\sigma^2}{L_{xx}} - 2\\bar{x} x_i \\frac{\\sigma^2}{L_{xx}} \\\\\n&amp;= \\left(\\frac{1}{n} + \\frac{(x_i - \\bar{x})^2}{L_{xx}}\\right)\\sigma^2\n\\end{aligned}\n(3)\n\\begin{aligned}\nCov(y_i, \\hat{y}_i) &amp;= Cov(y_i, \\hat{\\beta}_1 x_i + \\bar{y} - \\hat{\\beta}_1 \\bar{x})\\\\\n&amp;= Cov(y_i, \\hat{\\beta}_1 x_i) + (x_i - \\bar{x}) Cov(y_i, \\hat{\\beta}_1) \\\\\n&amp;= \\frac{1}{n} Var(y_i) + (x_i - \\bar{x}) Cov(y_i, \\frac{\\sum (x_i - \\bar{x}) y_i}{L_{xx}}) \\\\\n&amp;= \\frac{1}{n} Var(y_i) + \\frac{(x_i - \\bar{x})^2}{L_{xx}} Var(y_i) \\\\\n&amp;= \\left(\\frac{1}{n} + \\frac{(x_i - \\bar{x})^2}{L_{xx}}\\right)\\sigma^2\n\\end{aligned}\nç»¼ä¸Šï¼šVar(e_i) = \\sigma^2 + \\left(\\frac{1}{n} + \\frac{(x_i - \\bar{x})^2}{L_{xx}}\\right)\\sigma^2 - 2\\left(\\frac{1}{n} + \\frac{(x_i - \\bar{x})^2}{L_{xx}}\\right)\\sigma^2 = (1 - \\frac{1}{n} - \\frac{(x_i - \\bar{x})^2}{L_{xx}})\\sigma^2 = (1 - \\hat{h}_i)\\sigma^2"},"æ•°ç†ç»Ÿè®¡2/å›å½’/å›å½’æ¨¡å‹":{"slug":"æ•°ç†ç»Ÿè®¡2/å›å½’/å›å½’æ¨¡å‹","filePath":"æ•°ç†ç»Ÿè®¡2/å›å½’/å›å½’æ¨¡å‹.md","title":"å›å½’æ¨¡å‹","links":[],"tags":[],"content":"å˜é‡x_1,\\cdots,x_pä¸éšæœºå˜é‡yå­˜åœ¨ç›¸å…³å…³ç³»ï¼Œå³ç¡®å®šx_1,\\cdots,x_pçš„å–å€¼åå¯ä»¥ç¡®å®šyçš„åˆ†å¸ƒï¼Œyä¸x_1,\\cdots,x_pä¹‹é—´çš„æ¦‚ç‡æ¨¡å‹ä¸ºy=f(x_i,\\cdots,x_p)+\\epsilonå½“fä¸ºçº¿æ€§å‡½æ•°æ—¶ï¼Œç§°æ¨¡å‹ä¸ºçº¿æ€§å›å½’æ¨¡å‹ã€‚"},"æ•°ç†ç»Ÿè®¡2/æ¦‚ç‡è®ºä¸æ•°ç†ç»Ÿè®¡åŸºç¡€/å¸¸ç”¨åˆ†å¸ƒ":{"slug":"æ•°ç†ç»Ÿè®¡2/æ¦‚ç‡è®ºä¸æ•°ç†ç»Ÿè®¡åŸºç¡€/å¸¸ç”¨åˆ†å¸ƒ","filePath":"æ•°ç†ç»Ÿè®¡2/æ¦‚ç‡è®ºä¸æ•°ç†ç»Ÿè®¡åŸºç¡€/å¸¸ç”¨åˆ†å¸ƒ.md","title":"å¸¸ç”¨åˆ†å¸ƒ","links":[],"tags":[],"content":"tåˆ†å¸ƒ\nè‹¥\\epsilon \\sim N(0,1),\\etaæœä»è‡ªç”±åº¦ä¸ºnçš„\\chi^2åˆ†å¸ƒ\\eta \\sim \\chi^2(n),åˆ™ç§°éšæœºå˜é‡T=\\frac{\\epsilon}{\\sqrt{\\frac{\\eta}{n}}}æœä»è‡ªç”±åº¦ä¸ºnçš„tåˆ†å¸ƒï¼ŒT \\sim t(n).\nF åˆ†å¸ƒ\nè®¾\\epsilon,\\etaæ˜¯è‡ªç”±åº¦ä¸ºm,nçš„ç‹¬ç«‹çš„\\chi^2éšæœºå˜é‡ï¼Œåˆ™ç§°éšæœºå˜é‡F=\\frac{\\epsilon/m}{\\eta/n}æ‰€æœä»çš„åˆ†å¸ƒä¸ºFåˆ†å¸ƒï¼Œè‡ªç”±åº¦ä¸º(m,n),è®°ä½œF \\sim F(m,n)."},"æ•°ç†ç»Ÿè®¡2/æ¦‚ç‡è®ºä¸æ•°ç†ç»Ÿè®¡åŸºç¡€/æ–¹å·®ã€åæ–¹å·®çš„æ€§è´¨":{"slug":"æ•°ç†ç»Ÿè®¡2/æ¦‚ç‡è®ºä¸æ•°ç†ç»Ÿè®¡åŸºç¡€/æ–¹å·®ã€åæ–¹å·®çš„æ€§è´¨","filePath":"æ•°ç†ç»Ÿè®¡2/æ¦‚ç‡è®ºä¸æ•°ç†ç»Ÿè®¡åŸºç¡€/æ–¹å·®ã€åæ–¹å·®çš„æ€§è´¨.md","title":"æ–¹å·®ã€åæ–¹å·®çš„æ€§è´¨","links":[],"tags":[],"content":"å¼•ç†\nX,Yç‹¬ç«‹åˆ™å¯¹ä»»ä½•å‡½æ•°h,gæˆç«‹\n E[g(X)g(Y)]=E[g(X)] \\cdot E[h(Y)]\næ–¹å·®ä¸åæ–¹å·®å¸¸ç”¨å…¬å¼\n\nåæ–¹å·®çš„å®šä¹‰Cov(X,Y)=E[(X-EX)(Y-EY)]=E[XY]-EX \\cdot EY\näº¤æ¢æ€§ï¼šCov(X,Y)=Cov(Y,X)\nçº¿æ€§æ€§:Coc(aX,Y)=aCov(X,Y) Cov(\\Sigma_{i=1}^nX_i,\\Sigma_{j=1}^mY_j)=\\Sigma_{i=1}^n\\Sigma_{j=1}^m Cov(X_i,Y_j)\næ–¹å·®å±•å¼€å¼ï¼šVar(\\Sigma_{i=1}^nX_i)=\\Sigma_{i=1}^nVar(X_i)+2\\Sigma_{i&lt;j}Cov(X_i,X_j)\n"}}